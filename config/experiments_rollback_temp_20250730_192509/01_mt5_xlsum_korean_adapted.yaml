# mT5 XL-Sum RTX 3090 ê·¹í•œ ìµœì í™” ì‹¤í—˜ 2ë‹¨ê³„ (í•œêµ­ì–´ ë„ë©”ì¸ ì ì‘)
experiment_name: mt5_xlsum_extreme_stage2_korean_adapted
description: "mT5 XL-Sum RTX 3090 + Unsloth ê·¹í•œ ìµœì í™” 2ë‹¨ê³„ - ë°°ì¹˜ 10 + ì‹œí€€ìŠ¤ 1280 + í•œêµ­ì–´ ë„ë©”ì¸ ì ì‘"

general:
  model_name: csebuetnlp/mT5_multilingual_XLSum
  data_path: data/
  train_path: data/train.csv
  val_path: data/dev.csv
  model_type: seq2seq
  name: mt5_xlsum_extreme_stage2_korean_adapted

model:
  architecture: mt5
  checkpoint: csebuetnlp/mT5_multilingual_XLSum

# ğŸ”¥ ê·¹í•œ ìµœì í™” í•œêµ­ì–´ ëŒ€í™” ìš”ì•½ ë„ë©”ì¸ ì ì‘ prefix
input_prefix: "dialogue summarization in korean: "

tokenizer:
  bos_token: <pad>
  eos_token: </s>
  encoder_max_len: 1280              # 2ë‹¨ê³„: 768â†’1280 ê·¹í•œ í™•ì¥
  decoder_max_len: 230               # 2ë‹¨ê³„: 150â†’230 í™•ì¥
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#PassportNumber#'
    - '#DateOfBirth#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'
    - '<ëŒ€í™”ì‹œì‘>'
    - '<ëŒ€í™”ì¢…ë£Œ>'
    - '<ì¤‘ìš”>'
    - '<ê²°ë¡ >'
    - '<summary>'
    - '</summary>'
    - '<dialogue>'
    - '</dialogue>'

# ğŸ”¥ RTX 3090 + Unsloth ê·¹í•œ ìµœì í™” 2ë‹¨ê³„ (í•œêµ­ì–´ ë„ë©”ì¸ ì ì‘)
training:
  do_eval: true
  do_train: true
  evaluation_strategy: steps
  eval_steps: 100                     # ë” ìì£¼ í‰ê°€
  
  # ğŸ”¥ 2ë‹¨ê³„ ê·¹í•œ ìµœì í™” ë°°ì¹˜ ì„¤ì •
  per_device_train_batch_size: 10     # 5â†’10 2ë°° ì¦ê°€
  per_device_eval_batch_size: 20      # 10â†’20 2ë°° ì¦ê°€
  gradient_accumulation_steps: 5      # ìœ íš¨ ë°°ì¹˜ 50 ìœ ì§€
  
  # âš¡ 2ë‹¨ê³„ ë„ë©”ì¸ ì ì‘ íŠ¹í™” í•™ìŠµ íŒŒë¼ë¯¸í„°
  num_train_epochs: 7                 # ìµœì í™”ë¡œ ë” ê¸´ ë„ë©”ì¸ ì ì‘
  learning_rate: 1.0e-04              # 2ë‹¨ê³„ ë” ë†’ì€ í•™ìŠµë¥ 
  lr_scheduler_type: cosine_with_restarts
  warmup_ratio: 0.02                  # ì§§ì€ ì›œì—…
  weight_decay: 0.0001                # ì„¸ë°€í•œ ì •ê·œí™”
  
  # ğŸ”¥ RTX 3090 + CUDA 12.2 + Unsloth ê·¹í•œ ìµœì í™”
  fp16: false                         # bf16 ì‚¬ìš©ìœ¼ë¡œ ë³€ê²½
  bf16: true                          # RTX 3090 + CUDA 12.2 ìµœì 
  tf32: true                          # Ampere ì•„í‚¤í…ì²˜ ìµœì í™”
  gradient_checkpointing: false       # Unsloth ìì²´ ìµœì í™”
  dataloader_num_workers: 34          # 48ì½”ì–´ì˜ 70% í™œìš©
  dataloader_pin_memory: true         # 251GB RAM í™œìš©
  dataloader_persistent_workers: true # ì›Œì»¤ ì¬ì‚¬ìš©
  group_by_length: true
  remove_unused_columns: false        # ì „ì²´ ì •ë³´ í™œìš©
  
  # ğŸ”¥ Unsloth íŠ¹í™” ì˜µí‹°ë§ˆì´ì € ì„¤ì •
  optim: adamw_8bit                   # Unsloth í˜¸í™˜ ì˜µí‹°ë§ˆì´ì €
  adam_beta1: 0.9
  adam_beta2: 0.95                    # Unsloth ì¶”ì²œê°’
  max_grad_norm: 0.3                  # Unslothì™€ í•¨ê»˜ ë‚®ì€ ê°’
  
  # ğŸ“Š ì„¸ë°€í•œ ëª¨ë‹ˆí„°ë§
  logging_steps: 25
  save_strategy: steps
  save_steps: 150
  save_total_limit: 10                # ë” ë§ì€ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
  load_best_model_at_end: true
  early_stopping_patience: 10         # ì¶©ë¶„í•œ ë„ë©”ì¸ ì ì‘ ì‹œê°„
  
  # ğŸ† 2ë‹¨ê³„ í•œêµ­ì–´ ë„ë©”ì¸ ì ì‘ íŠ¹í™” ìƒì„±
  predict_with_generate: true
  generation_num_beams: 14            # 8â†’14 ì†ë„ í–¥ìƒ
  generation_max_length: 230          # 150â†’230 ì¦ê°€
  generation_min_length: 20           # 15â†’20 ìµœì†Œ ê¸¸ì´ ì¦ê°€
  generation_length_penalty: 0.75     # ê¸¸ì´ íŒ¨ë„í‹° ì¡°ì •
  generation_no_repeat_ngram_size: 3  # ë°˜ë³µ ë°©ì§€ ìœ ì§€
  generation_do_sample: false         # ê²°ì •ë¡ ì  ìƒì„±
  generation_early_stopping: true     # ì¡°ê¸° ì¤‘ë‹¨ í™œì„±í™”
  
  report_to: wandb
  seed: 42

# ğŸ”¥ RTX 3090 + Unsloth ê·¹í•œ ìµœì í™” 2ë‹¨ê³„ QLoRA
qlora:
  use_unsloth: true                   # Unsloth í™œì„±í™”
  use_qlora: true
  lora_rank: 192                      # 64â†’192 3ë°° ì¦ê°€
  lora_alpha: 384                     # 128â†’384 3ë°° ì¦ê°€
  lora_dropout: 0.01                  # 0.03â†’0.01 ë“œë¡­ì•„ì›ƒ ê°ì†Œ
  target_modules: ["q", "k", "v", "o", "wi", "wo", "lm_head", "embed_tokens"]  # ëª¨ë“ˆ í™•ì¥
  load_in_4bit: true
  bnb_4bit_compute_dtype: "bfloat16"   # RTX 3090 + CUDA 12.2 ìµœì 
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true

wandb:
  entity: lyjune37-juneictlab
  project: nlp-5
  name: mt5_xlsum_extreme_stage2_korean_adapted
  tags: [mT5, XL-Sum, RTX3090, extreme_stage2, korean_adapted, Unsloth, batch10, seq1280]
  notes: "mT5 XL-Sum RTX 3090 + Unsloth ê·¹í•œ ìµœì í™” 2ë‹¨ê³„ - ë°°ì¹˜ 10, ì‹œí€€ìŠ¤ 1280, LoRA 192, í•œêµ­ì–´ ë„ë©”ì¸ ì ì‘"

# ğŸ† 2ë‹¨ê³„ ê·¹í•œ ìµœì í™” ìƒì„± ì„¤ì •
generation:
  max_length: 230                     # ë” ê¸´ ìš”ì•½ í—ˆìš©
  min_length: 20                      # ìµœì†Œ ê¸¸ì´ ì¦ê°€
  num_beams: 14                       # ë‹¤ì–‘í•œ í›„ë³´ íƒìƒ‰
  length_penalty: 0.75                # ê¸¸ì´ íŒ¨ë„í‹°
  no_repeat_ngram_size: 3             # ë°˜ë³µ ë°©ì§€
  early_stopping: true                # ì¡°ê¸° ì¤‘ë‹¨
  do_sample: false                    # ê²°ì •ë¡ ì  ìƒì„±
