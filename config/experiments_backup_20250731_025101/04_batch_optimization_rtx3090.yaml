# ë°°ì¹˜ ìµœì í™” RTX 3090 24GB ê·¹í•œ í™œìš© ì‹¤í—˜
experiment_name: batch_optimization_rtx3090_ultimate
description: "RTX 3090 24GB ë©”ëª¨ë¦¬ ìµœëŒ€ í™œìš© ë°°ì¹˜ ìµœì í™” - ê·¹í•œ ì„±ëŠ¥"

general:
  model_name: digit82/kobart-summarization
  data_path: data/
  train_path: data/train.csv
  val_path: data/dev.csv
  model_type: seq2seq
  name: batch_optimization_rtx3090_ultimate

model:
  architecture: bart
  checkpoint: digit82/kobart-summarization

# ğŸ¯ ë°°ì¹˜ ìµœì í™” prefix
input_prefix: ""

tokenizer:
  bos_token: <s>
  eos_token: </s>
  encoder_max_len: 1024              # ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
  decoder_max_len: 256               # ìµœëŒ€ ìš”ì•½ ê¸¸ì´
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#PassportNumber#'
    - '#DateOfBirth#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'

# ğŸš€ RTX 3090 24GB ë©”ëª¨ë¦¬ ê·¹í•œ í™œìš©
training:
  do_eval: true
  do_train: true
  evaluation_strategy: steps
  eval_steps: 100                     # ìì£¼ í‰ê°€
  
  # ğŸ”¥ RTX 3090 ê·¹í•œ ë°°ì¹˜ ìµœì í™”
  per_device_train_batch_size: 4      # ê¸´ ì‹œí€€ìŠ¤ + í° ë°°ì¹˜
  per_device_eval_batch_size: 8       # í‰ê°€ì‹œ ë” í° ë°°ì¹˜
  gradient_accumulation_steps: 8      # ìœ íš¨ ë°°ì¹˜ 32 (ê·¹ëŒ€)
  
  # ğŸ¯ ë°°ì¹˜ ìµœì í™” íŠ¹í™” í•™ìŠµë¥ 
  num_train_epochs: 6                 # ê¸´ í•™ìŠµ
  learning_rate: 4.0e-05              # í° ë°°ì¹˜ì— ì í•©í•œ í•™ìŠµë¥ 
  lr_scheduler_type: polynomial       # ì•ˆì •ì  ìŠ¤ì¼€ì¤„ë§
  warmup_ratio: 0.06                  # ê¸´ ì›œì—… (í° ë°°ì¹˜)
  weight_decay: 0.01
  
  # âš¡ RTX 3090 ê·¹í•œ ë©”ëª¨ë¦¬ í™œìš©
  fp16: false
  bf16: true                          # ì•ˆì •ì„± ìš°ì„ 
  gradient_checkpointing: true        # ë©”ëª¨ë¦¬ ì ˆì•½
  dataloader_num_workers: 16          # ìµœëŒ€ ë°ì´í„° ë¡œë”©
  dataloader_pin_memory: true
  group_by_length: true
  remove_unused_columns: false        # ëª¨ë“  ì •ë³´ í™œìš©
  
  # ğŸ“Š ë°°ì¹˜ ìµœì í™” ëª¨ë‹ˆí„°ë§
  logging_steps: 10                   # ë§¤ìš° ìì£¼ ë¡œê¹…
  save_strategy: steps
  save_steps: 100
  save_total_limit: 10                # ë§ì€ ì²´í¬í¬ì¸íŠ¸
  load_best_model_at_end: true
  early_stopping_patience: 10         # ì¶©ë¶„í•œ patience
  
  # ğŸ† ë°°ì¹˜ ìµœì í™” ìƒì„± ì„¤ì •
  predict_with_generate: true
  generation_num_beams: 12            # ê·¹í•œ ë¹” ì„œì¹˜
  generation_max_length: 256
  generation_min_length: 30
  generation_length_penalty: 0.8
  generation_no_repeat_ngram_size: 4
  generation_do_sample: false
  generation_early_stopping: true
  
  report_to: wandb
  seed: 42

# ğŸš€ ë°°ì¹˜ ìµœì í™” QLoRA (Unsloth í™œì„±í™”)
qlora:
  use_unsloth: true
  use_qlora: true
  lora_rank: 128                      # ìµœëŒ€ í‘œí˜„ë ¥
  lora_alpha: 256                     # ìµœëŒ€ ìŠ¤ì¼€ì¼ë§
  lora_dropout: 0.02                  # ìµœì†Œ ë“œë¡­ì•„ì›ƒ
  target_modules: [
    "q_proj", "k_proj", "v_proj", "out_proj",  # attention
    "fc1", "fc2",                               # feed-forward
    "lm_head"                                   # ì¶œë ¥ í—¤ë“œ
  ]
  load_in_4bit: true
  bnb_4bit_compute_dtype: "bfloat16"
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true

# ğŸ”§ ê³ ê¸‰ ë°°ì¹˜ ìµœì í™” ì„¤ì •
advanced_optimization:
  dataloader_drop_last: false         # ëª¨ë“  ë°ì´í„° í™œìš©
  eval_accumulation_steps: 4          # í‰ê°€ë„ ë°°ì¹˜ ìµœì í™”
  prediction_loss_only: false        # ì „ì²´ ì¶œë ¥ ê³„ì‚°

wandb:
  entity: lyjune37-juneictlab
  project: nlp-5
  name: batch_optimization_rtx3090_ultimate
  tags: [KoBART, RTX3090, batch_optimization, ultimate, large_batch, korean]
  notes: "RTX 3090 24GB ë©”ëª¨ë¦¬ ê·¹í•œ í™œìš© ë°°ì¹˜ ìµœì í™” - ìœ íš¨ ë°°ì¹˜ 32"

# Generation settings
generation:
  max_length: 256
  min_length: 5
  num_beams: 4
  no_repeat_ngram_size: 2
\ntraining:\n  eval_strategy: no
