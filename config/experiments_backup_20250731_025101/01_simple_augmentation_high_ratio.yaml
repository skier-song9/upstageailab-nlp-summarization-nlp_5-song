experiment_name: simple_augmentation_high_ratio
description: Simple data augmentation with higher ratio (40%)

# Inherit most settings from baseline
model:
  name: digit82/kobart-summarization
  architecture: kobart

# Tokenizer configuration  
tokenizer:
  encoder_max_len: 512
  decoder_max_len: 200
  bos_token: "<s>"
  eos_token: "</s>"
  special_tokens:
    - '#Person1#'
    - '#Person2#'
    - '#Person3#'
    - '#PhoneNumber#'
    - '#Address#'
    - '#DateOfBirth#'
    - '#PassportNumber#'
    - '#SSN#'
    - '#CardNumber#'
    - '#CarNumber#'
    - '#Email#'

# Data augmentation configuration - Higher ratio
data_augmentation:
  enabled: true
  augmentation_ratio: 0.4  # Augment 40% of the data (doubled)
  seed: 42
  
  # Synonym replacement settings
  synonym_replacement:
    enabled: true
    num_replacements: 5  # Replace more words
  
  # Sentence reorder settings
  sentence_reorder:
    enabled: true
    max_distance: 3  # Allow more reordering
  
  # Cache settings
  use_cache: true
  cache_dir: "outputs/augmented_data_cache"

# Training configuration - Adjusted for more data
training:
  num_train_epochs: 15  # Fewer epochs due to more data
  learning_rate: 1.0e-05
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 4
  gradient_checkpointing: true
  fp16: true
  warmup_steps: 20  # More warmup for larger dataset
  weight_decay: 0.01
  seed: 42
  
  # Evaluation settings
  evaluation_strategy: steps
  eval_steps: 500  # Less frequent due to more data
  save_steps: 500
  save_total_limit: 1
  logging_steps: 100
  
  # Early stopping
  early_stopping_patience: 3
  early_stopping_threshold: 0.001
  load_best_model_at_end: true
  
  # Other training settings
  dataloader_num_workers: 4
  dataloader_drop_last: false
  group_by_length: true
  predict_with_generate: true
  remove_unused_columns: true

# Generation configuration
generation:
  max_length: 200
  num_beams: 4
  no_repeat_ngram_size: 2
  early_stopping: true
  length_penalty: 1.0

# WandB configuration
wandb:
  name: "01_simple_augmentation_high_ratio"
  notes: "Simple augmentation with 40% ratio for maximum data diversity"
  tags: ["augmentation", "high_ratio", "synonym", "reorder", "kobart"]

# Generation settings
generation:
  max_length: 256
  min_length: 5
  num_beams: 4
  no_repeat_ngram_size: 2
\ntraining:\n  eval_strategy: no
