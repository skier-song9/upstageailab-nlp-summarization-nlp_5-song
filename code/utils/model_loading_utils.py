"""
HuggingFace ëª¨ë¸ ë¡œë”© ì•ˆì •ì„± ê°•í™” ìœ í‹¸ë¦¬í‹°

ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨ ì‹œì—ë„ ëª¨ë¸ ë¡œë”©ì´ ì‹¤íŒ¨í•˜ì§€ ì•Šë„ë¡ í•˜ëŠ” ê²¬ê³ í•œ ëª¨ë¸ ë¡œë”.
ë¡œì»¬ ìºì‹œ í™œìš©, ì¬ì‹œë„ ë¡œì§, ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì§€ì›ì„ í†µí•´ ì‹¤í—˜ ì—°ì†ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.

í†µí•© ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ ì ìš©:
- ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬: ìë™ ì¬ì‹œë„ ë° ë¡œì»¬ ìºì‹œ í™œìš©
- ëª¨ë¸ ë¡œë”© ì—ëŸ¬: ëŒ€ì•ˆ ëª¨ë¸ ë˜ëŠ” ì˜¤í”„ë¼ì¸ ëª¨ë“œë¡œ ëŒ€ì²´
- êµ¬ì¡°í™”ëœ ë¡œê¹…ìœ¼ë¡œ ëª¨ë¸ ë¡œë”© ì„±ëŠ¥ ë° ìƒíƒœ ì¶”ì 
"""

import os
import time
import logging
import socket
from pathlib import Path
from typing import Dict, Any, Optional, Union, Type
import torch
from transformers import (
    AutoModel, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM,
    PreTrainedModel, PreTrainedTokenizer
)
# í†µí•© ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ import
from .error_handling import (
    handle_error, log_structured, log_performance_metric,
    safe_execute, get_logging_manager
)

logger = logging.getLogger(__name__)


class RobustModelLoader:
    """
    ê²¬ê³ í•œ HuggingFace ëª¨ë¸ ë¡œë”
    
    ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨ ì‹œì—ë„ ëª¨ë¸ ë¡œë”©ì´ ì¤‘ë‹¨ë˜ì§€ ì•Šë„ë¡ í•˜ëŠ” Fail-Safe ëª¨ë¸ ë¡œë”.
    ë¡œì»¬ ìºì‹œ ìš°ì„  í™•ì¸, ì¬ì‹œë„ ë¡œì§, ì˜¤í”„ë¼ì¸ ëª¨ë“œ ìë™ ì „í™˜ì„ í†µí•´ ì‹¤í—˜ ì—°ì†ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    """
    def __init__(self, 
                 cache_dir: str = "./hf_cache", 
                 offline_fallback: bool = True,
                 max_retries: int = 3,
                 retry_delay: float = 1.0):
        """
        Args:
            cache_dir: HuggingFace ìºì‹œ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            offline_fallback: ë„¤íŠ¸ì›Œí¬ ì‹¤íŒ¨ ì‹œ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
            max_retries: ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
            retry_delay: ì¬ì‹œë„ ê°„ê²© (ì´ˆ)
        """
        self.cache_dir = Path(cache_dir).resolve()
        self.offline_fallback = offline_fallback
        self.max_retries = max_retries
        self.retry_delay = retry_delay
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
        os.environ['TRANSFORMERS_CACHE'] = str(self.cache_dir)
        os.environ['HF_HOME'] = str(self.cache_dir)
        
        logger.info(f"ğŸ—‚ï¸ HuggingFace ìºì‹œ ë””ë ‰í† ë¦¬: {self.cache_dir}")
    
    def safe_from_pretrained(self, 
                           model_class: Type[PreTrainedModel], 
                           model_name: str, 
                           **kwargs) -> PreTrainedModel:
        """
        ì•ˆì „í•œ ëª¨ë¸ ë¡œë”© (ë„¤íŠ¸ì›Œí¬ ì‹¤íŒ¨ ëŒ€ì‘)
        
        Args:
            model_class: ëª¨ë¸ í´ë˜ìŠ¤ (AutoModelForSeq2SeqLM, AutoTokenizer ë“±)
            model_name: ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ê²½ë¡œ
            **kwargs: from_pretrained()ì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
            
        Returns:
            ë¡œë”©ëœ ëª¨ë¸ ë˜ëŠ” í† í¬ë‚˜ì´ì €
        """
        # ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
        kwargs.setdefault('cache_dir', str(self.cache_dir))
        
        # 1ë‹¨ê³„: ë¡œì»¬ ìºì‹œ ìš°ì„  í™•ì¸
        if self._check_local_cache(model_name):
            logger.info(f"ğŸ“¦ ë¡œì»¬ ìºì‹œì—ì„œ {model_name} ë¡œë”© ì‹œë„")
            try:
                return self._try_load_from_cache(model_class, model_name, **kwargs)
            except Exception as e:
                logger.warning(f"ìºì‹œì—ì„œ ë¡œë”© ì‹¤íŒ¨: {e}")
        
        # 2ë‹¨ê³„: ë„¤íŠ¸ì›Œí¬ ë‹¤ìš´ë¡œë“œ ì‹œë„ (ì¬ì‹œë„ ë¡œì§)
        return self._try_network_download(model_class, model_name, **kwargs)
    
    def _check_local_cache(self, model_name: str) -> bool:
        """
        ë¡œì»¬ ìºì‹œì— ëª¨ë¸ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        
        Args:
            model_name: ëª¨ë¸ ì´ë¦„
            
        Returns:
            ìºì‹œ ì¡´ì¬ ì—¬ë¶€
        """
        try:
            # HuggingFace ìºì‹œ êµ¬ì¡° í™•ì¸
            cache_paths = [
                self.cache_dir / "models--" / model_name.replace("/", "--"),
                self.cache_dir / "hub" / f"models--{model_name.replace('/', '--')}",
                # ë‹¤ì–‘í•œ ìºì‹œ ê²½ë¡œ íŒ¨í„´ ì§€ì›
            ]
            
            for cache_path in cache_paths:
                if cache_path.exists() and any(cache_path.iterdir()):
                    logger.debug(f"âœ… ë¡œì»¬ ìºì‹œ ë°œê²¬: {cache_path}")
                    return True
            
            return False
            
        except Exception as e:
            logger.debug(f"ìºì‹œ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def _try_load_from_cache(self, 
                           model_class: Type[PreTrainedModel], 
                           model_name: str, 
                           **kwargs) -> PreTrainedModel:
        """
        ë¡œì»¬ ìºì‹œì—ì„œ ëª¨ë¸ ë¡œë”© ì‹œë„
        
        Args:
            model_class: ëª¨ë¸ í´ë˜ìŠ¤
            model_name: ëª¨ë¸ ì´ë¦„
            **kwargs: ì¶”ê°€ ì¸ì
            
        Returns:
            ë¡œë”©ëœ ëª¨ë¸
        """
        # ì˜¤í”„ë¼ì¸ ëª¨ë“œë¡œ ìºì‹œì—ì„œë§Œ ë¡œë”©
        kwargs_offline = kwargs.copy()
        kwargs_offline['local_files_only'] = True
        
        try:
            model = model_class.from_pretrained(model_name, **kwargs_offline)
            logger.info(f"âœ… ìºì‹œì—ì„œ {model_name} ë¡œë”© ì„±ê³µ")
            return model
        except Exception as e:
            logger.warning(f"ìºì‹œ ë¡œë”© ì‹¤íŒ¨: {e}")
            raise
    
    def _try_network_download(self, 
                            model_class: Type[PreTrainedModel], 
                            model_name: str, 
                            **kwargs) -> PreTrainedModel:
        """
        ë„¤íŠ¸ì›Œí¬ë¥¼ í†µí•œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œë„ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        
        Args:
            model_class: ëª¨ë¸ í´ë˜ìŠ¤
            model_name: ëª¨ë¸ ì´ë¦„
            **kwargs: ì¶”ê°€ ì¸ì
            
        Returns:
            ë¡œë”©ëœ ëª¨ë¸
        """
        last_exception = None
        
        for attempt in range(self.max_retries):
            try:
                logger.info(f"ğŸŒ ë„¤íŠ¸ì›Œí¬ì—ì„œ {model_name} ë‹¤ìš´ë¡œë“œ ì‹œë„ ({attempt + 1}/{self.max_retries})")
                
                # ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‚¬ì „ í…ŒìŠ¤íŠ¸
                if not self._test_huggingface_connectivity():
                    raise ConnectionError("HuggingFace Hub ì—°ê²° ì‹¤íŒ¨")
                
                # ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œë„
                model = model_class.from_pretrained(model_name, **kwargs)
                logger.info(f"âœ… ë„¤íŠ¸ì›Œí¬ì—ì„œ {model_name} ë‹¤ìš´ë¡œë“œ ì„±ê³µ")
                return model
                
            except Exception as e:
                last_exception = e
                logger.warning(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({attempt + 1}/{self.max_retries}): {e}")
                
                # ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ì¸ì§€ í™•ì¸
                if self._is_network_error(e):
                    if attempt < self.max_retries - 1:
                        wait_time = self.retry_delay * (2 ** attempt)  # ì§€ìˆ˜ ë°±ì˜¤í”„
                        logger.info(f"ì¬ì‹œë„ ì „ {wait_time:.1f}ì´ˆ ëŒ€ê¸°...")
                        time.sleep(wait_time)
                        continue
                else:
                    # ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ê°€ ì•„ë‹Œ ê²½ìš° ì¦‰ì‹œ ì‹¤íŒ¨
                    logger.error(f"ë„¤íŠ¸ì›Œí¬ ì™¸ ì—ëŸ¬ë¡œ ì¦‰ì‹œ ì‹¤íŒ¨: {e}")
                    break
        
        # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ì‹œ ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì‹œë„
        return self._handle_download_failure(model_class, model_name, last_exception, **kwargs)
    
    def _test_huggingface_connectivity(self) -> bool:
        """
        HuggingFace Hub ì—°ê²° í…ŒìŠ¤íŠ¸
        
        Returns:
            ì—°ê²° ê°€ëŠ¥ ì—¬ë¶€
        """
        try:
            # DNS í•´ê²° í…ŒìŠ¤íŠ¸
            socket.gethostbyname('huggingface.co')
            
            # í¬íŠ¸ ì—°ê²° í…ŒìŠ¤íŠ¸
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            result = sock.connect_ex(('huggingface.co', 443))
            sock.close()
            
            if result == 0:
                logger.debug("HuggingFace Hub ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                return True
            else:
                logger.debug(f"HuggingFace Hub í¬íŠ¸ ì—°ê²° ì‹¤íŒ¨: {result}")
                return False
                
        except Exception as e:
            logger.debug(f"HuggingFace Hub ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def _is_network_error(self, exception: Exception) -> bool:
        """
        ë„¤íŠ¸ì›Œí¬ ê´€ë ¨ ì—ëŸ¬ì¸ì§€ íŒë‹¨
        
        Args:
            exception: ë°œìƒí•œ ì˜ˆì™¸
            
        Returns:
            ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ì—¬ë¶€
        """
        error_str = str(exception).lower()
        network_keywords = [
            'connection', 'timeout', 'network', 'resolve', 'unreachable',
            'offline', 'internet', 'dns', 'socket', 'ssl', 'certificate',
            'http', 'https', '404', '503', '502', '500', 'requests'
        ]
        
        return any(keyword in error_str for keyword in network_keywords)
    
    def _handle_download_failure(self, 
                                model_class: Type[PreTrainedModel], 
                                model_name: str, 
                                last_exception: Exception,
                                **kwargs) -> PreTrainedModel:
        """
        ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì²˜ë¦¬ (ì˜¤í”„ë¼ì¸ ëª¨ë“œ ì‹œë„)
        
        Args:
            model_class: ëª¨ë¸ í´ë˜ìŠ¤
            model_name: ëª¨ë¸ ì´ë¦„
            last_exception: ë§ˆì§€ë§‰ ì˜ˆì™¸
            **kwargs: ì¶”ê°€ ì¸ì
            
        Returns:
            ë¡œë”©ëœ ëª¨ë¸
        """
        if not self.offline_fallback:
            logger.error(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ë° ì˜¤í”„ë¼ì¸ ëª¨ë“œ ë¹„í™œì„±í™”: {last_exception}")
            raise last_exception
        
        logger.warning("ğŸ”„ ì˜¤í”„ë¼ì¸ ëª¨ë“œë¡œ ì „í™˜í•˜ì—¬ ìºì‹œì—ì„œ ë¡œë”© ì‹œë„")
        
        try:
            return self._try_load_from_cache(model_class, model_name, **kwargs)
        except Exception as cache_error:
            logger.error(f"âŒ ìºì‹œì—ì„œë„ ë¡œë”© ì‹¤íŒ¨: {cache_error}")
            logger.error(f"ì›ë³¸ ë‹¤ìš´ë¡œë“œ ì—ëŸ¬: {last_exception}")
            
            # ê°€ì¥ êµ¬ì²´ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
            error_msg = f"""
ëª¨ë¸ ë¡œë”© ì™„ì „ ì‹¤íŒ¨: {model_name}
1. ë„¤íŠ¸ì›Œí¬ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {last_exception}
2. ë¡œì»¬ ìºì‹œ ë¡œë”© ì‹¤íŒ¨: {cache_error}

í•´ê²° ë°©ë²•:
- ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
- HuggingFace Hub ì ‘ê·¼ì„± í™•ì¸
- ìºì‹œ ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸: {self.cache_dir}
"""
            raise ConnectionError(error_msg)
    
    def get_cache_info(self) -> Dict[str, Any]:
        """
        ìºì‹œ ë””ë ‰í† ë¦¬ ì •ë³´ ë°˜í™˜
        
        Returns:
            ìºì‹œ ì •ë³´
        """
        try:
            cache_size = sum(f.stat().st_size for f in self.cache_dir.rglob('*') if f.is_file())
            cache_size_mb = cache_size / (1024 * 1024)
            
            model_count = len(list((self.cache_dir / "models--").glob("*"))) if (self.cache_dir / "models--").exists() else 0
            
            return {
                'cache_dir': str(self.cache_dir),
                'cache_size_mb': round(cache_size_mb, 2),
                'cached_models': model_count,
                'exists': self.cache_dir.exists()
            }
        except Exception as e:
            logger.warning(f"ìºì‹œ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {
                'cache_dir': str(self.cache_dir),
                'error': str(e)
            }


# ì „ì—­ RobustModelLoader ì¸ìŠ¤í„´ìŠ¤
_robust_model_loader = RobustModelLoader()


def safe_load_model(model_class: Type[PreTrainedModel], 
                   model_name: str, 
                   **kwargs) -> PreTrainedModel:
    """
    ì•ˆì „í•œ ëª¨ë¸ ë¡œë”© (ì „ì—­ í•¨ìˆ˜)
    
    ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨ ì‹œ ë¡œì»¬ ìºì‹œë¥¼ í™œìš©í•˜ì—¬ ëª¨ë¸ ë¡œë”©.
    ê¸°ì¡´ from_pretrained() í˜¸ì¶œì„ ì´ í•¨ìˆ˜ë¡œ êµì²´í•˜ì—¬ ê²¬ê³ ì„± í™•ë³´.
    
    í†µí•© ì—ëŸ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ ë¡œë”© ì—ëŸ¬ë¥¼ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ 
    ëŒ€ì•ˆ ëª¨ë¸ ë˜ëŠ” ì˜¤í”„ë¼ì¸ ëª¨ë“œë¡œ ì•ˆì „í•˜ê²Œ ëŒ€ì²´í•©ë‹ˆë‹¤.
    
    Args:
        model_class: ëª¨ë¸ í´ë˜ìŠ¤ (AutoModelForSeq2SeqLM, AutoTokenizer ë“±)
        model_name: ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ê²½ë¡œ
        **kwargs: from_pretrained()ì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
        
    Returns:
        ë¡œë”©ëœ ëª¨ë¸ ë˜ëŠ” í† í¬ë‚˜ì´ì €
        
    Example:
        # ê¸°ì¡´ ë°©ì‹
        model = AutoModelForSeq2SeqLM.from_pretrained("gogamza/kobart-base-v2")
        
        # ì•ˆì „í•œ ë°©ì‹  
        model = safe_load_model(AutoModelForSeq2SeqLM, "gogamza/kobart-base-v2")
    """
    # í†µí•© ì—ëŸ¬ ì²˜ë¦¬ë¡œ ëª¨ë¸ ë¡œë”© ë˜í•‘
    return safe_execute(
        func=_execute_model_loading,
        model_class=model_class,
        model_name=model_name,
        kwargs=kwargs,
        error_category="model_loading_errors",
        default_return=None  # ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨ ì‹œ None ë°˜í™˜
    )


def _execute_model_loading(model_class: Type[PreTrainedModel], 
                          model_name: str, 
                          kwargs: Dict[str, Any]) -> PreTrainedModel:
    """
    ì‹¤ì œ ëª¨ë¸ ë¡œë”© ì‹¤í–‰ (ë‚´ë¶€ í•¨ìˆ˜)
    """
    start_time = time.time()
    
    log_structured(
        level="INFO",
        message=f"ëª¨ë¸ ë¡œë”© ì‹œì‘: {model_name}",
        component="model_loading_utils",
        function="safe_load_model",
        metadata={"model_name": model_name, "model_class": model_class.__name__}
    )
    
    try:
        # RobustModelLoaderë¥¼ í†µí•œ ì•ˆì „í•œ ë¡œë”©
        result = _robust_model_loader.safe_from_pretrained(model_class, model_name, **kwargs)
        
        # ì„±ê³µ ì‹œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…
        loading_duration = time.time() - start_time
        log_performance_metric(
            metric_name="model_loading_duration",
            value=loading_duration,
            unit="seconds",
            component="model_loading_utils"
        )
        
        log_structured(
            level="INFO",
            message=f"ëª¨ë¸ ë¡œë”© ì™„ë£Œ: {model_name}",
            component="model_loading_utils",
            function="safe_load_model",
            metadata={
                "model_name": model_name,
                "loading_duration": loading_duration,
                "success": True
            }
        )
        
        return result
        
    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ í†µí•© ì—ëŸ¬ ì²˜ë¦¬ë¡œ ì „ë‹¬
        loading_duration = time.time() - start_time
        
        log_structured(
            level="ERROR",
            message=f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {model_name}",
            component="model_loading_utils",
            function="safe_load_model",
            metadata={
                "model_name": model_name,
                "loading_duration": loading_duration,
                "success": False,
                "error": str(e)
            }
        )
        
        # ì›ë³¸ ì—ëŸ¬ ì¬ë°œìƒ (safe_executeì—ì„œ ì²˜ë¦¬ë¨)
        raise e


def safe_load_tokenizer(model_name: str, **kwargs) -> PreTrainedTokenizer:
    """
    ì•ˆì „í•œ í† í¬ë‚˜ì´ì € ë¡œë”© (í¸ì˜ í•¨ìˆ˜)
    
    Args:
        model_name: ëª¨ë¸ ì´ë¦„ ë˜ëŠ” ê²½ë¡œ
        **kwargs: from_pretrained()ì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì
        
    Returns:
        ë¡œë”©ëœ í† í¬ë‚˜ì´ì €
    """
    return safe_load_model(AutoTokenizer, model_name, **kwargs)


def get_model_cache_info() -> Dict[str, Any]:
    """
    ëª¨ë¸ ìºì‹œ ì •ë³´ ì¡°íšŒ (ì „ì—­ í•¨ìˆ˜)
    
    Returns:
        ìºì‹œ ì •ë³´
    """
    return _robust_model_loader.get_cache_info()


def check_model_availability(model_name: str) -> Dict[str, bool]:
    """
    ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ì„± í™•ì¸
    
    Args:
        model_name: ëª¨ë¸ ì´ë¦„
        
    Returns:
        ì‚¬ìš© ê°€ëŠ¥ì„± ì •ë³´
    """
    return {
        'local_cache': _robust_model_loader._check_local_cache(model_name),
        'network': _robust_model_loader._test_huggingface_connectivity()
    }
