"""
μ‹¤ν— μ—°μ†μ„± λ³΄μ¥ μ²΄ν¬ν¬μΈνΈ μ‹μ¤ν…

μ»¨ν…μ΄λ„ μ¬μ‹μ‘μ΄λ‚ μμƒμΉ λ»ν• μ¤‘λ‹¨ μƒν™©μ—μ„ μ‹¤ν—μ„ μλ™μΌλ΅ λ³µκµ¬ν•  μ μλ”
μ²΄ν¬ν¬μΈνΈ λ° μƒνƒ μ¶”μ  μ‹μ¤ν…μ…λ‹λ‹¤. μ‹¤ν— λ‹¨κ³„λ³„ λ©”νƒ€λ°μ΄ν„° μ €μ¥κ³Ό μ¬μ‹μ‘ κ°€λ¥μ„±μ„ νλ‹¨ν•©λ‹λ‹¤.
"""

import os
import json
import time
import hashlib
import logging
import threading
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass, asdict
import torch
import psutil

logger = logging.getLogger(__name__)


@dataclass
class ExperimentCheckpoint:
    """μ‹¤ν— μ²΄ν¬ν¬μΈνΈ μ •λ³΄"""
    experiment_id: str
    experiment_name: str
    stage: str  # 'init', 'model_loaded', 'training_started', 'epoch_completed', 'completed', 'failed'
    timestamp: str
    config_hash: str
    system_info: Dict[str, Any]
    progress_info: Dict[str, Any]
    model_info: Dict[str, Any]
    training_metrics: Dict[str, Any]
    checksum: str
    
    def to_dict(self) -> Dict[str, Any]:
        """λ”•μ…”λ„λ¦¬λ΅ λ³€ν™"""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ExperimentCheckpoint':
        """λ”•μ…”λ„λ¦¬μ—μ„ μƒμ„±"""
        return cls(**data)


@dataclass
class SystemSnapshot:
    """μ‹μ¤ν… μƒνƒ μ¤λƒ…μƒ·"""
    cpu_percent: float
    memory_percent: float
    disk_usage_percent: float
    gpu_memory_used: Optional[float]
    gpu_utilization: Optional[float]
    container_id: Optional[str]
    python_version: str
    torch_version: str
    cuda_version: Optional[str]
    hostname: str
    timestamp: str


class ExperimentContinuityManager:
    """
    μ‹¤ν— μ—°μ†μ„± λ³΄μ¥ κ΄€λ¦¬μ
    
    μ»¨ν…μ΄λ„ μ¬μ‹μ‘μ΄λ‚ μμƒμΉ λ»ν• μ¤‘λ‹¨ μƒν™©μ—μ„ μ‹¤ν—μ„ μλ™μΌλ΅ λ³µκµ¬ν•  μ μλ”
    μ²΄ν¬ν¬μΈνΈ λ° μƒνƒ μ¶”μ  μ‹μ¤ν…μ„ μ κ³µν•©λ‹λ‹¤.
    """
    
    def __init__(self, 
                 checkpoint_dir: str = "./checkpoints/continuity",
                 auto_save_interval: int = 300,  # 5λ¶„
                 max_checkpoints: int = 10):
        """
        Args:
            checkpoint_dir: μ²΄ν¬ν¬μΈνΈ μ €μ¥ λ””λ ‰ν† λ¦¬
            auto_save_interval: μλ™ μ €μ¥ κ°„κ²© (μ΄)
            max_checkpoints: μµλ€ λ³΄κ΄€ν•  μ²΄ν¬ν¬μΈνΈ μ
        """
        self.checkpoint_dir = Path(checkpoint_dir)
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        self.auto_save_interval = auto_save_interval
        self.max_checkpoints = max_checkpoints
        
        self.current_experiment: Optional[ExperimentCheckpoint] = None
        self.auto_save_thread: Optional[threading.Thread] = None
        self.auto_save_running = False
        
        logger.info(f"π—‚οΈ μ‹¤ν— μ—°μ†μ„± κ΄€λ¦¬μ μ΄κΈ°ν™”: {self.checkpoint_dir}")
    
    def start_experiment(self, 
                        experiment_id: str,
                        experiment_name: str, 
                        config: Dict[str, Any]) -> ExperimentCheckpoint:
        """
        μƒλ΅μ΄ μ‹¤ν— μ‹μ‘ λ° μ΄κΈ° μ²΄ν¬ν¬μΈνΈ μƒμ„±
        
        Args:
            experiment_id: μ‹¤ν— κ³ μ  ID
            experiment_name: μ‹¤ν—λ…
            config: μ‹¤ν— μ„¤μ •
            
        Returns:
            μ΄κΈ° μ²΄ν¬ν¬μΈνΈ
        """
        logger.info(f"π€ μ‹¤ν— μ—°μ†μ„± μ¶”μ  μ‹μ‘: {experiment_name} (ID: {experiment_id})")
        
        # μ„¤μ • ν•΄μ‹ μƒμ„± (μ¬μ‹μ‘ μ‹ μ„¤μ • λ³€κ²½ κ°μ§€μ©)
        config_hash = self._calculate_config_hash(config)
        
        # μ‹μ¤ν… μ •λ³΄ μμ§‘
        system_info = self._collect_system_info()
        
        # μ΄κΈ° μ²΄ν¬ν¬μΈνΈ μƒμ„±
        checkpoint = ExperimentCheckpoint(
            experiment_id=experiment_id,
            experiment_name=experiment_name,
            stage='init',
            timestamp=datetime.now().isoformat(),
            config_hash=config_hash,
            system_info=system_info,
            progress_info={
                'total_epochs': config.get('training', {}).get('num_train_epochs', 0),
                'completed_epochs': 0,
                'current_step': 0,
                'total_steps': 0
            },
            model_info={
                'architecture': config.get('model', {}).get('architecture', 'unknown'),
                'checkpoint': config.get('model', {}).get('checkpoint', 'unknown'),
                'model_loaded': False
            },
            training_metrics={},
            checksum=''
        )
        
        # μ²΄ν¬μ„¬ κ³„μ‚°
        checkpoint.checksum = self._calculate_checkpoint_checksum(checkpoint)
        
        # μ²΄ν¬ν¬μΈνΈ μ €μ¥
        self._save_checkpoint(checkpoint)
        
        self.current_experiment = checkpoint
        
        # μλ™ μ €μ¥ μ¤λ λ“ μ‹μ‘
        self._start_auto_save()
        
        return checkpoint
    
    def update_experiment_stage(self, 
                               stage: str,
                               progress_info: Optional[Dict[str, Any]] = None,
                               model_info: Optional[Dict[str, Any]] = None,
                               training_metrics: Optional[Dict[str, Any]] = None) -> None:
        """
        μ‹¤ν— λ‹¨κ³„ μ—…λ°μ΄νΈ
        
        Args:
            stage: ν„μ¬ λ‹¨κ³„
            progress_info: μ§„ν–‰ μ •λ³΄
            model_info: λ¨λΈ μ •λ³΄
            training_metrics: ν•™μµ λ©”νΈλ¦­
        """
        if not self.current_experiment:
            logger.warning("μ§„ν–‰ μ¤‘μΈ μ‹¤ν—μ΄ μ—†μ–΄ λ‹¨κ³„ μ—…λ°μ΄νΈλ¥Ό κ±΄λ„λλ‹λ‹¤")
            return
        
        logger.debug(f"π“ μ‹¤ν— λ‹¨κ³„ μ—…λ°μ΄νΈ: {stage}")
        
        # ν„μ¬ μ²΄ν¬ν¬μΈνΈ λ³µμ‚¬ λ° μ—…λ°μ΄νΈ
        updated_checkpoint = ExperimentCheckpoint(
            experiment_id=self.current_experiment.experiment_id,
            experiment_name=self.current_experiment.experiment_name,
            stage=stage,
            timestamp=datetime.now().isoformat(),
            config_hash=self.current_experiment.config_hash,
            system_info=self._collect_system_info(),
            progress_info={**self.current_experiment.progress_info, **(progress_info or {})},
            model_info={**self.current_experiment.model_info, **(model_info or {})},
            training_metrics={**self.current_experiment.training_metrics, **(training_metrics or {})},
            checksum=''
        )
        
        # μ²΄ν¬μ„¬ μ¬κ³„μ‚°
        updated_checkpoint.checksum = self._calculate_checkpoint_checksum(updated_checkpoint)
        
        # μ²΄ν¬ν¬μΈνΈ μ €μ¥
        self._save_checkpoint(updated_checkpoint)
        
        self.current_experiment = updated_checkpoint
    
    def save_experiment_checkpoint(self, 
                                  stage: str,
                                  **kwargs) -> bool:
        """
        μ‹¤ν— μ²΄ν¬ν¬μΈνΈ μ €μ¥ (νΈμ ν•¨μ)
        
        Args:
            stage: ν„μ¬ λ‹¨κ³„
            **kwargs: μ¶”κ°€ μ •λ³΄
            
        Returns:
            μ €μ¥ μ„±κ³µ μ—¬λ¶€
        """
        try:
            self.update_experiment_stage(stage, **kwargs)
            return True
        except Exception as e:
            logger.error(f"μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ‹¤ν¨: {e}")
            return False
    
    def can_resume_experiment(self, experiment_id: str) -> Tuple[bool, Optional[ExperimentCheckpoint]]:
        """
        μ‹¤ν— μ¬μ‹μ‘ κ°€λ¥μ„± νλ‹¨
        
        Args:
            experiment_id: μ‹¤ν— ID
            
        Returns:
            (μ¬μ‹μ‘ κ°€λ¥ μ—¬λ¶€, μµμ‹  μ²΄ν¬ν¬μΈνΈ)
        """
        try:
            # μµμ‹  μ²΄ν¬ν¬μΈνΈ μ°ΎκΈ°
            latest_checkpoint = self._find_latest_checkpoint(experiment_id)
            
            if not latest_checkpoint:
                logger.info(f"μ‹¤ν— {experiment_id}μ μ²΄ν¬ν¬μΈνΈλ¥Ό μ°Ύμ„ μ μ—†μµλ‹λ‹¤")
                return False, None
            
            # μ²΄ν¬ν¬μΈνΈ λ¬΄κ²°μ„± κ²€μ¦
            if not self._verify_checkpoint_integrity(latest_checkpoint):
                logger.error(f"μ²΄ν¬ν¬μΈνΈ λ¬΄κ²°μ„± κ²€μ¦ μ‹¤ν¨: {experiment_id}")
                return False, None
            
            # μ¬μ‹μ‘ κ°€λ¥ν• λ‹¨κ³„μΈμ§€ ν™•μΈ
            resumable_stages = ['model_loaded', 'training_started', 'epoch_completed']
            
            if latest_checkpoint.stage in resumable_stages:
                logger.info(f"β… μ‹¤ν— {experiment_id} μ¬μ‹μ‘ κ°€λ¥ (λ‹¨κ³„: {latest_checkpoint.stage})")
                return True, latest_checkpoint
            elif latest_checkpoint.stage == 'completed':
                logger.info(f"μ‹¤ν— {experiment_id}λ” μ΄λ―Έ μ™„λ£λμ—μµλ‹λ‹¤")
                return False, latest_checkpoint
            elif latest_checkpoint.stage == 'failed':
                logger.warning(f"μ‹¤ν— {experiment_id}λ” μ‹¤ν¨ μƒνƒμ…λ‹λ‹¤")
                return False, latest_checkpoint
            else:
                logger.info(f"μ‹¤ν— {experiment_id}λ” μ¬μ‹μ‘ν•κΈ°μ—λ” λ„λ¬΄ μ΄κΈ° λ‹¨κ³„μ…λ‹λ‹¤ (λ‹¨κ³„: {latest_checkpoint.stage})")
                return False, latest_checkpoint
            
        except Exception as e:
            logger.error(f"μ¬μ‹μ‘ κ°€λ¥μ„± νλ‹¨ μ¤‘ μ¤λ¥: {e}")
            return False, None
    
    def resume_experiment(self, experiment_id: str) -> Optional[ExperimentCheckpoint]:
        """
        μ‹¤ν— μλ™ λ³µκµ¬
        
        Args:
            experiment_id: μ‹¤ν— ID
            
        Returns:
            λ³µκµ¬λ μ²΄ν¬ν¬μΈνΈ λλ” None
        """
        can_resume, checkpoint = self.can_resume_experiment(experiment_id)
        
        if not can_resume or not checkpoint:
            logger.error(f"μ‹¤ν— {experiment_id} λ³µκµ¬ λ¶κ°€λ¥")
            return None
        
        logger.info(f"π”„ μ‹¤ν— {experiment_id} μλ™ λ³µκµ¬ μ‹μ‘")
        logger.info(f"   λ³µκµ¬ μ§€μ : {checkpoint.stage}")
        logger.info(f"   λ§μ§€λ§‰ μ €μ¥: {checkpoint.timestamp}")
        
        # ν„μ¬ μ‹¤ν—μΌλ΅ μ„¤μ •
        self.current_experiment = checkpoint
        
        # μλ™ μ €μ¥ μ¤λ λ“ μ¬μ‹μ‘
        self._start_auto_save()
        
        # λ³µκµ¬ μ •λ³΄ λ΅κΉ…
        if checkpoint.progress_info.get('completed_epochs', 0) > 0:
            logger.info(f"   μ™„λ£λ μ—ν¬ν¬: {checkpoint.progress_info['completed_epochs']}/{checkpoint.progress_info['total_epochs']}")
        
        if checkpoint.training_metrics:
            latest_metrics = list(checkpoint.training_metrics.keys())[-1] if checkpoint.training_metrics else 'None'
            logger.info(f"   μµμ‹  λ©”νΈλ¦­: {latest_metrics}")
        
        logger.info(f"β… μ‹¤ν— {experiment_id} λ³µκµ¬ μ™„λ£")
        
        return checkpoint
    
    def finish_experiment(self, 
                         success: bool = True,
                         final_metrics: Optional[Dict[str, Any]] = None) -> None:
        """
        μ‹¤ν— μΆ…λ£ μ²λ¦¬
        
        Args:
            success: μ„±κ³µ μ—¬λ¶€
            final_metrics: μµμΆ… λ©”νΈλ¦­
        """
        if not self.current_experiment:
            logger.warning("μ§„ν–‰ μ¤‘μΈ μ‹¤ν—μ΄ μ—†μ–΄ μΆ…λ£ μ²λ¦¬λ¥Ό κ±΄λ„λλ‹λ‹¤")
            return
        
        stage = 'completed' if success else 'failed'
        
        logger.info(f"π μ‹¤ν— μΆ…λ£ μ²λ¦¬: {self.current_experiment.experiment_name} ({'μ„±κ³µ' if success else 'μ‹¤ν¨'})")
        
        self.update_experiment_stage(
            stage=stage,
            training_metrics=final_metrics or {}
        )
        
        # μλ™ μ €μ¥ μ¤‘μ§€
        self._stop_auto_save()
        
        # μ¤λλ μ²΄ν¬ν¬μΈνΈ μ •λ¦¬
        self._cleanup_old_checkpoints(self.current_experiment.experiment_id)
        
        self.current_experiment = None
    
    def list_experiments(self) -> List[Dict[str, Any]]:
        """
        μ €μ¥λ μ‹¤ν— λ©λ΅ λ°ν™
        
        Returns:
            μ‹¤ν— μ •λ³΄ λ¦¬μ¤νΈ
        """
        experiments = {}
        
        try:
            for checkpoint_file in self.checkpoint_dir.glob("*.json"):
                try:
                    with open(checkpoint_file, 'r', encoding='utf-8') as f:
                        checkpoint_data = json.load(f)
                    
                    exp_id = checkpoint_data['experiment_id']
                    
                    # μµμ‹  μ²΄ν¬ν¬μΈνΈλ§ μ μ§€
                    if exp_id not in experiments or checkpoint_data['timestamp'] > experiments[exp_id]['timestamp']:
                        experiments[exp_id] = {
                            'experiment_id': exp_id,
                            'experiment_name': checkpoint_data['experiment_name'],
                            'stage': checkpoint_data['stage'],
                            'timestamp': checkpoint_data['timestamp'],
                            'progress': checkpoint_data.get('progress_info', {}),
                            'model': checkpoint_data.get('model_info', {}).get('architecture', 'unknown')
                        }
                        
                except Exception as e:
                    logger.debug(f"μ²΄ν¬ν¬μΈνΈ νμΌ μ½κΈ° μ‹¤ν¨: {checkpoint_file} - {e}")
                    continue
            
            return list(experiments.values())
            
        except Exception as e:
            logger.error(f"μ‹¤ν— λ©λ΅ μ΅°ν μ‹¤ν¨: {e}")
            return []
    
    def _calculate_config_hash(self, config: Dict[str, Any]) -> str:
        """μ„¤μ • ν•΄μ‹ κ³„μ‚°"""
        config_str = json.dumps(config, sort_keys=True, default=str)
        return hashlib.md5(config_str.encode()).hexdigest()
    
    def _calculate_checkpoint_checksum(self, checkpoint: ExperimentCheckpoint) -> str:
        """μ²΄ν¬ν¬μΈνΈ μ²΄ν¬μ„¬ κ³„μ‚°"""
        # checksum ν•„λ“λ¥Ό μ μ™Έν• λ‚λ¨Έμ§€ λ°μ΄ν„°λ΅ μ²΄ν¬μ„¬ κ³„μ‚°
        checkpoint_dict = checkpoint.to_dict()
        checkpoint_dict.pop('checksum', None)
        
        checkpoint_str = json.dumps(checkpoint_dict, sort_keys=True, default=str)
        return hashlib.sha256(checkpoint_str.encode()).hexdigest()
    
    def _collect_system_info(self) -> Dict[str, Any]:
        """μ‹μ¤ν… μ •λ³΄ μμ§‘"""
        try:
            # κΈ°λ³Έ μ‹μ¤ν… μ •λ³΄
            system_info = {
                'cpu_percent': psutil.cpu_percent(interval=1),
                'memory_percent': psutil.virtual_memory().percent,
                'disk_usage_percent': psutil.disk_usage('.').percent,
                'hostname': os.uname().nodename if hasattr(os, 'uname') else 'unknown',
                'python_version': f"{sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}",
                'torch_version': torch.__version__,
                'timestamp': datetime.now().isoformat()
            }
            
            # GPU μ •λ³΄ (κ°€λ¥ν• κ²½μ°)
            if torch.cuda.is_available():
                try:
                    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
                    gpu_memory_used = torch.cuda.memory_allocated(0) / (1024**3)
                    system_info.update({
                        'cuda_version': torch.version.cuda,
                        'gpu_memory_total_gb': gpu_memory,
                        'gpu_memory_used_gb': gpu_memory_used,
                        'gpu_memory_percent': (gpu_memory_used / gpu_memory) * 100
                    })
                except:
                    pass
            
            # μ»¨ν…μ΄λ„ μ •λ³΄ (κ°€λ¥ν• κ²½μ°)
            try:
                if os.path.exists('/.dockerenv'):
                    with open('/proc/self/cgroup', 'r') as f:
                        cgroup_content = f.read()
                        if 'docker' in cgroup_content:
                            # Docker μ»¨ν…μ΄λ„ ID μ¶”μ¶ μ‹λ„
                            for line in cgroup_content.split('\n'):
                                if 'docker' in line and '/' in line:
                                    container_id = line.split('/')[-1][:12]  # μ²μ 12μλ¦¬λ§
                                    system_info['container_id'] = container_id
                                    break
            except:
                pass
            
            return system_info
            
        except Exception as e:
            logger.debug(f"μ‹μ¤ν… μ •λ³΄ μμ§‘ μ¤‘ μ¤λ¥: {e}")
            return {
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _save_checkpoint(self, checkpoint: ExperimentCheckpoint) -> bool:
        """μ²΄ν¬ν¬μΈνΈ μ €μ¥"""
        try:
            # νμΌλ…: experiment_id_timestamp.json
            timestamp_str = checkpoint.timestamp.replace(':', '-').replace('.', '-')
            filename = f"{checkpoint.experiment_id}_{timestamp_str}.json"
            filepath = self.checkpoint_dir / filename
            
            # JSON μ €μ¥
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(checkpoint.to_dict(), f, indent=2, ensure_ascii=False, default=str)
            
            logger.debug(f"μ²΄ν¬ν¬μΈνΈ μ €μ¥λ¨: {filepath}")
            return True
            
        except Exception as e:
            logger.error(f"μ²΄ν¬ν¬μΈνΈ μ €μ¥ μ‹¤ν¨: {e}")
            return False
    
    def _find_latest_checkpoint(self, experiment_id: str) -> Optional[ExperimentCheckpoint]:
        """μµμ‹  μ²΄ν¬ν¬μΈνΈ μ°ΎκΈ°"""
        try:
            latest_checkpoint = None
            latest_timestamp = None
            
            pattern = f"{experiment_id}_*.json"
            for checkpoint_file in self.checkpoint_dir.glob(pattern):
                try:
                    with open(checkpoint_file, 'r', encoding='utf-8') as f:
                        checkpoint_data = json.load(f)
                    
                    timestamp = checkpoint_data['timestamp']
                    
                    if latest_timestamp is None or timestamp > latest_timestamp:
                        latest_timestamp = timestamp
                        latest_checkpoint = ExperimentCheckpoint.from_dict(checkpoint_data)
                        
                except Exception as e:
                    logger.debug(f"μ²΄ν¬ν¬μΈνΈ νμΌ μ½κΈ° μ‹¤ν¨: {checkpoint_file} - {e}")
                    continue
            
            return latest_checkpoint
            
        except Exception as e:
            logger.error(f"μµμ‹  μ²΄ν¬ν¬μΈνΈ μ°ΎκΈ° μ‹¤ν¨: {e}")
            return None
    
    def _verify_checkpoint_integrity(self, checkpoint: ExperimentCheckpoint) -> bool:
        """μ²΄ν¬ν¬μΈνΈ λ¬΄κ²°μ„± κ²€μ¦"""
        try:
            # μ²΄ν¬μ„¬ μ¬κ³„μ‚° λ° λΉ„κµ
            calculated_checksum = self._calculate_checkpoint_checksum(checkpoint)
            
            if calculated_checksum != checkpoint.checksum:
                logger.error(f"μ²΄ν¬ν¬μΈνΈ μ²΄ν¬μ„¬ λ¶μΌμΉ: μμƒ {checkpoint.checksum}, μ‹¤μ  {calculated_checksum}")
                return False
            
            # ν•„μ ν•„λ“ ν™•μΈ
            required_fields = ['experiment_id', 'experiment_name', 'stage', 'timestamp']
            for field in required_fields:
                if not getattr(checkpoint, field, None):
                    logger.error(f"μ²΄ν¬ν¬μΈνΈ ν•„μ ν•„λ“ λ„λ½: {field}")
                    return False
            
            return True
            
        except Exception as e:
            logger.error(f"μ²΄ν¬ν¬μΈνΈ λ¬΄κ²°μ„± κ²€μ¦ μ‹¤ν¨: {e}")
            return False
    
    def _start_auto_save(self) -> None:
        """μλ™ μ €μ¥ μ¤λ λ“ μ‹μ‘"""
        if self.auto_save_thread and self.auto_save_thread.is_alive():
            return
        
        self.auto_save_running = True
        self.auto_save_thread = threading.Thread(target=self._auto_save_worker, daemon=True)
        self.auto_save_thread.start()
        
        logger.debug(f"μλ™ μ €μ¥ μ¤λ λ“ μ‹μ‘ (κ°„κ²©: {self.auto_save_interval}μ΄)")
    
    def _stop_auto_save(self) -> None:
        """μλ™ μ €μ¥ μ¤λ λ“ μ¤‘μ§€"""
        self.auto_save_running = False
        
        if self.auto_save_thread and self.auto_save_thread.is_alive():
            self.auto_save_thread.join(timeout=5)
        
        logger.debug("μλ™ μ €μ¥ μ¤λ λ“ μ¤‘μ§€")
    
    def _auto_save_worker(self) -> None:
        """μλ™ μ €μ¥ μ›μ»¤"""
        while self.auto_save_running:
            try:
                time.sleep(self.auto_save_interval)
                
                if self.current_experiment and self.auto_save_running:
                    # ν„μ¬ μƒνƒλ΅ μ²΄ν¬ν¬μΈνΈ μ—…λ°μ΄νΈ (λ‹¨κ³„λ” μ μ§€)
                    self.update_experiment_stage(
                        stage=self.current_experiment.stage + '_auto_save',
                    )
                    
            except Exception as e:
                logger.debug(f"μλ™ μ €μ¥ μ¤‘ μ¤λ¥: {e}")
    
    def _cleanup_old_checkpoints(self, experiment_id: str) -> None:
        """μ¤λλ μ²΄ν¬ν¬μΈνΈ μ •λ¦¬"""
        try:
            pattern = f"{experiment_id}_*.json"
            checkpoint_files = list(self.checkpoint_dir.glob(pattern))
            
            # νμΌμ„ νƒ€μ„μ¤νƒ¬ν”„ μμΌλ΅ μ •λ ¬ (μµμ‹ μ)
            checkpoint_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)
            
            # μµλ€ κ°μλ¥Ό μ΄κ³Όν•λ” νμΌλ“¤ μ‚­μ 
            if len(checkpoint_files) > self.max_checkpoints:
                files_to_delete = checkpoint_files[self.max_checkpoints:]
                
                for file_to_delete in files_to_delete:
                    try:
                        file_to_delete.unlink()
                        logger.debug(f"μ¤λλ μ²΄ν¬ν¬μΈνΈ μ‚­μ : {file_to_delete}")
                    except Exception as e:
                        logger.debug(f"μ²΄ν¬ν¬μΈνΈ μ‚­μ  μ‹¤ν¨: {file_to_delete} - {e}")
            
        except Exception as e:
            logger.debug(f"μ²΄ν¬ν¬μΈνΈ μ •λ¦¬ μ¤‘ μ¤λ¥: {e}")


# μ „μ—­ ExperimentContinuityManager μΈμ¤ν„΄μ¤
_experiment_continuity_manager = ExperimentContinuityManager()


def get_continuity_manager() -> ExperimentContinuityManager:
    """μ „μ—­ μ—°μ†μ„± κ΄€λ¦¬μ λ°ν™"""
    return _experiment_continuity_manager


def save_experiment_checkpoint(stage: str, **kwargs) -> bool:
    """
    μ‹¤ν— μ²΄ν¬ν¬μΈνΈ μ €μ¥ (μ „μ—­ ν•¨μ)
    
    Args:
        stage: ν„μ¬ λ‹¨κ³„
        **kwargs: μ¶”κ°€ μ •λ³΄
        
    Returns:
        μ €μ¥ μ„±κ³µ μ—¬λ¶€
    """
    return _experiment_continuity_manager.save_experiment_checkpoint(stage, **kwargs)


def can_resume_experiment(experiment_id: str) -> Tuple[bool, Optional[ExperimentCheckpoint]]:
    """
    μ‹¤ν— μ¬μ‹μ‘ κ°€λ¥μ„± νλ‹¨ (μ „μ—­ ν•¨μ)
    
    Args:
        experiment_id: μ‹¤ν— ID
        
    Returns:
        (μ¬μ‹μ‘ κ°€λ¥ μ—¬λ¶€, μµμ‹  μ²΄ν¬ν¬μΈνΈ)
    """
    return _experiment_continuity_manager.can_resume_experiment(experiment_id)


def resume_experiment(experiment_id: str) -> Optional[ExperimentCheckpoint]:
    """
    μ‹¤ν— μλ™ λ³µκµ¬ (μ „μ—­ ν•¨μ)
    
    Args:
        experiment_id: μ‹¤ν— ID
        
    Returns:
        λ³µκµ¬λ μ²΄ν¬ν¬μΈνΈ λλ” None
    """
    return _experiment_continuity_manager.resume_experiment(experiment_id)
