# NLP ëŒ€í™” ìš”ì•½ í”„ë¡œì íŠ¸ (lyj ë¸Œëœì¹˜)

í•œêµ­ì–´ ëŒ€í™”ë¥¼ ìë™ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.

## ğŸ¯ í”„ë¡œì íŠ¸ ëª©í‘œ

- ë² ì´ìŠ¤ë¼ì¸ ì„±ëŠ¥(ROUGE-F1 47.12%)ì„ 55-60%ë¡œ í–¥ìƒ
- íŠ¹ìˆ˜ í† í°(PII, í™”ì ì •ë³´) ë³´ì¡´ìœ¨ ê·¹ëŒ€í™”
- ì‹¤ìš©ì ì¸ ì¶”ë¡  ì†ë„ ìœ ì§€

## ğŸ“Š ëª©í‘œ ì„±ëŠ¥ (ì˜ˆìƒì¹˜)

> âš ï¸ **ì£¼ì˜**: ì•„ë˜ ì„±ëŠ¥ ìˆ˜ì¹˜ëŠ” ì•„ì§ ì‹¤ì œë¡œ ë‹¬ì„±ë˜ì§€ ì•Šì€ **ëª©í‘œì¹˜**ì…ë‹ˆë‹¤. ì‹¤ì œ ì‹¤í—˜ í›„ ì—…ë°ì´íŠ¸ ì˜ˆì •ì…ë‹ˆë‹¤.

| ëª¨ë¸ | ROUGE-1 | ROUGE-2 | ROUGE-L | ROUGE-F1 í‰ê·  | ìƒíƒœ |
|------|---------|---------|---------|---------------|------|
| ë² ì´ìŠ¤ë¼ì¸ | 0.5123 | 0.2845 | 0.4756 | 0.4712 | âœ… í™•ì¸ë¨ |
| 1ì°¨ ê°œì„  (ëª©í‘œ) | 0.5456 | 0.3123 | 0.5089 | 0.5056 | ğŸ¯ ëª©í‘œ |
| 2ì°¨ í†µí•© (ëª©í‘œ) | 0.5821 | 0.3456 | 0.5234 | 0.5504 | ğŸ¯ ëª©í‘œ |
| Solar ì•™ìƒë¸” (ëª©í‘œ) | 0.5989 | 0.3612 | 0.5401 | 0.5667 | ğŸ¯ ëª©í‘œ |

## ğŸ¤– ì§€ì› ëª¨ë¸

í”„ë¡œì íŠ¸ì—ì„œ ì§€ì›í•˜ëŠ” ëª¨ë¸ ëª©ë¡:

| ëª¨ë¸ëª… | ì„¤ëª… | íŠ¹ì§• | ì‚¬ìš©ë²• |
|-----------|------|------|--------|
| **eenzeenee/xsum-t5-1.7b** | í•œêµ­ì–´ ìš”ì•½ T5 ëª¨ë¸ | - 1.7B íŒŒë¼ë¯¸í„°<br>- í•œêµ­ì–´ ìµœì í™”<br>- ìë™ prefix ì²˜ë¦¬ | `./run_eenzeenee_experiment.sh` |
| digit82/kobart-summarization | KoBART ìš”ì•½ ëª¨ë¸ | - BART ì•„í‚¤í…ì²˜<br>- í•œêµ­ì–´ ì§€ì› | ì „ìš© ìŠ¤í¬ë¦½íŠ¸ |
| google/mt5-* | Multilingual T5 | - ë‹¤êµ­ì–´ ì§€ì›<br>- T5 ì•„í‚¤í…ì²˜ | `--config-section mt5_base` |
| google/flan-t5-* | FLAN-T5 | - ì¸ìŠ¤íŠ¸ëŸ­ì…˜ íŠ¤ë‹<br>- ì˜ì–´ ìµœì í™” | `--config-section flan_t5_base` |

### eenzeenee ëª¨ë¸ íŠ¹ì§•

- **ìë™ Prefix ì²˜ë¦¬**: 'summarize: ' prefixê°€ ëª¨ë“  ì…ë ¥ì— ìë™ìœ¼ë¡œ ì¶”ê°€
- **í•œêµ­ì–´ ìµœì í™”**: í•œêµ­ì–´ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‚¬ì „ í•™ìŠµ
- **T5 ì•„í‚¤í…ì²˜**: sequence-to-sequence ëª¨ë¸ë¡œ ìš”ì•½ ì‘ì—…ì— ìµœì í™”
- **ê¸°ë³¸ ì„¤ì •**: ë°°ì¹˜ í¬ê¸° 8, ì…ë ¥ ê¸¸ì´ 512, ì¶œë ¥ ê¸¸ì´ 200

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. í™˜ê²½ ì„¤ì •

```bash
# Conda í™˜ê²½ ìƒì„±
conda create -n nlp-sum python=3.11
conda activate nlp-sum

# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# KoNLPy ì„¤ì • (ì„ íƒì‚¬í•­)
bash scripts/install_konlpy.sh
```

### 2. eenzeenee ëª¨ë¸ ì‹¤í—˜ ì‹¤í–‰

```bash
# ë‹¨ì¼ eenzeenee ëª¨ë¸ ì‹¤í—˜
./run_eenzeenee_experiment.sh

# ì‹¤ì œ í•™ìŠµ ì‹¤í–‰ (ì„¤ì • í›„)
EENZEENEE_RUN_ACTUAL=true ./run_eenzeenee_experiment.sh

# ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ì‹¤í—˜ (eenzeenee í¬í•¨)
./run_multi_model_experiments.sh
```

### 3. ìµœì¢… ëª¨ë¸ë¡œ ì¶”ë¡ 

```bash
# ê°„ë‹¨í•œ ì¶”ë¡  (Fine-tuned ëª¨ë¸ë§Œ)
python final_submission/run_final_inference.py

# Solar API ì•™ìƒë¸” (ìµœê³  ì„±ëŠ¥)
export UPSTAGE_API_KEY="your-api-key"
python final_submission/run_final_inference.py --use_ensemble
```

### 4. ì œì¶œ íŒŒì¼ í™•ì¸

```bash
# í˜•ì‹ ê²€ì¦
python scripts/validate_submission.py \
    --submission final_submission/submission.csv \
    --sample sample_submission.csv
```

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
nlp-sum-lyj/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ core/               # í•µì‹¬ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ data_augmentation/  # ë°ì´í„° ì¦ê°•
â”‚   â”œâ”€â”€ ensemble/           # Solar API ì•™ìƒë¸”
â”‚   â”œâ”€â”€ models/             # ëª¨ë¸ ê´€ë ¨ (ê°€ì¤‘ì¹˜ ì†ì‹¤ ë“±)
â”‚   â”œâ”€â”€ postprocessing/     # í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ preprocessing/      # ì „ì²˜ë¦¬ (í…ìŠ¤íŠ¸ ì •ê·œí™”)
â”‚   â”œâ”€â”€ utils/              # ìœ í‹¸ë¦¬í‹°
â”‚   â””â”€â”€ trainer.py          # í•™ìŠµ ëª¨ë“ˆ
â”œâ”€â”€ config/
â”‚   â””â”€â”€ experiments/        # ì‹¤í—˜ ì„¤ì • YAML íŒŒì¼
â”œâ”€â”€ data/                   # ë°ì´í„° íŒŒì¼
â”œâ”€â”€ docs/                   # ë¬¸ì„œ
â”œâ”€â”€ final_submission/       # ìµœì¢… ì œì¶œ ê´€ë ¨
â”œâ”€â”€ logs/                   # ì‹¤í—˜ ë¡œê·¸
â”œâ”€â”€ models/                 # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”œâ”€â”€ outputs/                # ì‹¤í—˜ ê²°ê³¼
â””â”€â”€ scripts/                # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
```

## ğŸ”§ ì£¼ìš” ê¸°ëŠ¥

### 1. ìë™í™” ì‹¤í—˜ ì‹œìŠ¤í…œ
- YAML ê¸°ë°˜ ì‹¤í—˜ ì„¤ì •
- ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì 
- WandB í†µí•© ëª¨ë‹ˆí‡ë§
- **WandB Sweep**: ë² ì´ì§€ì•ˆ ìµœì í™” ë° Hyperband ì¡°ê¸° ì¢…ë£Œ âœ…

### 2. ë°ì´í„° ì¦ê°•
- ë™ì˜ì–´ ì¹˜í™˜
- ë¬¸ì¥ ìˆœì„œ ë³€ê²½
- ë°±íŠ¸ëœìŠ¬ë ˆì´ì…˜ (í•œâ†’ì˜â†’í•œ)

### 3. íŠ¹ìˆ˜ í† í° ê°€ì¤‘ì¹˜
- PII í† í° 2.5ë°° ê°€ì¤‘ì¹˜
- í™”ì í† í° 2.0ë°° ê°€ì¤‘ì¹˜
- ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì •

### 4. í›„ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
- ì¤‘ë³µ ì œê±°
- ê¸¸ì´ ìµœì í™”
- íŠ¹ìˆ˜ í† í° ê²€ì¦

### 5. Solar API ì•™ìƒë¸” (ì•ˆì •ì„± ê°•í™”)
- Fine-tuned ëª¨ë¸ + Solar API
- **ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”**: ì§€ìˆ˜ ë°±ì˜¤í”„ ì¬ì‹œë„, íƒ€ì„ì•„ì›ƒ ì¦ê°€, ì—°ê²° í…ŒìŠ¤íŠ¸
- **í´ë°± ë©”ì»¤ë‹ˆì¦˜**: Solar API ì‹¤íŒ¨ ì‹œ Fine-tuned ëª¨ë¸ë¡œ ìë™ ì „í™˜
- **ë¹„ìš© ìµœì í™”**: ìºì‹±, rate limiting, ì—°ì† ì‹¤íŒ¨ ëª¨ë‹ˆí„°ë§
- ë™ì  ê°€ì¤‘ì¹˜ ê²°í•©
- **í˜„ì¬ ìƒíƒœ**: ì½”ë“œ êµ¬í˜„ ì™„ë£Œ, API í‚¤ í•„ìš”

## ğŸš€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (WandB Sweep)

### ë² ì´ì§€ì•ˆ ìµœì í™” ì‹¤í–‰
```bash
# 50ê°œ ì‹¤í—˜ìœ¼ë¡œ ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì°¾ê¸°
python code/sweep_runner.py \
  --base-config config/base_config.yaml \
  --sweep-config hyperparameter_sweep \
  --count 50

# ëª¨ë¸ ë¹„êµ ì‹¤í—˜
python code/sweep_runner.py \
  --base-config config/base_config.yaml \
  --sweep-config model_comparison_sweep \
  --count 20
```
âœ… **ì¥ì **: WandB Sweep ë² ì´ì§€ì•ˆ ìµœì í™” + WandB ì‹¤í—˜ ì¶”ì  ì™„ì „ í†µí•©

## ğŸ“¨ ì‹¤í—˜ ì¬í˜„

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
# 1. ë² ì´ìŠ¤ë¼ì¸ ì¬í˜„
python code/auto_experiment_runner.py \
    --config config/experiments/00_baseline_reproduction.yaml

# 2. 1ì°¨ ê°œì„  ì‹¤í—˜
./scripts/experiments/run_auto_experiments.sh phase1

# 3. 2ì°¨ í†µí•© ì‹¤í—˜
./run_phase2_experiments.sh

# 4. Solar ì•™ìƒë¸” (ì„ íƒì‚¬í•­)
./run_solar_ensemble.sh
```

### ê°œë³„ ì‹¤í—˜ ì‹¤í–‰

```bash
# íŠ¹ì • ì‹¤í—˜ë§Œ ì‹¤í–‰
python code/auto_experiment_runner.py \
    --config config/experiments/10_combination_phase2/10c_all_optimizations.yaml
```

## ğŸ› ï¸ ê³ ê¸‰ ì„¤ì •

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
```yaml
# configì—ì„œ ì¡°ì •
training:
  per_device_train_batch_size: 8  # ì¤„ì´ê¸°
  gradient_accumulation_steps: 8   # ëŠ˜ë¦¬ê¸°
  fp16: true                       # í•„ìˆ˜
  gradient_checkpointing: true     # í•„ìˆ˜
```

### ì»¤ìŠ¤í…€ í›„ì²˜ë¦¬
```python
from postprocessing import PostProcessingPipeline, CustomProcessor

pipeline = PostProcessingPipeline()
pipeline.add_processor(CustomProcessor())
```

### WandB ì„¤ì •
```bash
# ë¡œê·¸ì¸
wandb login

# í”„ë¡œì íŠ¸ ì„¤ì •
export WANDB_PROJECT="nlp-summarization"
export WANDB_ENTITY="your-team"
```

## ğŸ“ ê³„íšëœ ê°œì„ ì‚¬í•­ ìƒì„¸

> ğŸ’¡ **ì•ˆë‚´**: ì•„ë˜ëŠ” ê³„íšëœ ê°œì„  ë°©ë²•ë“¤ì´ë©°, ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒì¹˜ì…ë‹ˆë‹¤. ì‹¤ì œ êµ¬í˜„ í›„ ê²°ê³¼ê°€ ì—…ë°ì´íŠ¸ë  ì˜ˆì •ì…ë‹ˆë‹¤.

### 1. ë°ì´í„° ì¦ê°• (ì˜ˆìƒ: ROUGE +2-3%)
- SynonymReplacement: WordNet ê¸°ë°˜ ë™ì˜ì–´ ì¹˜í™˜ âœ… êµ¬í˜„ ì™„ë£Œ
- SentenceReorder: í™”ì ìˆœì„œ ë³´ì¡´í•˜ë©° ì¬ë°°ì—´ âœ… êµ¬í˜„ ì™„ë£Œ
- BackTranslation: Google Translate API í™œìš© âœ… êµ¬í˜„ ì™„ë£Œ

### 2. í•™ìŠµ ìµœì í™” (ì˜ˆìƒ: ROUGE +1-2%)
- Cosine Annealing with Warm Restarts âœ… ì„¤ì • ì¤€ë¹„
- Learning Rate: 3e-5 â†’ 5e-5 ğŸ¯ ì‹¤í—˜ ì˜ˆì •
- Gradient Accumulation ìµœì í™” âœ… ì„¤ì • ì¤€ë¹„

### 3. íŠ¹ìˆ˜ í† í° ì²˜ë¦¬ (ì˜ˆìƒ: ROUGE +2-3%)
- Weighted Cross Entropy Loss âœ… êµ¬í˜„ ì™„ë£Œ
- ë™ì  ê°€ì¤‘ì¹˜ ìŠ¤ì¼€ì¤„ë§ âœ… êµ¬í˜„ ì™„ë£Œ
- í† í°ë³„ ì†ì‹¤ ì¶”ì  ğŸ¯ ì¶”ê°€ ê°œë°œ í•„ìš”

### 4. ë¹” ì„œì¹˜ ê°œì„  (ì˜ˆìƒ: ROUGE +1%)
- Diverse Beam Search (5 groups) âœ… ì„¤ì • ì¤€ë¹„
- Length Penalty ì¡°ì • (1.0 â†’ 1.2) âœ… ì„¤ì • ì¤€ë¹„
- No Repeat N-gram ê°•í™” âœ… ì„¤ì • ì¤€ë¹„

### 5. Solar API ì•™ìƒë¸” (ì˜ˆìƒ: ROUGE +2-3%)
- ê°€ì¤‘ í‰ê·  ê²°í•© âœ… ì½”ë“œ êµ¬í˜„
- ì‹ ë¢°ë„ ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜ âœ… ì½”ë“œ êµ¬í˜„
- Few-shot í”„ë¡¬í”„íŠ¸ ìµœì í™” ğŸ”‘ API í‚¤ í•„ìš”

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### CUDA Out of Memory
```bash
# ë°°ì¹˜ í¬ê¸° ê°ì†Œ
python code/trainer.py --per_device_train_batch_size 4

# Mixed Precision í™œì„±í™”
python code/trainer.py --fp16 true --fp16_backend amp
```

### ëŠë¦° í•™ìŠµ ì†ë„
```bash
# ë°ì´í„°ë¡œë” ì›Œì»¤ ì¦ê°€
python code/trainer.py --dataloader_num_workers 8

# ìºì‹œ í™œì„±í™”
export TRANSFORMERS_CACHE=/path/to/cache
```

### API Rate Limit
```python
# configì—ì„œ ì¡°ì •
solar_api:
  rate_limit_per_minute: 50  # ì¤„ì´ê¸°
  retry_delay: 10            # ëŠ˜ë¦¬ê¸°
```

## ğŸ“š ì°¸ê³  ìë£Œ

- [í”„ë¡œì íŠ¸ ë¬¸ì„œ](docs/)
- [ì‹¤í—˜ ê²°ê³¼ ë¶„ì„](docs/experiment_results/)
- [API ë¬¸ì„œ](docs/api/)
- [íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ](docs/troubleshooting.md)

## ğŸ¤ ê¸°ì—¬ ë°©ë²•

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ë¥¼ ë”°ë¦…ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [LICENSE](LICENSE) íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.

## ğŸ‘¥ íŒ€

- ê°œë°œì: LYJ
- í”„ë¡œì íŠ¸ ê¸°ê°„: 2025.01

## ğŸ™ ê°ì‚¬ì˜ ë§

- Upstage AI Lab for providing the dataset and baseline
- Hugging Face for the excellent transformers library
- The open-source community for various tools and libraries

---

**Note**: Solar API í‚¤ê°€ í•„ìš”í•œ ê¸°ëŠ¥ì€ ë³„ë„ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ [Solar API ê°€ì´ë“œ](code/ensemble/README.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
