{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BartForConditionalGeneration, BartConfig, AutoModelForSeq2SeqLM, AutoConfig\n",
    "# model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "model_name = \"digit82/kobart-summarization\"\n",
    "\n",
    "# bart_config = BartConfig().from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, legacy=False)\n",
    "# model = BartForConditionalGeneration.from_pretrained(model_name, config=bart_config)\n",
    "# config = AutoConfig.from_pretrained(model_name)\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce98d8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000000000000019884624838656"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a28bf67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    BOS : None,\n",
      "    EOS : </s>,\n",
      "    Special_tokens : {'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'},\n",
      "    Tokenizer's max_model_input_sizes : 1000000000000000019884624838656\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    BART Embedding Layer: {model.get_encoder().embed_tokens}, {model.get_encoder().embed_positions}\n",
    "    tokenizer의 encoder_max_len은 {model.get_encoder().embed_positions.num_embeddings} 이하여야 한다.\n",
    "\n",
    "    BART Decoder Layer: {model.get_decoder().embed_tokens}, {model.get_decoder().embed_positions}\n",
    "    tokenizer의 decoder_max_len은 {model.get_decoder().embed_positions.num_embeddings} 이하여야 한다.\n",
    "'''\n",
    "\n",
    "# from pprint import pprint\n",
    "print(f'''\n",
    "    BOS : {tokenizer.bos_token},\n",
    "    EOS : {tokenizer.eos_token},\n",
    "    Special_tokens : {tokenizer.special_tokens_map},\n",
    "    Tokenizer's max_model_input_sizes : {tokenizer.model_max_length}\n",
    "\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a9cd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 구성 정보를 YAML 파일로 저장합니다.\n",
    "project_dir = \"/data/ephemeral/home/nlp-5/song/\"\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\n",
    "    project_dir\n",
    ")\n",
    "from src.utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "514c6d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0729212926\n"
     ]
    }
   ],
   "source": [
    "current_time = get_current_time()\n",
    "output_dir = f\"./outputs/exp_auto_{current_time}\"\n",
    "save_eval_log_steps = 400 # save_step은 eval, log step의 배수여야 한다. 같이 맞춰주는 것이 편하다.\n",
    "print(current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13d51eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    \"general\": {\n",
    "        \"data_path\": \"./data/\", # 모델 생성에 필요한 데이터 경로를 사용자 환경에 맞게 지정합니다.\n",
    "        \"model_name\": \"digit82/kobart-summarization\", # 불러올 모델의 이름을 사용자 환경에 맞게 지정할 수 있습니다.\n",
    "        \"output_dir\": output_dir # 모델의 최종 출력 값을 저장할 경로를 설정합니다.\n",
    "    },\n",
    "    \"tokenizer\": {\n",
    "        \"encoder_max_len\": 1300,\n",
    "        \"decoder_max_len\": 160,\n",
    "        \"bos_token\": f\"{tokenizer.bos_token}\",\n",
    "        \"eos_token\": f\"{tokenizer.eos_token}\",\n",
    "        # 특정 단어들이 분해되어 tokenization이 수행되지 않도록 special_tokens을 지정해줍니다.\n",
    "        \"special_tokens\": [ '#Person1#', '#Person2#', '#Person3#', '#Person4#',\n",
    "            '#Person5#', '#Person6#', '#Person7#',\n",
    "            '#PhoneNumber#', '#Address#', '#DateOfBirth#','#PassportNumber#','#SSN#','#CardNumber#','#CarNumber#','#Email#'\n",
    "        ]\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"seed\": 42,\n",
    "        \"output_dir\": output_dir,\n",
    "        \"overwrite_output_dir\": False,\n",
    "\n",
    "        \"save_total_limit\": 1,\n",
    "        \"load_best_model_at_end\": True,\n",
    "        \"save_steps\": save_eval_log_steps,\n",
    "\n",
    "        \"logging_dir\": output_dir,\n",
    "        \"logging_steps\": save_eval_log_steps,\n",
    "\n",
    "        \"num_train_epochs\": 35,\n",
    "        \"per_device_train_batch_size\": 16,\n",
    "        \"remove_unused_columns\": True,\n",
    "        \"fp16\": False, # float16 사용 메모리 절약, But 정밀도 문제 존재 > 구형 GPU에서 사용\n",
    "        \"bf16\": True, # float16 사용 메모리 절약, 정밀도 문제 개선 > 30/40,... 등 최신 GPU 가능\n",
    "        \"dataloader_drop_last\": False,\n",
    "        \"group_by_length\": True,\n",
    "        \n",
    "        \"gradient_checkpointing\": True,\n",
    "        \"gradient_checkpointing_kwargs\": {\"use_reentrant\": False},\n",
    "        \"gradient_accumulation_steps\": 8,\n",
    "        \"torch_empty_cache_steps\": 2,\n",
    "        \"dataloader_num_workers\": 8,\n",
    "\n",
    "        \"per_device_eval_batch_size\": 16,\n",
    "        \"evaluation_strategy\": 'steps',\n",
    "        \"eval_steps\": save_eval_log_steps,\n",
    "        \n",
    "        \"predict_with_generate\": True,\n",
    "        \"generation_max_length\": 160,\n",
    "        \n",
    "        # Callbacks\n",
    "        \"early_stopping_patience\": 1,\n",
    "        \"early_stopping_threshold\": 0.001,\n",
    "\n",
    "        # Optimizer\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"warmup_steps\": 10,\n",
    "        \"weight_decay\": 1e-3,\n",
    "\n",
    "        \"report_to\": \"none\" # 학습 과정을 어느 백엔드에 저장할 것인지\n",
    "    },\n",
    "    # (선택) wandb 홈페이지에 가입하여 얻은 정보를 기반으로 작성합니다.\n",
    "    \"wandb\": {\n",
    "        \"entity\": \"skiersong\", # 팀 실험 시 organization 이름\n",
    "        \"project\": \"nlp-5\",\n",
    "        \"name\": f\"b_automodel_{current_time}\", # 개별 실험 이름\n",
    "        # \"group\": \"\", # 유사한 실험들은 같은 그룹으로 설정\n",
    "        \"notes\": \"b AutoModel \", # 실험에 대한 추가 설명\n",
    "    },\n",
    "    \"inference\": {\n",
    "        \"ckt_dir\": os.path.join(output_dir, 'best'), # 파인튜닝이 진행된 모델의 checkpoint를 저장할 경로를 설정합니다.\n",
    "        \"result_path\": os.path.join(output_dir, f\"submission_{current_time}.csv\"), # 제출할 csv 파일 저장 경로\n",
    "        \"no_repeat_ngram_size\": 2, # \n",
    "        \"early_stopping\": True,\n",
    "        \"generate_max_length\": 160,\n",
    "        \"num_beams\": 4,\n",
    "        \"batch_size\" : 16,\n",
    "        # 정확한 모델 평가를 위해 제거할 불필요한 생성 토큰들을 정의합니다.\n",
    "        \"remove_tokens\": ['<usr>', f\"{tokenizer.bos_token}\", f\"{tokenizer.eos_token}\", f\"{tokenizer.pad_token}\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "616c2f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general': {'data_path': './data/',\n",
      "             'model_name': 'csebuetnlp/mT5_multilingual_XLSum',\n",
      "             'output_dir': './outputs/exp_auto_0729212926'},\n",
      " 'inference': {'batch_size': 16,\n",
      "               'ckt_dir': './outputs/exp_auto_0729212926/best',\n",
      "               'early_stopping': True,\n",
      "               'generate_max_length': 160,\n",
      "               'no_repeat_ngram_size': 2,\n",
      "               'num_beams': 4,\n",
      "               'remove_tokens': ['<usr>', 'None', '</s>', '<pad>'],\n",
      "               'result_path': './outputs/exp_auto_0729212926/submission_0729212926.csv'},\n",
      " 'tokenizer': {'bos_token': 'None',\n",
      "               'decoder_max_len': 160,\n",
      "               'encoder_max_len': 1300,\n",
      "               'eos_token': '</s>',\n",
      "               'special_tokens': ['#Person1#',\n",
      "                                  '#Person2#',\n",
      "                                  '#Person3#',\n",
      "                                  '#Person4#',\n",
      "                                  '#PhoneNumber#',\n",
      "                                  '#Address#',\n",
      "                                  '#DateOfBirth#',\n",
      "                                  '#PassportNumber#',\n",
      "                                  '#SSN#',\n",
      "                                  '#CardNumber#',\n",
      "                                  '#CarNumber#',\n",
      "                                  '#Email#']},\n",
      " 'training': {'bf16': True,\n",
      "              'dataloader_drop_last': False,\n",
      "              'dataloader_num_workers': 8,\n",
      "              'early_stopping_patience': 1,\n",
      "              'early_stopping_threshold': 0.001,\n",
      "              'eval_steps': 400,\n",
      "              'evaluation_strategy': 'steps',\n",
      "              'fp16': False,\n",
      "              'generation_max_length': 160,\n",
      "              'gradient_accumulation_steps': 8,\n",
      "              'gradient_checkpointing': True,\n",
      "              'gradient_checkpointing_kwargs': {'use_reentrant': False},\n",
      "              'group_by_length': True,\n",
      "              'learning_rate': 1e-05,\n",
      "              'load_best_model_at_end': True,\n",
      "              'logging_dir': './outputs/exp_auto_0729212926',\n",
      "              'logging_steps': 400,\n",
      "              'num_train_epochs': 35,\n",
      "              'output_dir': './outputs/exp_auto_0729212926',\n",
      "              'overwrite_output_dir': False,\n",
      "              'per_device_eval_batch_size': 16,\n",
      "              'per_device_train_batch_size': 16,\n",
      "              'predict_with_generate': True,\n",
      "              'remove_unused_columns': True,\n",
      "              'report_to': 'none',\n",
      "              'save_steps': 400,\n",
      "              'save_total_limit': 1,\n",
      "              'seed': 42,\n",
      "              'torch_empty_cache_steps': 2,\n",
      "              'warmup_steps': 10,\n",
      "              'weight_decay': 0.001},\n",
      " 'wandb': {'entity': 'skiersong',\n",
      "           'name': 'b_automodel_0729212926',\n",
      "           'notes': 'b AutoModel ',\n",
      "           'project': 'nlp-5'}}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "from pprint import pprint\n",
    "\n",
    "config_path = os.path.join(\n",
    "    project_dir,'src','configs',\n",
    "    f\"config_auto_{current_time}.yaml\" # config 파일 이름을 설정\n",
    ")\n",
    "with open(config_path, \"w\") as file:\n",
    "    yaml.dump(config_data, file, allow_unicode=True)\n",
    "\n",
    "with open(config_path, \"r\") as file:\n",
    "    loaded_config = yaml.safe_load(file)\n",
    "\n",
    "# 불러온 config 파일의 전체 내용을 확인합니다.\n",
    "pprint(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27711c85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
