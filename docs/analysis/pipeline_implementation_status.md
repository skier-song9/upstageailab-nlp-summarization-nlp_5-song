# Run_main_5_experiments.shì˜ Baseline.py ê¸°ëŠ¥ êµ¬í˜„ ì™„ì „ ë¶„ì„

## ğŸ“Œ í•µì‹¬ ìš”ì•½

**run_main_5_experiments.shëŠ” ì´ë¯¸ baseline.pyì˜ ëª¨ë“  ê¸°ëŠ¥ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, í›¨ì”¬ ë” ê°•ë ¥í•œ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.**

---

## 1. ë°ì´í„° ë¡œë”© êµ¬í˜„ ìƒíƒœ âœ…

### Baseline.py ë°©ì‹
```python
# baseline.py ë¼ì¸ 160-165
train_df = pd.read_csv(os.path.join(data_path,'train.csv'))
val_df = pd.read_csv(os.path.join(data_path,'dev.csv'))
```

### Pipeline êµ¬í˜„ (ì´ë¯¸ êµ¬í˜„ë¨)
```python
# utils/data_utils.pyì˜ DataProcessor í´ë˜ìŠ¤
class DataProcessor:
    def load_dataset(self, data_path: str, split: str = 'train'):
        """ë°ì´í„°ì…‹ ë¡œë“œ - baselineê³¼ ë™ì¼í•œ ê²½ë¡œ ì‚¬ìš©"""
        if split == 'train':
            df = pd.read_csv(os.path.join(data_path, 'train.csv'))
        elif split == 'dev' or split == 'validation':
            df = pd.read_csv(os.path.join(data_path, 'dev.csv'))
        elif split == 'test':
            df = pd.read_csv(os.path.join(data_path, 'test.csv'))
        return df
```

**ìœ„ì¹˜**: `code/utils/data_utils.py`ì˜ `DataProcessor.load_dataset()` ë©”ì„œë“œ

---

## 2. ëª¨ë¸ í•™ìŠµ êµ¬í˜„ ìƒíƒœ âœ…

### Baseline.py ë°©ì‹
```python
# baseline.py ë¼ì¸ 361-373
trainer = Seq2SeqTrainer(
    model=generate_model,
    args=training_args,
    train_dataset=train_inputs_dataset,
    eval_dataset=val_inputs_dataset,
    compute_metrics=lambda pred: compute_metrics(config, tokenizer, pred),
    callbacks=[EarlyStoppingCallback()]
)
trainer.train()
```

### Pipeline êµ¬í˜„ (ì´ë¯¸ êµ¬í˜„ë¨)
```python
# trainer.pyì˜ DialogueSummarizationTrainer í´ë˜ìŠ¤
def train(self):
    """ëª¨ë¸ í•™ìŠµ - baselineê³¼ ë™ì¼í•œ Seq2SeqTrainer ì‚¬ìš©"""
    trainer = Seq2SeqTrainer(
        model=self.model,
        args=self.training_args,
        train_dataset=self.train_dataset,
        eval_dataset=self.eval_dataset,
        tokenizer=self.tokenizer,
        data_collator=self.data_collator,
        compute_metrics=self.compute_metrics,
        callbacks=self.callbacks
    )
    
    # í•™ìŠµ ì‹¤í–‰
    trainer.train()
    
    # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥
    trainer.save_model()
```

**ìœ„ì¹˜**: `code/trainer.py`ì˜ `DialogueSummarizationTrainer.train()` ë©”ì„œë“œ

---

## 3. Test.csv ì¶”ë¡  êµ¬í˜„ ìƒíƒœ âœ…

### Baseline.py ë°©ì‹
```python
# baseline.py ë¼ì¸ 499-542
def inference(config):
    # test.csv ë¡œë“œ
    test_data = preprocessor.make_set_as_df(test_file_path, is_train=False)
    
    # ë°°ì¹˜ ì¶”ë¡ 
    for item in tqdm(dataloader):
        generated_ids = generate_model.generate(
            input_ids=item['input_ids'],
            num_beams=4,
            max_length=100
        )
```

### Pipeline êµ¬í˜„ (ì´ë¯¸ êµ¬í˜„ë¨)

#### 3.1 ìë™ ì¶”ë¡  íŠ¸ë¦¬ê±° (auto_experiment_runner.py)
```python
# auto_experiment_runner.py ë¼ì¸ 420-470
if process.returncode == 0:  # í•™ìŠµ ì„±ê³µ ì‹œ
    print(f"\nğŸ“Š Test ì¶”ë¡  ì‹œì‘: {experiment_id}")
    
    # post_training_inference í™œìš©
    from post_training_inference import generate_submission_after_training
    
    submission_path = generate_submission_after_training(
        experiment_name=experiment_id,
        model_path=str(best_checkpoint),
        config_dict=config
    )
```

#### 3.2 ì‹¤ì œ ì¶”ë¡  êµ¬í˜„ (post_training_inference.py)
```python
def generate_submission_after_training(experiment_name, model_path, config_dict):
    # 1. test.csv ë¡œë“œ
    test_df = pd.read_csv('data/test.csv')
    
    # 2. ëª¨ë¸ ë¡œë“œ
    model, tokenizer = load_trained_model(model_path, config_dict)
    
    # 3. ë°°ì¹˜ ì¶”ë¡  (baselineê³¼ ë™ì¼í•œ ë°©ì‹)
    for i in range(0, len(test_df), batch_size):
        batch = test_df.iloc[i:i+batch_size]
        outputs = model.generate(
            inputs,
            max_length=config_dict.get('generation', {}).get('max_length', 100),
            num_beams=config_dict.get('generation', {}).get('num_beams', 4),
            no_repeat_ngram_size=2,
            early_stopping=True
        )
```

**ìœ„ì¹˜**: 
- `code/auto_experiment_runner.py`ì˜ `_run_single_experiment()` ë©”ì„œë“œ
- `code/post_training_inference.py`ì˜ `generate_submission_after_training()` í•¨ìˆ˜

---

## 4. ê²°ê³¼ CSV ìƒì„± êµ¬í˜„ ìƒíƒœ âœ…

### Baseline.py ë°©ì‹
```python
# baseline.py ë¼ì¸ 544-560
output = pd.DataFrame({
    "fname": test_data['fname'],
    "summary": preprocessed_summary
})
output.to_csv(os.path.join(result_path, "output.csv"), index=False)
```

### Pipeline êµ¬í˜„ (ì´ë¯¸ êµ¬í˜„ë¨)
```python
# post_training_inference.pyì™€ csv_results_saver.py
def save_submission(self, experiment_name, test_df, summaries):
    """ì œì¶œìš© CSV íŒŒì¼ ìƒì„± - baselineê³¼ ë™ì¼í•œ í˜•ì‹"""
    submission_df = pd.DataFrame({
        'fname': test_df['fname'],
        'summary': summaries
    })
    
    # ì‹¤í—˜ë³„ ê³ ìœ  íŒŒì¼ëª…
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_path = f'outputs/submissions/{experiment_name}_{timestamp}.csv'
    
    submission_df.to_csv(output_path, index=False)
    return output_path
```

**ìœ„ì¹˜**: `code/utils/csv_results_saver.py`ì˜ `CSVResultsSaver` í´ë˜ìŠ¤

---

## 5. ì‹¤ì œ ì‹¤í–‰ íë¦„ (ì „ì²´ í†µí•©)

### 5.1 run_main_5_experiments.sh ì‹¤í–‰ ì‹œ
```bash
#!/bin/bash
# 1. GPU ìƒíƒœ í™•ì¸
enhanced_gpu_monitor "ì‹¤í—˜ ì „"

# 2. ê° ì‹¤í—˜ ì‹¤í–‰ (ì˜ˆ: KoBART baseline)
for experiment in "${experiments[@]}"; do
    # 3. auto_experiment_runner.py í˜¸ì¶œ
    python code/auto_experiment_runner.py \
        --config config/experiments/01_baseline_kobart_rtx3090.yaml
    
    # ì´ ëª…ë ¹ì€ ë‹¤ìŒì„ ìˆ˜í–‰:
    # a) trainer.pyë¥¼ í†µí•´ ëª¨ë¸ í•™ìŠµ (train.csv ì‚¬ìš©)
    # b) í•™ìŠµ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ test.csv ì¶”ë¡ 
    # c) ê²°ê³¼ CSV ìƒì„± ë° ì €ì¥
done
```

### 5.2 ë°ì´í„° íë¦„
```
1. data/train.csv â†’ DataProcessor â†’ ëª¨ë¸ í•™ìŠµ
2. data/dev.csv â†’ í‰ê°€ ë° ì¡°ê¸° ì¢…ë£Œ
3. í•™ìŠµ ì™„ë£Œ â†’ ë² ìŠ¤íŠ¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
4. data/test.csv â†’ ìë™ ì¶”ë¡  ì‹¤í–‰
5. outputs/submissions/ì‹¤í—˜ëª…_timestamp.csv ìƒì„±
```

---

## 6. Baselineê³¼ ì™„ì „íˆ ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ëŠ” ë°©ë²•

### 6.1 ì„¤ì • íŒŒì¼ ì¤€ë¹„
```yaml
# config/experiments/baseline_exact_reproduction.yaml
experiment_name: baseline_exact_reproduction

general:
  model_name: digit82/kobart-summarization
  data_path: data/

tokenizer:
  encoder_max_len: 512
  decoder_max_len: 100
  special_tokens: ['#Person1#', '#Person2#', '#Person3#', 
                   '#PhoneNumber#', '#Address#', '#PassportNumber#']

training:
  num_train_epochs: 20
  learning_rate: 1e-5
  per_device_train_batch_size: 50
  per_device_eval_batch_size: 32
  warmup_ratio: 0.1
  fp16: true
  evaluation_strategy: epoch
  save_strategy: epoch
  early_stopping_patience: 3

generation:
  max_length: 100
  num_beams: 4
  no_repeat_ngram_size: 2
  early_stopping: true

inference:
  batch_size: 32
  remove_tokens: ['<usr>', '<s>', '</s>', '<pad>']
```

### 6.2 ì‹¤í–‰ ëª…ë ¹
```bash
# ë‹¨ì¼ ì‹¤í—˜ ì‹¤í–‰
python code/auto_experiment_runner.py \
    --config config/experiments/baseline_exact_reproduction.yaml

# ë˜ëŠ” run_main_5_experiments.shì— ì¶”ê°€í•˜ì—¬ ì‹¤í–‰
```

---

## 7. Pipelineì˜ ì¶”ê°€ ê¸°ëŠ¥ë“¤

### 7.1 ì´ë¯¸ êµ¬í˜„ëœ ê³ ê¸‰ ê¸°ëŠ¥ë“¤
1. **ìë™ GPU ë©”ëª¨ë¦¬ ê´€ë¦¬**: GPU ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë° ìµœì í™”
2. **ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›**: mT5, T5, KoBART, Solar ë“±
3. **QLoRA/Unsloth ìµœì í™”**: ë©”ëª¨ë¦¬ íš¨ìœ¨ì  í•™ìŠµ
4. **WandB í†µí•©**: ì‹¤í—˜ ì¶”ì  ë° ì‹œê°í™”
5. **ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**: Sweep ê¸°ëŠ¥
6. **ë³‘ë ¬ ì‹¤í—˜ ì‹¤í–‰**: ì—¬ëŸ¬ GPUì—ì„œ ë™ì‹œ ì‹¤í–‰
7. **ì‹¤í—˜ ê²°ê³¼ ìë™ ë¶„ì„**: ë©”íŠ¸ë¦­ ë¹„êµ ë° ë² ìŠ¤íŠ¸ ëª¨ë¸ ì„ íƒ

### 7.2 Baselineì—ëŠ” ì—†ëŠ” Pipeline ê¸°ëŠ¥
```python
# 1. ë°ì´í„° ì¦ê°•
augmentation:
  use_augmentation: true
  augmentation_types: ['backtranslation', 'paraphrase', 'noise']

# 2. ì•™ìƒë¸”
ensemble:
  models: ['model1', 'model2', 'model3']
  strategy: 'weighted_average'

# 3. ê³ ê¸‰ ìƒì„± ì „ëµ
generation:
  strategy: 'contrastive_search'
  top_k: 50
  penalty_alpha: 0.6
```

---

## ê²°ë¡ 

**run_main_5_experiments.shëŠ” ì´ë¯¸ baseline.pyì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ì™„ë²½í•˜ê²Œ êµ¬í˜„í•˜ê³  ìˆìŠµë‹ˆë‹¤:**

1. âœ… **ë°ì´í„° ë¡œë”©**: `data/train.csv`, `data/dev.csv`, `data/test.csv` ëª¨ë‘ ì‚¬ìš©
2. âœ… **ëª¨ë¸ í•™ìŠµ**: ë™ì¼í•œ Seq2SeqTrainer ê¸°ë°˜
3. âœ… **Test ì¶”ë¡ **: í•™ìŠµ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì‹¤í–‰
4. âœ… **ê²°ê³¼ CSV ìƒì„±**: ë™ì¼í•œ í˜•ì‹ì˜ submission íŒŒì¼ ìƒì„±

**ì¶”ê°€ë¡œ ì œê³µí•˜ëŠ” ê¸°ëŠ¥:**
- ğŸš€ ìë™í™”ëœ ì‹¤í—˜ ê´€ë¦¬
- ğŸ’ª GPU ë©”ëª¨ë¦¬ ìµœì í™”
- ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ì¶”ì  ë° ë¶„ì„
- ğŸ”¥ ë‹¤ì–‘í•œ ëª¨ë¸ ë° ìµœì í™” ê¸°ë²• ì§€ì›

**ì‚¬ìš© ê¶Œì¥ì‚¬í•­:**
- ë¹ ë¥¸ í”„ë¡œí† íƒ€ì…: `python code/baseline.py`
- ë³¸ê²©ì ì¸ ì‹¤í—˜: `bash run_main_5_experiments.sh`
- ìµœì¢… ì œì¶œ: Pipelineì˜ ë² ìŠ¤íŠ¸ ëª¨ë¸ ì‚¬ìš©
