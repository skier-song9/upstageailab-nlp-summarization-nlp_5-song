# ğŸ Mac/Linux í™˜ê²½ ìë™ ê°ì§€ ë° MPS/CUDA ì§€ì› êµ¬í˜„ ê°€ì´ë“œ

## ğŸ“Š ê°œìš”

ì´ ë¬¸ì„œëŠ” Mac(Apple Silicon)ê³¼ Linux í™˜ê²½ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ì ì ˆí•œ GPU ê°€ì†(MPS/CUDA)ì„ ì‚¬ìš©í•˜ë„ë¡ ì„¤ì •í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

**ì‘ì„±ì¼**: 2025-07-26  
**í˜„ì¬ ìƒíƒœ**: âŒ MPS ë¯¸ì§€ì› (CUDAë§Œ ì§€ì›)  
**ëª©í‘œ**: Mac M1/M2ì˜ MPSì™€ Linux/Windowsì˜ CUDA ìë™ ê°ì§€ ë° ìµœì í™”

---

## ğŸ”´ í˜„ì¬ ë¬¸ì œì 

### trainer.pyì˜ í˜„ì¬ ë””ë°”ì´ìŠ¤ ì„¤ì • ì½”ë“œ
```python
def _setup_device(self) -> torch.device:
    """ë””ë°”ì´ìŠ¤ ì„¤ì •"""
    device_config = self.config['general'].get('device', 'auto')
    
    if device_config == 'auto':
        # ë¬¸ì œ: MPSë¥¼ ì „í˜€ ê³ ë ¤í•˜ì§€ ì•ŠìŒ
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(device_config)
    
    logger.info(f"Using device: {device}")
    return device
```

**ì˜í–¥**:
- Mac M1/M2 ì‚¬ìš©ìëŠ” GPU ê°€ì†ì„ ë°›ì„ ìˆ˜ ì—†ìŒ
- CPU ëŒ€ë¹„ 10ë°° ì´ìƒ ëŠë¦° í•™ìŠµ ì†ë„

---

## âœ… í•´ê²° ë°©ì•ˆ

### 1. device_utils.py ìƒì„±

```python
# code/utils/device_utils.py
import torch
import platform
import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)

def get_system_info() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
    return {
        'platform': platform.system(),  # 'Darwin' (Mac), 'Linux', 'Windows'
        'platform_release': platform.release(),
        'platform_version': platform.version(),
        'architecture': platform.machine(),  # 'arm64' (M1/M2), 'x86_64', etc.
        'processor': platform.processor(),
        'python_version': platform.python_version(),
        'torch_version': torch.__version__,
        'cuda_available': torch.cuda.is_available(),
        'cuda_version': torch.version.cuda if torch.cuda.is_available() else None,
        'mps_available': torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else False,
    }

def get_optimal_device() -> str:
    """
    í™˜ê²½ì— ë”°ë¥¸ ìµœì  ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ
    
    ìš°ì„ ìˆœìœ„:
    1. CUDA (NVIDIA GPU) - Linux/Windows
    2. MPS (Apple Silicon GPU) - Mac M1/M2
    3. CPU (fallback)
    
    Returns:
        str: 'cuda', 'mps', ë˜ëŠ” 'cpu'
    """
    system_info = get_system_info()
    
    # CUDA í™•ì¸ (ì£¼ë¡œ Linux/Windows)
    if torch.cuda.is_available():
        device = "cuda"
        device_name = torch.cuda.get_device_name(0)
        memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3
        logger.info(f"CUDA device detected: {device_name} ({memory_gb:.1f}GB)")
        logger.info(f"CUDA version: {torch.version.cuda}")
        
    # MPS í™•ì¸ (Mac M1/M2)
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = "mps"
        logger.info("Apple MPS (Metal Performance Shaders) device detected")
        logger.info(f"Platform: {system_info['platform']} {system_info['architecture']}")
        
        # MPS ì‚¬ìš© ì‹œ ì£¼ì˜ì‚¬í•­ ë¡œê¹…
        logger.warning("MPS Notes: Some operations may be slower than CUDA. "
                      "Mixed precision (fp16) is not fully supported.")
        
    # CPU fallback
    else:
        device = "cpu"
        logger.info("No GPU detected, using CPU")
        logger.info(f"Platform: {system_info['platform']} {system_info['architecture']}")
        
        # ì¶”ì²œì‚¬í•­ ì œê³µ
        if system_info['platform'] == 'Darwin' and system_info['architecture'] == 'arm64':
            logger.warning("You appear to be on Apple Silicon but MPS is not available. "
                          "Please ensure PyTorch is installed with MPS support: "
                          "pip install torch torchvision torchaudio")
    
    return device

def setup_device_config(config: Dict[str, Any]) -> Dict[str, Any]:
    """
    ë””ë°”ì´ìŠ¤ë³„ ìµœì í™”ëœ ì„¤ì • ìë™ êµ¬ì„±
    
    Args:
        config: ê¸°ì¡´ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        
    Returns:
        Dict[str, Any]: ë””ë°”ì´ìŠ¤ ìµœì í™”ê°€ ì ìš©ëœ ì„¤ì •
    """
    device = get_optimal_device()
    
    # ë””ë°”ì´ìŠ¤ë³„ ê¸°ë³¸ ìµœì í™” ì„¤ì •
    device_optimizations = {
        "cuda": {
            "fp16": True,  # CUDAëŠ” mixed precision ì™„ë²½ ì§€ì›
            "dataloader_num_workers": 4,
            "gradient_accumulation_steps": 1,
            "per_device_train_batch_size": 8,
            "gradient_checkpointing": False,  # ë©”ëª¨ë¦¬ ì¶©ë¶„í•˜ë©´ ë¹„í™œì„±í™”
        },
        "mps": {
            "fp16": False,  # MPSëŠ” í˜„ì¬ fp16 ë¯¸ì§€ì›
            "dataloader_num_workers": 0,  # MPSëŠ” multiprocessingê³¼ í˜¸í™˜ì„± ì´ìŠˆ
            "gradient_accumulation_steps": 4,  # ì‘ì€ ë°°ì¹˜ í¬ê¸° ë³´ìƒ
            "per_device_train_batch_size": 4,  # ì•ˆì •ì„±ì„ ìœ„í•´ ì‘ê²Œ
            "gradient_checkpointing": True,  # ë©”ëª¨ë¦¬ ì ˆì•½
        },
        "cpu": {
            "fp16": False,  # CPUëŠ” fp16 ë¹„íš¨ìœ¨ì 
            "dataloader_num_workers": 2,
            "gradient_accumulation_steps": 8,
            "per_device_train_batch_size": 2,
            "gradient_checkpointing": True,
        }
    }
    
    # ê¸°ì¡´ ì„¤ì •ì— ë””ë°”ì´ìŠ¤ ìµœì í™” ì ìš©
    optimizations = device_optimizations[device]
    
    if "training" not in config:
        config["training"] = {}
    
    # ì‚¬ìš©ìê°€ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •í•˜ì§€ ì•Šì€ ê°’ë§Œ ì—…ë°ì´íŠ¸
    for key, value in optimizations.items():
        if key not in config["training"]:
            config["training"][key] = value
            logger.info(f"Auto-configured {key}: {value} for {device}")
    
    # ë””ë°”ì´ìŠ¤ ì •ë³´ ì¶”ê°€
    config["device"] = device
    config["device_info"] = get_system_info()
    
    return config

def log_device_info():
    """ë””ë°”ì´ìŠ¤ ì •ë³´ ìƒì„¸ ë¡œê¹…"""
    system_info = get_system_info()
    device = get_optimal_device()
    
    logger.info("="*50)
    logger.info("System Information:")
    logger.info(f"  Platform: {system_info['platform']}")
    logger.info(f"  Architecture: {system_info['architecture']}")
    logger.info(f"  Python: {system_info['python_version']}")
    logger.info(f"  PyTorch: {system_info['torch_version']}")
    
    if device == "cuda":
        logger.info(f"  CUDA Version: {system_info['cuda_version']}")
        logger.info(f"  GPU Count: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            logger.info(f"  GPU {i}: {props.name} ({props.total_memory / 1024**3:.1f}GB)")
    
    elif device == "mps":
        logger.info("  MPS: Available (Apple Silicon GPU)")
    
    logger.info(f"  Selected Device: {device}")
    logger.info("="*50)
```

### 2. trainer.py ìˆ˜ì •

```python
# trainer.pyì˜ _setup_device ë©”ì„œë“œë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ìˆ˜ì •

from utils.device_utils import get_optimal_device, setup_device_config, log_device_info

def _setup_device(self) -> torch.device:
    """ë””ë°”ì´ìŠ¤ ì„¤ì • (MPS/CUDA ìë™ ê°ì§€)"""
    # ë””ë°”ì´ìŠ¤ ì •ë³´ ë¡œê¹…
    log_device_info()
    
    # ì„¤ì •ì—ì„œ ëª…ì‹œì  ë””ë°”ì´ìŠ¤ ì§€ì • í™•ì¸
    device_config = self.config['general'].get('device', 'auto')
    
    if device_config == 'auto':
        # ìë™ ê°ì§€
        device_str = get_optimal_device()
        
        # ì„¤ì • ìë™ ìµœì í™”
        self.config = setup_device_config(self.config)
    else:
        # ì‚¬ìš©ì ì§€ì • ë””ë°”ì´ìŠ¤
        device_str = device_config
        logger.info(f"Using user-specified device: {device_str}")
    
    device = torch.device(device_str)
    logger.info(f"Final device selection: {device}")
    
    # MPS ì‚¬ìš© ì‹œ ì¶”ê°€ ì„¤ì •
    if device_str == "mps":
        # MPS ê´€ë ¨ í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì„ íƒì‚¬í•­)
        import os
        os.environ['PYTORCH_MPS_HIGH_WATERMARK_RATIO'] = '0.0'
        logger.info("MPS environment variables configured")
    
    return device
```

### 3. ì„¤ì¹˜ ìš”êµ¬ì‚¬í•­ ì—…ë°ì´íŠ¸

```bash
# requirements.txtì— ì¶”ê°€
torch>=2.0.0  # MPSëŠ” PyTorch 2.0 ì´ìƒì—ì„œ ì•ˆì •ì 

# Mac M1/M2 ì‚¬ìš©ìë¥¼ ìœ„í•œ ì„¤ì¹˜ ëª…ë ¹ (README.mdì— ì¶”ê°€)
# For Mac M1/M2 (Apple Silicon):
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# For Linux/Windows with CUDA 11.8:
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì½”ë“œ

```python
# test_device_setup.py
import sys
sys.path.append('code')

from utils.device_utils import get_optimal_device, get_system_info, setup_device_config

def test_device_detection():
    """ë””ë°”ì´ìŠ¤ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    print("=== Device Detection Test ===")
    
    # ì‹œìŠ¤í…œ ì •ë³´
    info = get_system_info()
    print(f"Platform: {info['platform']}")
    print(f"Architecture: {info['architecture']}")
    print(f"CUDA Available: {info['cuda_available']}")
    print(f"MPS Available: {info['mps_available']}")
    
    # ìµœì  ë””ë°”ì´ìŠ¤ ì„ íƒ
    device = get_optimal_device()
    print(f"\nSelected Device: {device}")
    
    # ì„¤ì • ìµœì í™” í…ŒìŠ¤íŠ¸
    config = {"training": {}}
    optimized_config = setup_device_config(config)
    
    print("\nOptimized Configuration:")
    for key, value in optimized_config['training'].items():
        print(f"  {key}: {value}")

if __name__ == "__main__":
    test_device_detection()
```

---

## ğŸ“‹ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `code/utils/device_utils.py` íŒŒì¼ ìƒì„±
- [ ] `get_optimal_device()` í•¨ìˆ˜ êµ¬í˜„
- [ ] `setup_device_config()` í•¨ìˆ˜ êµ¬í˜„
- [ ] trainer.pyì˜ `_setup_device()` ë©”ì„œë“œ ìˆ˜ì •
- [ ] requirements.txt ì—…ë°ì´íŠ¸
- [ ] README.mdì— í”Œë«í¼ë³„ ì„¤ì¹˜ ê°€ì´ë“œ ì¶”ê°€
- [ ] í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ë° ê²€ì¦

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### MPS ì‚¬ìš© ì‹œ ì œí•œì‚¬í•­
1. **Mixed Precision (fp16) ë¯¸ì§€ì›**: í˜„ì¬ MPSëŠ” fp16 ì—°ì‚°ì„ ì™„ì „íˆ ì§€ì›í•˜ì§€ ì•ŠìŒ
2. **ì¼ë¶€ ì—°ì‚° ëŠë¦¼**: íŠ¹ì • ì—°ì‚°ì€ CUDAë³´ë‹¤ ëŠë¦´ ìˆ˜ ìˆìŒ
3. **DataLoader ë©€í‹°í”„ë¡œì„¸ì‹± ì´ìŠˆ**: num_workersëŠ” 0ìœ¼ë¡œ ì„¤ì • í•„ìš”

### ì„±ëŠ¥ ë¹„êµ
- **CUDA**: ê°€ì¥ ë¹ ë¦„, ëª¨ë“  ê¸°ëŠ¥ ì§€ì›
- **MPS**: CUDAì˜ 70-80% ì„±ëŠ¥, ì¼ë¶€ ì œí•œ
- **CPU**: ê°€ì¥ ëŠë¦¼ (GPU ëŒ€ë¹„ 10-20ë°°)

---

## ğŸš€ ì˜ˆìƒ íš¨ê³¼

1. **Mac M1/M2 ì‚¬ìš©ì**: CPU ëŒ€ë¹„ 5-10ë°° ë¹ ë¥¸ í•™ìŠµ
2. **ìë™ ìµœì í™”**: í”Œë«í¼ë³„ ìµœì  ì„¤ì • ìë™ ì ìš©
3. **í˜¸í™˜ì„±**: ëª¨ë“  í”Œë«í¼ì—ì„œ ì½”ë“œ ìˆ˜ì • ì—†ì´ ì‹¤í–‰

---

**ì‘ì„±ì**: AI Assistant  
**ìµœì¢… ê²€í† **: 2025-07-26  
**ë¬¸ì„œ ë²„ì „**: 1.0