# CompetitionCSVManager ì„¤ê³„ ë¬¸ì„œ

## ğŸ“‹ **ëª©ì **
ëŒ€íšŒ ì±„ì ìš© CSV íŒŒì¼ì„ baseline.pyì™€ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ìƒì„±í•˜ë©´ì„œ, ë‹¤ì¤‘ ì‹¤í—˜ ì§€ì› ë° ì‹¤í—˜ ì¶”ì  ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤.

## ğŸ¯ **í•µì‹¬ ìš”êµ¬ì‚¬í•­**

### **1. Baseline.py í˜¸í™˜ì„±**
- **íŒŒì¼ í˜•ì‹**: `fname,summary` (ë™ì¼)
- **ì €ì¥ ìœ„ì¹˜**: `./prediction/` ë””ë ‰í† ë¦¬ (ë™ì¼)
- **íŒŒì¼ëª…**: `output.csv` (ë™ì¼)

### **2. ë‹¤ì¤‘ ì‹¤í—˜ ì§€ì›**  
- **ì‹¤í—˜ë³„ êµ¬ë¶„**: ê° ì‹¤í—˜ë§ˆë‹¤ ë…ë¦½ëœ í´ë”
- **íƒ€ì„ìŠ¤íƒ¬í”„**: ì–¸ì œ ìƒì„±ë˜ì—ˆëŠ”ì§€ ì¶”ì 
- **ë®ì–´ì“°ê¸° ë°©ì§€**: ì´ì „ ì‹¤í—˜ ê²°ê³¼ ë³´ì¡´

### **3. í¸ì˜ ê¸°ëŠ¥**
- **ìµœì‹  ê²°ê³¼**: `latest_output.csv` ë¹ ë¥¸ ì ‘ê·¼
- **ì‹¤í—˜ ì¶”ì **: `experiment_index.csv` ì „ì²´ ê´€ë¦¬
- **ë°±ì—… ê¸°ëŠ¥**: `history/` í´ë”ì— íˆìŠ¤í† ë¦¬ ë³´ê´€

## ğŸ—‚ï¸ **ìƒì„±ë  íŒŒì¼ êµ¬ì¡°**

```
ğŸ“ prediction/
â”œâ”€â”€ ğŸ“ baseline_kobart_20250802_143022/         # ì‹¤í—˜ 1
â”‚   â”œâ”€â”€ ğŸ“„ output.csv                           # ì±„ì ìš© (í‘œì¤€ í˜•ì‹)
â”‚   â””â”€â”€ ğŸ“„ experiment_metadata.json             # ì‹¤í—˜ ì •ë³´
â”œâ”€â”€ ğŸ“ mt5_xlsum_20250802_151055/               # ì‹¤í—˜ 2  
â”‚   â”œâ”€â”€ ğŸ“„ output.csv                           # ì±„ì ìš© (í‘œì¤€ í˜•ì‹)
â”‚   â””â”€â”€ ğŸ“„ experiment_metadata.json
â”œâ”€â”€ ğŸ“ eenzeenee_t5_20250802_164233/            # ì‹¤í—˜ 3
â”‚   â”œâ”€â”€ ğŸ“„ output.csv                           # ì±„ì ìš© (í‘œì¤€ í˜•ì‹)
â”‚   â””â”€â”€ ğŸ“„ experiment_metadata.json
â”œâ”€â”€ ğŸ“„ latest_output.csv                        # ìµœì‹  ì‹¤í—˜ ê²°ê³¼ (í¸ì˜ìš©)
â”œâ”€â”€ ğŸ“„ experiment_index.csv                     # ì‹¤í—˜ ì¸ë±ìŠ¤ (ì¶”ì ìš©)
â””â”€â”€ ğŸ“ history/                                 # ë°±ì—… ë³´ê´€ì†Œ
    â”œâ”€â”€ ğŸ“„ output_baseline_kobart_20250802_143022.csv
    â”œâ”€â”€ ğŸ“„ output_mt5_xlsum_20250802_151055.csv
    â””â”€â”€ ğŸ“„ output_eenzeenee_t5_20250802_164233.csv
```

## ğŸ“Š **íŒŒì¼ ë‚´ìš© ì˜ˆì‹œ**

### **1. output.csv (ì±„ì ìš© - baseline.pyì™€ ë™ì¼)**
```csv
fname,summary
TREC002_00001,ëŒ€í™” ì°¸ê°€ìë“¤ì´ ì—¬í–‰ ê³„íšì— ëŒ€í•´ ë…¼ì˜í•˜ê³  ìˆë‹¤.
TREC002_00002,ê³ ê°ì´ ì œí’ˆ êµ¬ë§¤ ê´€ë ¨ ë¬¸ì˜ë¥¼ í•˜ê³  ìˆë‹¤.
TREC002_00003,ì¹œêµ¬ë“¤ì´ ì €ë… ì‹ì‚¬ ì•½ì†ì„ ì •í•˜ê³  ìˆë‹¤.
```

### **2. experiment_index.csv (ì‹¤í—˜ ì¶”ì )**
```csv
experiment_name,folder_name,timestamp,submission_file,latest_file,created_at,rouge_combined,rouge1,rouge2,rougeL
mt5_xlsum,mt5_xlsum_20250802_151055,20250802_151055,./prediction/mt5_xlsum_20250802_151055/output.csv,./prediction/latest_output.csv,2025-08-02 15:10:55,0.579,0.254,0.095,0.230
baseline_kobart,baseline_kobart_20250802_143022,20250802_143022,./prediction/baseline_kobart_20250802_143022/output.csv,./prediction/latest_output.csv,2025-08-02 14:30:22,0.523,0.231,0.087,0.205
eenzeenee_t5,eenzeenee_t5_20250802_164233,20250802_164233,./prediction/eenzeenee_t5_20250802_164233/output.csv,./prediction/latest_output.csv,2025-08-02 16:42:33,0.467,0.198,0.078,0.189
```

### **3. experiment_metadata.json (ìƒì„¸ ì •ë³´)**
```json
{
  "experiment_name": "mt5_xlsum",
  "timestamp": "20250802_151055",
  "created_at": "2025-08-02T15:10:55",
  "model_name": "csebuetnlp/mT5_multilingual_XLSum",
  "config_summary": {
    "learning_rate": 5e-05,
    "batch_size": 1,
    "num_epochs": 3
  },
  "metrics": {
    "eval_rouge1_f1": 0.254,
    "eval_rouge2_f1": 0.095,
    "eval_rougeL_f1": 0.230,
    "eval_rouge_combined_f1": 0.579
  },
  "submission_info": {
    "format": "fname,summary",
    "encoding": "utf-8"
  }
}
```

## ğŸ”§ **í´ë˜ìŠ¤ ì„¤ê³„**

### **ì£¼ìš” ë©”ì„œë“œ**
```python
class CompetitionCSVManager:
    def __init__(self, prediction_base: str = "./prediction")
    
    # í•µì‹¬ ê¸°ëŠ¥
    def save_experiment_submission(self, experiment_name: str, result_df: pd.DataFrame, 
                                 config: Dict = None, metrics: Dict = None, timestamp: str = None) -> Dict[str, str]
    
    # ë‚´ë¶€ ê¸°ëŠ¥
    def _save_experiment_metadata(self, metadata_path: Path, experiment_name: str, config: Dict, metrics: Dict, timestamp: str)
    def _save_to_history(self, submission_df: pd.DataFrame, experiment_name: str, timestamp: str) -> str
    def _update_experiment_index(self, experiment_name: str, experiment_folder: str, timestamp: str, metrics: Dict = None)
    def _print_generation_summary(self, result_paths: Dict[str, str], num_samples: int)
    
    # ì¡°íšŒ ê¸°ëŠ¥
    def get_latest_experiment(self) -> Optional[Dict]
    def list_all_experiments(self) -> pd.DataFrame
    def get_best_experiment_by_rouge(self) -> Optional[Dict]
```

## ğŸ”„ **ì‹¤í–‰ íë¦„**

### **ì…ë ¥**
- `result_df`: DataFrame with columns ['fname', 'summary']
- `experiment_name`: "mt5_xlsum"
- `config`: ì‹¤í—˜ ì„¤ì • ë”•ì…”ë„ˆë¦¬
- `metrics`: ì„±ëŠ¥ ì§€í‘œ ë”•ì…”ë„ˆë¦¬

### **ì²˜ë¦¬ ê³¼ì •**
1. **ì…ë ¥ ê²€ì¦**: fname, summary ì»¬ëŸ¼ í™•ì¸
2. **í´ë” ìƒì„±**: `prediction/{experiment_name}_{timestamp}/`
3. **ì±„ì ìš© CSV ì €ì¥**: `output.csv` (baseline.py í˜•ì‹)
4. **ë©”íƒ€ë°ì´í„° ì €ì¥**: `experiment_metadata.json`
5. **ìµœì‹  íŒŒì¼ ì—…ë°ì´íŠ¸**: `latest_output.csv` (ë®ì–´ì“°ê¸°)
6. **íˆìŠ¤í† ë¦¬ ë°±ì—…**: `history/output_{experiment_name}_{timestamp}.csv`
7. **ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸**: `experiment_index.csv`ì— ì‹¤í—˜ ì¶”ê°€

### **ì¶œë ¥**
```python
{
    'experiment_path': './prediction/mt5_xlsum_20250802_151055/output.csv',
    'latest_path': './prediction/latest_output.csv',
    'history_path': './prediction/history/output_mt5_xlsum_20250802_151055.csv',
    'metadata_path': './prediction/mt5_xlsum_20250802_151055/experiment_metadata.json',
    'experiment_folder': 'mt5_xlsum_20250802_151055'
}
```

## ğŸ“Š **ì‚¬ìš© ì˜ˆì‹œ**

### **auto_experiment_runner.pyì—ì„œ ì‚¬ìš©**
```python
from utils.competition_csv_manager import CompetitionCSVManager

csv_manager = CompetitionCSVManager()

# ì¶”ë¡  ì™„ë£Œ í›„ í˜¸ì¶œ
competition_paths = csv_manager.save_experiment_submission(
    experiment_name="mt5_xlsum",
    result_df=result_df,  # fname, summary ì»¬ëŸ¼ í¬í•¨
    config=config,
    metrics={"eval_rouge1_f1": 0.254, "eval_rouge2_f1": 0.095},
    timestamp=None  # ìë™ ìƒì„±
)

print(f"âœ… ì±„ì ìš© íŒŒì¼: {competition_paths['experiment_path']}")
print(f"âœ… ìµœì‹  íŒŒì¼: {competition_paths['latest_path']}")
```

### **ì‹¤í—˜ ì¡°íšŒ**
```python
# ê°€ì¥ ìµœê·¼ ì‹¤í—˜
latest = csv_manager.get_latest_experiment()
print(f"ìµœê·¼ ì‹¤í—˜: {latest['experiment_name']} â†’ {latest['submission_file']}")

# ìµœê³  ì„±ëŠ¥ ì‹¤í—˜  
best = csv_manager.get_best_experiment_by_rouge()
print(f"ìµœê³  ì„±ëŠ¥: {best['experiment_name']} (ROUGE: {best['rouge_combined']})")

# ì „ì²´ ì‹¤í—˜ ëª©ë¡
all_experiments = csv_manager.list_all_experiments()
print(all_experiments[['experiment_name', 'rouge_combined', 'created_at']])
```

## ğŸ¯ **baseline.pyì™€ì˜ ë¹„êµ**

| êµ¬ë¶„ | baseline.py | CompetitionCSVManager |
|------|------------|----------------------|
| **ì €ì¥ ìœ„ì¹˜** | `./prediction/output.csv` | âœ… `./prediction/{ì‹¤í—˜ëª…}/output.csv` |
| **íŒŒì¼ í˜•ì‹** | `fname,summary` | âœ… ë™ì¼ |
| **ë‹¤ì¤‘ ì‹¤í—˜** | âŒ ë®ì–´ì“°ê¸°ë§Œ | âœ… ì‹¤í—˜ë³„ í´ë” ë¶„ë¦¬ |
| **ìµœì‹  ê²°ê³¼** | âŒ ì—†ìŒ | âœ… `latest_output.csv` |
| **ì‹¤í—˜ ì¶”ì ** | âŒ ì—†ìŒ | âœ… `experiment_index.csv` |
| **ë©”íƒ€ë°ì´í„°** | âŒ ì—†ìŒ | âœ… JSON í˜•íƒœë¡œ ì €ì¥ |
| **ë°±ì—…** | âŒ ì—†ìŒ | âœ… `history/` í´ë” |

## ğŸ“ˆ **ê¸°ëŒ€ íš¨ê³¼**

1. **âœ… ëŒ€íšŒ í‘œì¤€ ì¤€ìˆ˜**: baseline.pyì™€ ë™ì¼í•œ ì œì¶œ í˜•ì‹
2. **âœ… ë‹¤ì¤‘ ì‹¤í—˜ ì§€ì›**: ì—¬ëŸ¬ ì‹¤í—˜ ê²°ê³¼ ë™ì‹œ ê´€ë¦¬  
3. **âœ… ì¶”ì  ê°€ëŠ¥ì„±**: ì–¸ì œ ì–´ë–¤ ì‹¤í—˜ìœ¼ë¡œ ìƒì„±ëëŠ”ì§€ ê¸°ë¡
4. **âœ… í¸ì˜ì„±**: latest_output.csvë¡œ ìµœì‹  ê²°ê³¼ ë¹ ë¥¸ ì ‘ê·¼
5. **âœ… ì•ˆì „ì„±**: ì´ì „ ì‹¤í—˜ ê²°ê³¼ ë³´ì¡´ ë° ë°±ì—…
6. **âœ… ë¶„ì„ ê¸°ëŠ¥**: ì‹¤í—˜ ì„±ëŠ¥ ë¹„êµ ë° ìµœì  ëª¨ë¸ ì„ íƒ

---

**ì‘ì„±ì¼**: 2025-08-02  
**ìƒíƒœ**: ì„¤ê³„ ì™„ë£Œ, êµ¬í˜„ ì¤€ë¹„
