# AIStages ìµœì‹  ê¸°ìˆ  ìŠ¤íƒ í™˜ê²½ ì„¤ì • ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” AI ë¶€íŠ¸ìº í”„ AIStages ì„œë²„ì—ì„œ ì¡°ì¥ë‹˜ì˜ ìµœì‹  ê¸°ìˆ  ìŠ¤íƒ(torch 2.6.0, transformers 4.54.0, unsloth)ì„ ì ìš©í•œ í”„ë¡œì íŠ¸ í™˜ê²½ì„ ì„¤ì •í•˜ëŠ” ì™„ì „í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ì—…ê·¸ë ˆì´ë“œ ì‚¬í•­
- **torch**: >=2.0.0 â†’ 2.6.0
- **transformers**: 4.35.2 â†’ 4.54.0 (19ë²„ì „ ëŒ€í­ ì—…ê·¸ë ˆì´ë“œ!)
- **pytorch_lightning**: 2.1.2 â†’ 2.5.2
- **unsloth ì§€ì›**: ê³ ì„±ëŠ¥ íŒŒì¸íŠœë‹ (Linux í™˜ê²½ ìµœì í™”)
- **QLoRA ì§€ì›**: 4-bit ì–‘ìí™”ë¡œ ë©”ëª¨ë¦¬ 30-50% ì ˆì•½
- **ì˜ˆìƒ íš¨ê³¼**: í•™ìŠµ ì†ë„ 20-30% í–¥ìƒ, ë©”ëª¨ë¦¬ 75% ì ˆì•½

## ì£¼ìš” ë‹¨ê³„ ìš”ì•½

### ì„œë²„ ì¬ìƒì„± ë¯¸í•„ìš” (Python 3.11 ì‚¬ìš© ì¤‘)
1. upstream/songì—ì„œ ìƒˆë¡œìš´ ì½”ë“œ pull
2. ìƒˆë¡œìš´ requirements.txtë¡œ í™˜ê²½ ì¬ì„¤ì¹˜: `uv pip install -r requirements.txt`

### ì„œë²„ ì¬ìƒì„± í•„ìš” (Python 3.10 + --system ì‚¬ìš©)
1. ì„œë²„ ë°±ì—… (outputs í´ë” ì œì™¸)
2. ì„œë²„ ì¬ìƒì„±
3. ë°±ì—… íŒŒì¼ ë³µì›
4. ìµœì‹  ë²„ì „ ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
5. conda ê°€ìƒí™˜ê²½ ìƒì„±: `conda create -n [ê°€ìƒí™˜ê²½ ì´ë¦„] python==3.11 -y`
6. requirements.txt ì„¤ì¹˜: `uv pip install -r requirements.txt`

---

## 1. conda ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”

### 1.1 Python 3.11 ê°€ìƒí™˜ê²½ ìƒì„±
```bash
# Python 3.11 ê°€ìƒí™˜ê²½ ìƒì„±
conda create -n nlp-sum-latest python==3.11 -y

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source activate nlp-sum-latest

# Python ë²„ì „ í™•ì¸
python --version  # Python 3.11.x í™•ì¸
```

### 1.2 ê¸°ì¡´ íŒ¨í‚¤ì§€ ì •ë¦¬ (í•„ìš”ì‹œ)
```bash
# íŠ¹ì • íŒ¨í‚¤ì§€ë§Œ ì œê±° (ì „ì²´ ì œê±° ë¶ˆí•„ìš”)
uv pip uninstall torch torchvision torchaudio transformers

# ë˜ëŠ” ìƒˆë¡œìš´ ê°€ìƒí™˜ê²½ ì´ë¦„ ì‚¬ìš©
conda create -n nlp-sum-new python==3.11 -y
source activate nlp-sum-new
```

---

## 2. AIStages Github ì„¤ì •

### 2.1 Git ì„¤ì¹˜ ë° ì„¤ì •
```bash
# Git ì„¤ì¹˜
apt update
apt install -y git

# Git ì‚¬ìš©ì ì •ë³´ ì„¤ì •
git config --global credential.helper store
git config --global user.name "ì—¬ëŸ¬ë¶„ì˜_ê¹ƒí—™_ì‚¬ìš©ìëª…"
git config --global user.email "ì—¬ëŸ¬ë¶„ì˜_ê¹ƒí—™_ì´ë©”ì¼"
git config --global core.pager "cat"

# Vim í¸ì§‘ê¸° ì„¤ì¹˜ ë° ì„¤ì •
apt install -y vim
git config --global core.editor "vim"
```

### 2.2 ì„¤ì • í™•ì¸
```bash
# ì„¤ì • í™•ì¸
git config --list
```

---

## 3. ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

### 3.1 í•œêµ­ì–´ í°íŠ¸ ì„¤ì¹˜
```bash
# í•œêµ­ì–´ í°íŠ¸ ì„¤ì¹˜
apt-get update
apt-get install -y fonts-nanum*

# í°íŠ¸ íŒŒì¼ ìœ„ì¹˜ í™•ì¸
ls /usr/share/fonts/truetype/nanum/Nanum*
```

### 3.2 Curl ì„¤ì¹˜ (UV ì„¤ì¹˜ìš©)
```bash
# curl ì„¤ì¹˜
apt-get install -y curl
```

### 3.3 OpenCV ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
```bash
# OpenCV ì˜ì¡´ì„± ì„¤ì¹˜
apt-get install -y libgl1-mesa-glx
apt-get install -y libglib2.0-0
```

> ğŸ’¡ **íŒ**: `libglib2.0-0` ì„¤ì¹˜ ì‹œ ì§€ì—­ ì„ íƒ í™”ë©´ì´ ë‚˜ì˜¤ë©´ **6ë²ˆ Asia** â†’ **69ë²ˆ Seoul**ì„ ì„ íƒí•˜ì„¸ìš”.

---

## 4. Fork & Clone ì„¤ì •

### 4.1 GitHub Fork
1. ë¸Œë¼ìš°ì €ì—ì„œ íŒ€ ë ˆí¬ì§€í† ë¦¬ ì ‘ì†
2. ìš°ì¸¡ ìƒë‹¨ **Fork** ë²„íŠ¼ í´ë¦­
3. ë³¸ì¸ ê³„ì •ì— Forkëœ ë ˆí¬ì§€í† ë¦¬ ìƒì„± í™•ì¸

### 4.2 ë¡œì»¬ Clone
```bash
# HOME ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd ~/
# AIStagesì˜ HOME ê²½ë¡œ: /data/ephemeral/home/

# Forkí•œ ë ˆí¬ì§€í† ë¦¬ Clone
git clone https://github.com/[ë³¸ì¸_ê¹ƒí—™_ê³„ì •]/upstageailab-nlp-summarization-nlp_5.git

# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd upstageailab-nlp-summarization-nlp_5
```

### 4.3 Upstream ì„¤ì •
```bash
# íŒ€ ë ˆí¬ì§€í† ë¦¬ë¥¼ upstreamìœ¼ë¡œ ì„¤ì •
git remote add upstream https://github.com/AIBootcamp13/upstageailab-nlp-summarization-nlp_5.git

# Push ë°©ì§€ ì„¤ì • (ì‹¤ìˆ˜ ë°©ì§€)
git remote set-url --push upstream no-push

# Remote í™•ì¸
git remote -v
```

### 4.4 Upstream ë™ê¸°í™”
```bash
# íŒ€ ë ˆí¬ì§€í† ë¦¬ì˜ ìµœì‹  ë³€ê²½ì‚¬í•­ ê°€ì ¸ì˜¤ê¸°
git fetch upstream main && git merge FETCH_HEAD
```

---

## 5. UV ì„¤ì • ë° ì‚¬ìš©

### 5.1 UV ì„¤ì¹˜
```bash
# HOME ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd ~/

# UV ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### 5.2 í™˜ê²½ë³€ìˆ˜ ì„¤ì •
```bash
# .bashrc íŒŒì¼ í¸ì§‘
vim ~/.bashrc

# ë‹¤ìŒ ì¤„ ì¶”ê°€ (i í‚¤ë¥¼ ëˆŒëŸ¬ í¸ì§‘ ëª¨ë“œ)
export PATH="/data/ephemeral/home/.local/bin:$PATH"

# ì €ì¥ ë° ì¢…ë£Œ (ESC â†’ :wq)

# ë³€ê²½ì‚¬í•­ ì ìš©
source ~/.bashrc
```

### 5.3 ì„¤ì¹˜ í™•ì¸
```bash
# UV ë²„ì „ í™•ì¸
uv --version
```

### 5.4 ìµœì‹  ê¸°ìˆ  ìŠ¤íƒ ì„¤ì¹˜ (í•„ìˆ˜)

> ğŸ“Œ **ì¤‘ìš”**: conda ê°€ìƒí™˜ê²½ì— ì„¤ì¹˜í•©ë‹ˆë‹¤. `--system` ì˜µì…˜ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€!

#### ìµœì‹  ê¸°ìˆ  ìŠ¤íƒ ì„¤ì¹˜
```bash
# í”„ë¡œì íŠ¸ í´ë”ë¡œ ì´ë™
cd ~/upstageailab-nlp-summarization-nlp_5/nlp-sum-lyj

# conda ê°€ìƒí™˜ê²½ì— ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
uv pip install -r requirements.txt

# ì„¤ì¹˜ ìœ„ì¹˜ í™•ì¸ - conda í™˜ê²½ì— ì„¤ì¹˜ë˜ëŠ”ì§€ í™•ì¸
# /opt/conda/envs/[nlp-sum-latest]/lib/python3.11/site-packages/
```

### 5.5 ìµœì‹  ê¸°ìˆ  ìŠ¤íƒ ì„¤ì¹˜ í™•ì¸
```bash
# ìµœì‹  ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ë° CUDA ì§€ì› í™•ì¸
python -c "
import torch, transformers, pytorch_lightning
print(f'âœ… torch: {torch.__version__}')
print(f'âœ… transformers: {transformers.__version__}')
print(f'âœ… pytorch_lightning: {pytorch_lightning.__version__}')
print(f'âœ… CUDA: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'âœ… GPU: {torch.cuda.get_device_name(0)}')
"

# QLoRA ì§€ì› í™•ì¸
python -c "
try:
    import peft, bitsandbytes
    print('âœ… QLoRA ì§€ì› (peft + bitsandbytes)')
except ImportError:
    print('âŒ QLoRA ì§€ì› ì—†ìŒ')
"

# unsloth ê³ ì„±ëŠ¥ íŒŒì¸íŠœë‹ í™•ì¸
python -c "
try:
    import unsloth
    print('âœ… unsloth ì§€ì› (ê³ ì„±ëŠ¥ íŒŒì¸íŠœë‹ í™œì„±í™”)')
except ImportError:
    print('âŒ unsloth ì„¤ì¹˜ ì‹¤íŒ¨, QLoRA ëª¨ë“œ ì‚¬ìš©')
"

# ì „ì²´ í™˜ê²½ ê²€ì¦
./check_env.sh
```

---

## 6. Config íŒŒì¼ ì„¤ì •

### 6.1 Config íŒŒì¼ ìƒì„±
```bash
# Jupyter Notebook ë˜ëŠ” Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ì‹¤í–‰
jupyter notebook src/configs/generate_config.ipynb
```

### 6.2 ì£¼ìš” ì„¤ì • í•­ëª©

#### 6.2.1 í”„ë¡œì íŠ¸ ê²½ë¡œ
```yaml
project_dir: "/data/ephemeral/home/upstageailab-nlp-summarization-nlp_5"
output_dir: "./outputs/exp_baseline_001"
```

#### 6.2.2 ì¼ë°˜ ì„¤ì •
```yaml
general:
  data_path: "./data/"
  model_name: "digit82/kobart-summarization"
  output_path: "./outputs/"
```

#### 6.2.3 Tokenizer ì„¤ì •
```yaml
tokenizer:
  encoder_max_len: 1024  # ëª¨ë¸ì— ë”°ë¼ ì¡°ì •
  decoder_max_len: 128
  special_tokens:
    - "#Person1#"
    - "#Person2#"
    # ... ì¶”ê°€ í† í°
```

#### 6.2.4 í•™ìŠµ ì„¤ì •
```yaml
training:
  seed: 42
  save_total_limit: 3
  save_eval_log_steps: 500
  num_train_epochs: 20
  per_device_train_batch_size: 16  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •
  generation_max_length: 128
  early_stopping_patience: 3
  learning_rate: 3e-5
  warmup_ratio: 0.1
```

#### 6.2.5 WandB ì„¤ì •
```yaml
wandb:
  entity: "your_wandb_team"
  project: "dialogue-summarization"
  name: "kobart-baseline-v1"
  group: "baseline"
  notes: "KoBART baseline with special tokens"
```

#### 6.2.6 ì¶”ë¡  ì„¤ì •
```yaml
inference:
  batch_size: 32
  num_beams: 4
  no_repeat_ngram_size: 2
```

---

## 7. Main íŒŒì¼ ì‹¤í–‰

### 7.1 í•™ìŠµ ì‹¤í–‰
```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰
python src/main_base.py --config config_base_0725140000.yaml
```

### 7.2 ì¶”ë¡ ë§Œ ì‹¤í–‰
```bash
# ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ë¡œ ì¶”ë¡ 
python src/main_base.py --config config_base_0725140000.yaml --inference True
```

### 7.3 ì‹¤í–‰ ëª¨ë‹ˆí„°ë§
```bash
# ë¡œê·¸ ì‹¤ì‹œê°„ í™•ì¸
tail -f outputs/exp_baseline_001/train.log

# GPU ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
watch -n 1 nvidia-smi
```

---

## 8. ê¸°ì¡´ í”„ë¡œì íŠ¸ì™€ì˜ í†µí•©

### 8.1 í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡°ì™€ì˜ ë§¤í•‘

í˜„ì¬ `nlp-sum-lyj` í”„ë¡œì íŠ¸ êµ¬ì¡°:
```
nlp-sum-lyj/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ baseline.ipynb      # ê¸°ì¡´ ë² ì´ìŠ¤ë¼ì¸
â”‚   â”œâ”€â”€ config.yaml         # ê¸°ì¡´ ì„¤ì •
â”‚   â””â”€â”€ requirements.txt    # ì˜ì¡´ì„±
â”œâ”€â”€ data/
â””â”€â”€ docs/
```

ìƒˆë¡œìš´ êµ¬ì¡° í†µí•© ë°©ì•ˆ:
```
nlp-sum-lyj/
â”œâ”€â”€ src/                    # ìƒˆë¡œ ì¶”ê°€
â”‚   â”œâ”€â”€ main_base.py
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â””â”€â”€ generate_config.ipynb
â”‚   â””â”€â”€ ...
â”œâ”€â”€ code/                   # ê¸°ì¡´ ìœ ì§€
â”œâ”€â”€ data/
â””â”€â”€ docs/
    â””â”€â”€ setup_guides/       # ìƒˆë¡œ ì¶”ê°€
        â””â”€â”€ aistages_environment_setup.md
```

### 8.2 ê¸°ì¡´ ì½”ë“œ ì ìš© ë°©ë²•

#### 8.2.1 ê¸°ì¡´ baseline.ipynb ì‚¬ìš©
```python
# ê¸°ì¡´ ì½”ë“œì˜ config ìˆ˜ì •
config = {
    'general': {
        'data_path': './data/',
        'model_name': 'digit82/kobart-summarization',
        'output_path': './outputs/'
    },
    # ... ìƒˆë¡œìš´ config í˜•ì‹ì— ë§ì¶° ìˆ˜ì •
}
```

#### 8.2.2 UV í™˜ê²½ì—ì„œ ì‹¤í–‰
```bash
# UVë¡œ ì„¤ì¹˜í•œ í™˜ê²½ì—ì„œ Jupyter ì‹¤í–‰
jupyter notebook code/baseline.ipynb
```

### 8.3 ê¶Œì¥ ì›Œí¬í”Œë¡œìš°

1. **í™˜ê²½ ì„¤ì •**: ì´ ë¬¸ì„œì˜ 1-5ë‹¨ê³„ ì§„í–‰
2. **ê¸°ì¡´ ì½”ë“œ ì‹¤í–‰**: `code/baseline.ipynb`ë¡œ ì´ˆê¸° ì‹¤í—˜
3. **ìƒˆ êµ¬ì¡° ì ìš©**: `src/main_base.py` êµ¬ì¡°ë¡œ ì „í™˜
4. **ì‹¤í—˜ ê´€ë¦¬**: WandBë¡œ ì²´ê³„ì ì¸ ì‹¤í—˜ ì¶”ì 

### 8.4 íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

#### UV ì„¤ì¹˜ ì‹¤íŒ¨
```bash
# ëŒ€ì•ˆ: pipìœ¼ë¡œ UV ì„¤ì¹˜
pip install uv
```

#### CUDA ì˜¤ë¥˜
```bash
# PyTorch CUDA ë²„ì „ í™•ì¸
python -c "import torch; print(torch.cuda.is_available())"
```

#### ë©”ëª¨ë¦¬ ë¶€ì¡±
```yaml
# configì—ì„œ batch size ê°ì†Œ
per_device_train_batch_size: 8
gradient_accumulation_steps: 2
```

---

## ìš”ì•½

ì´ ê°€ì´ë“œëŠ” AIStages í™˜ê²½ì—ì„œ NLP ìš”ì•½ í”„ë¡œì íŠ¸ë¥¼ ì„¤ì •í•˜ëŠ” ì™„ì „í•œ ê³¼ì •ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ì°¨ì´ì :

1. **UV ì‚¬ìš©**: pipë³´ë‹¤ 10-100ë°° ë¹ ë¥¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜
2. **ì‹œìŠ¤í…œ ì„¤ì¹˜**: Docker í™˜ê²½ì´ë¯€ë¡œ `--system` ì˜µì…˜ ì‚¬ìš©
3. **ê²½ë¡œ ì„¤ì •**: AIStagesì˜ íŠ¹ìˆ˜ ê²½ë¡œ êµ¬ì¡° ê³ ë ¤
4. **Git ì›Œí¬í”Œë¡œìš°**: Fork & Clone ë°©ì‹ì˜ í˜‘ì—…

ê¸°ì¡´ í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ìƒˆë¡œìš´ í™˜ê²½ ì„¤ì •ì„ ì ìš©í•  ìˆ˜ ìˆìœ¼ë©°, í•„ìš”ì— ë”°ë¼ ì ì§„ì ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
