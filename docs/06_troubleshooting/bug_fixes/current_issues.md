# ë²„ê·¸ ìˆ˜ì • ë° ì½”ë“œ ê°œì„  ì‚¬í•­

## ğŸ¯ ê°œìš”

í˜„ì¬ ì½”ë“œì—ì„œ ë°œê²¬ëœ **ë²„ê·¸**ì™€ **ê°œì„ ì´ í•„ìš”í•œ ì‚¬í•­**ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ìˆ˜ì •ë“¤ì€ ì‹œìŠ¤í…œ ì•ˆì •ì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì„ ìœ„í•´ **ë°˜ë“œì‹œ ì²˜ë¦¬**ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

---

## ğŸ”´ Critical Bugs (ì¦‰ì‹œ ìˆ˜ì • í•„ìš”)

### 1. trainer.py - ì ˆëŒ€ ê²½ë¡œ í•˜ë“œì½”ë”©

#### ë¬¸ì œ ìœ„ì¹˜
```python
# code/trainer.py, ë¼ì¸ ì•½ 80-90
def setup_paths(self):
    base_output_dir = Path(self.config['general']['output_dir'])
    
    # ë¬¸ì œ: ì ˆëŒ€ ê²½ë¡œê°€ í•˜ë“œì½”ë”©ë  ê°€ëŠ¥ì„±
    if self.sweep_mode and wandb.run:
        self.output_dir = base_output_dir / f"sweep_{wandb.run.id}"
    else:
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.output_dir = base_output_dir / f"{self.experiment_name}_{timestamp}"
```

#### ìˆ˜ì • ë°©ì•ˆ
```python
# ìˆ˜ì •ëœ ì½”ë“œ
from utils.path_utils import PathManager

def setup_paths(self):
    # PathManagerë¥¼ ì‚¬ìš©í•œ ì•ˆì „í•œ ê²½ë¡œ ì²˜ë¦¬
    base_output_dir = PathManager.resolve_path(self.config['general']['output_dir'])
    
    if self.sweep_mode and wandb.run:
        self.output_dir = base_output_dir / f"sweep_{wandb.run.id}"
    else:
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.output_dir = base_output_dir / f"{self.experiment_name}_{timestamp}"
    
    # ë””ë ‰í† ë¦¬ ì¡´ì¬ ë³´ì¥
    PathManager.ensure_dir(self.output_dir)
```

### 2. config_manager.py - í™˜ê²½ë³€ìˆ˜ ë§¤í•‘ ë¶€ì¡±

#### ë¬¸ì œ ìœ„ì¹˜
```python
# code/utils/config_manager.py, ë¼ì¸ ì•½ 40-50
self._env_mapping = {
    'WANDB_PROJECT': 'wandb.project',
    'WANDB_ENTITY': 'wandb.entity', 
    'MODEL_NAME': 'general.model_name',
    'OUTPUT_DIR': 'general.output_dir',
    'BATCH_SIZE': 'training.per_device_train_batch_size',
    'LEARNING_RATE': 'training.learning_rate',
    'NUM_EPOCHS': 'training.num_train_epochs'
}
```

#### ìˆ˜ì • ë°©ì•ˆ
```python
# í™•ì¥ëœ í™˜ê²½ë³€ìˆ˜ ë§¤í•‘
self._env_mapping = {
    # ê¸°ì¡´ ë§¤í•‘
    'WANDB_PROJECT': 'wandb.project',
    'WANDB_ENTITY': 'wandb.entity',
    'MODEL_NAME': 'general.model_name',
    'OUTPUT_DIR': 'general.output_dir',
    'BATCH_SIZE': 'training.per_device_train_batch_size',
    'LEARNING_RATE': 'training.learning_rate',
    'NUM_EPOCHS': 'training.num_train_epochs',
    
    # ì¶”ê°€ ë§¤í•‘ (í¬ë¡œìŠ¤ í”Œë«í¼ ì§€ì›)
    'DATA_PATH': 'general.data_path',
    'MODEL_ARCHITECTURE': 'model.architecture',
    'MODEL_CHECKPOINT': 'model.checkpoint',
    'ENCODER_MAX_LEN': 'tokenizer.encoder_max_len',
    'DECODER_MAX_LEN': 'tokenizer.decoder_max_len',
    'NUM_BEAMS': 'generation.num_beams',
    'FP16': 'training.fp16',
    'SEED': 'general.seed',
    'DEVICE': 'general.device',
    
    # AI Stages íŠ¹í™” í™˜ê²½ë³€ìˆ˜
    'AISTAGES_DATA_DIR': 'general.data_path',
    'AISTAGES_OUTPUT_DIR': 'general.output_dir',
    'CUDA_VISIBLE_DEVICES': 'general.visible_devices'
}
```

### 3. scripts/setup_aistages.sh - í•˜ë“œì½”ë”©ëœ ê²½ë¡œ

#### ë¬¸ì œ ìœ„ì¹˜
```bash
# code/scripts/setup_aistages.sh, ë¼ì¸ ì•½ 20-25
export PATH="/data/ephemeral/home/.local/bin:$PATH"
echo 'export PATH="/data/ephemeral/home/.local/bin:$PATH"' >> ~/.bashrc
```

#### ìˆ˜ì • ë°©ì•ˆ
```bash
# ë™ì  ê²½ë¡œ íƒì§€
USER_HOME=$(eval echo ~$USER)
LOCAL_BIN_DIR="$USER_HOME/.local/bin"

# UV ì„¤ì¹˜ ê²½ë¡œ ë™ì  íƒì§€
if [ -f "$LOCAL_BIN_DIR/uv" ]; then
    UV_PATH="$LOCAL_BIN_DIR"
elif command -v uv &> /dev/null; then
    UV_PATH=$(dirname $(which uv))
else
    echo "UV ì„¤ì¹˜ ì¤‘..."
    curl -LsSf https://astral.sh/uv/install.sh | sh
    UV_PATH="$USER_HOME/.local/bin"
fi

# PATH ì—…ë°ì´íŠ¸
export PATH="$UV_PATH:$PATH"
if ! grep -q "$UV_PATH" ~/.bashrc; then
    echo "export PATH=\"$UV_PATH:\$PATH\"" >> ~/.bashrc
fi
```

---

## ğŸŸ¡ ì¤‘ìš”í•œ ê°œì„  ì‚¬í•­

### 4. data_utils.py - ì—ëŸ¬ ì²˜ë¦¬ ë¶€ì¡±

#### ë¬¸ì œ ìœ„ì¹˜
```python
# code/utils/data_utils.py ì „ë°˜
def load_dataset(self, file_path: Union[str, Path]) -> pd.DataFrame:
    df = pd.read_csv(file_path)  # ì—ëŸ¬ ì²˜ë¦¬ ë¶€ì¡±
    return df
```

#### ìˆ˜ì • ë°©ì•ˆ
```python
def load_dataset(self, file_path: Union[str, Path]) -> pd.DataFrame:
    """
    ë°ì´í„°ì…‹ ë¡œë”© (ê°œì„ ëœ ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)
    """
    from utils.path_utils import PathManager
    
    # ê²½ë¡œ í•´ê²°
    file_path = PathManager.resolve_path(file_path)
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not file_path.exists():
        raise FileNotFoundError(f"Dataset file not found: {file_path}")
    
    # íŒŒì¼ ê¶Œí•œ í™•ì¸
    if not file_path.is_file():
        raise ValueError(f"Path is not a file: {file_path}")
    
    try:
        # ì¸ì½”ë”© ìë™ ê°ì§€ ì‹œë„
        encodings = ['utf-8', 'cp949', 'euc-kr', 'latin-1']
        df = None
        
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                self.logger.info(f"Successfully loaded with encoding: {encoding}")
                break
            except UnicodeDecodeError:
                continue
        
        if df is None:
            raise ValueError(f"Could not read file with any supported encoding: {encodings}")
        
        # ë¹ˆ íŒŒì¼ í™•ì¸
        if df.empty:
            raise ValueError(f"Dataset file is empty: {file_path}")
        
        self.logger.info(f"Loaded dataset: {len(df)} samples from {file_path}")
        return df
        
    except pd.errors.EmptyDataError:
        raise ValueError(f"Dataset file is empty or invalid: {file_path}")
    except pd.errors.ParserError as e:
        raise ValueError(f"Failed to parse CSV file: {e}")
    except Exception as e:
        self.logger.error(f"Unexpected error loading dataset: {e}")
        raise
```

### 5. sweep_runner.py - ë©”ëª¨ë¦¬ ê´€ë¦¬ ë¶€ì¡±

#### ë¬¸ì œ ìœ„ì¹˜
```python
# code/sweep_runner.py, train_function ë©”ì„œë“œ
def train_function(self):
    # ... í•™ìŠµ ì½”ë“œ ...
    # ë¬¸ì œ: ë©”ëª¨ë¦¬ ì •ë¦¬ ì—†ìŒ
    result = trainer.train(datasets)
    return result  # ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ê°€ëŠ¥ì„±
```

#### ìˆ˜ì • ë°©ì•ˆ
```python
def train_function(self):
    """
    ë‹¨ì¼ Sweep ì‹¤í–‰ì„ ìœ„í•œ í•™ìŠµ í•¨ìˆ˜ (ë©”ëª¨ë¦¬ ìµœì í™”)
    """
    run = wandb.run
    
    if run is None:
        raise RuntimeError("WandB run not initialized")
    
    trainer = None
    try:
        # Sweep íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
        sweep_params = dict(wandb.config)
        
        logger.info(f"Starting sweep run: {run.id}")
        logger.info(f"Sweep parameters: {sweep_params}")
        
        # ê¸°ë³¸ ì„¤ì •ì— Sweep íŒŒë¼ë¯¸í„° ë³‘í•©
        config = self.config_manager.merge_sweep_params(sweep_params)
        
        # ì‹¤í—˜ëª… ìƒì„±
        experiment_name = self._generate_experiment_name(sweep_params)
        
        # íŠ¸ë ˆì´ë„ˆ ìƒì„±
        trainer = DialogueSummarizationTrainer(
            config=config,
            sweep_mode=True,
            experiment_name=experiment_name
        )
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
        trainer.initialize_components()
        
        # ë°ì´í„° ì¤€ë¹„
        datasets = trainer.prepare_data()
        
        # í•™ìŠµ ì‹¤í–‰
        result = trainer.train(datasets)
        
        # WandBì— ìµœì¢… ê²°ê³¼ ë¡œê¹…
        wandb.run.summary.update({
            'best_rouge1_f1': result.best_metrics.get('rouge1_f1', 0),
            'best_rouge2_f1': result.best_metrics.get('rouge2_f1', 0),
            'best_rougeL_f1': result.best_metrics.get('rougeL_f1', 0),
            'best_rouge_combined_f1': result.best_metrics.get('rouge_combined_f1', 0),
            'final_loss': result.final_metrics.get('eval_loss', 0),
            'model_path': result.model_path
        })
        
        # ê²°ê³¼ ì €ì¥
        self._save_sweep_result(run.id, sweep_params, result)
        
        logger.info(f"Sweep run {run.id} completed successfully")
        logger.info(f"Best ROUGE combined F1: {result.best_metrics.get('rouge_combined_f1', 0):.4f}")
        
        return result
        
    except Exception as e:
        logger.error(f"Sweep run failed: {str(e)}")
        wandb.run.summary['status'] = 'failed'
        wandb.run.summary['error'] = str(e)
        raise
    
    finally:
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        if trainer is not None:
            # ëª¨ë¸ ë©”ëª¨ë¦¬ í•´ì œ
            if hasattr(trainer, 'model') and trainer.model is not None:
                del trainer.model
            if hasattr(trainer, 'tokenizer') and trainer.tokenizer is not None:
                del trainer.tokenizer
            del trainer
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        # Python ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
        import gc
        gc.collect()
```

### 6. utils/__init__.py íŒŒì¼ ëˆ„ë½

#### ë¬¸ì œ
```
code/utils/ ë””ë ‰í† ë¦¬ì— __init__.py íŒŒì¼ì´ ì—†ì–´ Python ëª¨ë“ˆë¡œ ì¸ì‹ë˜ì§€ ì•ŠìŒ
```

#### ìˆ˜ì • ë°©ì•ˆ
```python
# code/utils/__init__.py (ì‹ ê·œ ìƒì„±)
"""
NLP Dialogue Summarization Utils Package

ì´ íŒ¨í‚¤ì§€ëŠ” NLP ëŒ€í™” ìš”ì•½ í”„ë¡œì íŠ¸ì˜ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤.
"""

from .config_manager import ConfigManager, load_config
from .data_utils import DataProcessor, TextPreprocessor, DialogueSummarizationDataset
from .metrics import RougeCalculator

# ë²„ì „ ì •ë³´
__version__ = "1.0.0"
__author__ = "NLP Team 5"

# ê³µí†µ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def get_project_info():
    """í”„ë¡œì íŠ¸ ì •ë³´ ë°˜í™˜"""
    return {
        "name": "NLP Dialogue Summarization",
        "version": __version__,
        "author": __author__,
        "description": "AI ë¶€íŠ¸ìº í”„ 13ê¸° NLP Advanced ëŒ€í™” ìš”ì•½ í”„ë¡œì íŠ¸"
    }

# ëª¨ë“ˆ ì„í¬íŠ¸ ì‹œ ìë™ ì‹¤í–‰ë˜ëŠ” ì„¤ì •
import logging
import warnings

# ë¡œê¹… ì„¤ì •
logging.getLogger(__name__).addHandler(logging.NullHandler())

# ë¶ˆí•„ìš”í•œ ê²½ê³  ì–µì œ
warnings.filterwarnings("ignore", category=FutureWarning, module="transformers")
warnings.filterwarnings("ignore", category=UserWarning, module="torch")

__all__ = [
    'ConfigManager',
    'load_config', 
    'DataProcessor',
    'TextPreprocessor',
    'DialogueSummarizationDataset',
    'RougeCalculator',
    'get_project_info'
]
```

### 7. requirements.txt ì˜ì¡´ì„± ë²„ì „ ì´ìŠˆ

#### ë¬¸ì œ ìœ„ì¹˜
```txt
# code/requirements.txt
pandas==2.1.4
numpy==1.23.5
wandb==0.16.1
tqdm==4.66.1
pytorch_lightning==2.1.2  # ì‹¤ì œë¡œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
transformers[torch]==4.35.2
rouge==1.0.1
jupyter==1.0.0
jupyterlab==4.0.9
```

#### ìˆ˜ì • ë°©ì•ˆ
```txt
# ìˆ˜ì •ëœ requirements.txt
# ë°ì´í„° ì²˜ë¦¬
pandas>=2.1.0,<3.0.0
numpy>=1.23.0,<2.0.0

# ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
torch>=2.0.0,<3.0.0
transformers[torch]>=4.35.0,<5.0.0

# í‰ê°€ ë° ëª¨ë‹ˆí„°ë§
evaluate>=0.4.0  # rouge ëŒ€ì‹  ì‚¬ìš©
wandb>=0.16.0,<1.0.0

# ìœ í‹¸ë¦¬í‹°
tqdm>=4.60.0
pyyaml>=6.0
pathlib2>=2.3.0; python_version < "3.4"

# í•œêµ­ì–´ ì²˜ë¦¬ (ì„ íƒì )
konlpy>=0.6.0; extra == "korean"

# ê°œë°œ í™˜ê²½
jupyter>=1.0.0
jupyterlab>=4.0.0

# ì¶”ê°€ ì˜ì¡´ì„±
scipy>=1.9.0  # í†µê³„ ê³„ì‚°ìš©
matplotlib>=3.5.0  # ê·¸ë˜í”„ ìƒì„±ìš©
seaborn>=0.11.0  # ë°ì´í„° ì‹œê°í™”ìš©
psutil>=5.8.0  # ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ìš©

# ì„ íƒì  ì˜ì¡´ì„± (ì„±ëŠ¥ ìµœì í™”)
accelerate>=0.20.0; extra == "accelerate"
deepspeed>=0.9.0; extra == "deepspeed"
```

---

## ğŸŸ¢ ê°œì„  ê¶Œì¥ ì‚¬í•­

### 8. ë¡œê¹… ì‹œìŠ¤í…œ í‘œì¤€í™”

#### í˜„ì¬ ë¬¸ì œ
ê° ëª¨ë“ˆë§ˆë‹¤ ë‹¤ë¥¸ ë¡œê¹… ë°©ì‹ ì‚¬ìš©

#### ê°œì„  ë°©ì•ˆ
```python
# code/utils/logging_utils.py (ì‹ ê·œ ìƒì„±)
import logging
import sys
from pathlib import Path
from typing import Optional
from utils.path_utils import PathManager

def setup_logger(name: str, 
                log_file: Optional[str] = None,
                level: str = "INFO",
                format_string: Optional[str] = None) -> logging.Logger:
    """
    í‘œì¤€í™”ëœ ë¡œê±° ì„¤ì •
    
    Args:
        name: ë¡œê±° ì´ë¦„
        log_file: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ì½˜ì†”ë§Œ)
        level: ë¡œê¹… ë ˆë²¨
        format_string: ì»¤ìŠ¤í…€ í¬ë§· ë¬¸ìì—´
    """
    logger = logging.getLogger(name)
    
    # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
    for handler in logger.handlers[:]:
        logger.removeHandler(handler)
    
    logger.setLevel(getattr(logging, level.upper()))
    
    # ê¸°ë³¸ í¬ë§·
    if format_string is None:
        format_string = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    formatter = logging.Formatter(format_string)
    
    # ì½˜ì†” í•¸ë“¤ëŸ¬
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    # íŒŒì¼ í•¸ë“¤ëŸ¬ (ì„ íƒì )
    if log_file:
        log_path = PathManager.resolve_path(log_file)
        PathManager.ensure_dir(log_path.parent)
        
        file_handler = logging.FileHandler(log_path, encoding='utf-8')
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
    
    return logger

# í”„ë¡œì íŠ¸ ì „ì²´ì—ì„œ ì‚¬ìš©í•  ë¡œê±° íŒ©í† ë¦¬
def get_logger(module_name: str) -> logging.Logger:
    """ëª¨ë“ˆë³„ í‘œì¤€ ë¡œê±° ë°˜í™˜"""
    output_dir = PathManager.get_output_dir()
    log_file = output_dir / "logs" / f"{module_name}.log"
    
    return setup_logger(
        name=module_name,
        log_file=str(log_file),
        level="INFO"
    )
```

### 9. ì„¤ì • ê²€ì¦ ê°•í™”

#### ê°œì„  ë°©ì•ˆ
```python
# code/utils/config_validator.py (ì‹ ê·œ ìƒì„±)
from typing import Dict, Any, List, Tuple
import os
from pathlib import Path

class ConfigValidator:
    """ì„¤ì • ê²€ì¦ê¸°"""
    
    def __init__(self):
        self.validation_rules = self._load_validation_rules()
    
    def _load_validation_rules(self) -> Dict[str, Any]:
        """ê²€ì¦ ê·œì¹™ ì •ì˜"""
        return {
            'training': {
                'learning_rate': {
                    'type': (int, float),
                    'range': (1e-7, 1e-2),
                    'required': True
                },
                'per_device_train_batch_size': {
                    'type': int,
                    'range': (1, 512),
                    'required': True
                },
                'num_train_epochs': {
                    'type': int,
                    'range': (1, 1000),
                    'required': True
                },
                'warmup_ratio': {
                    'type': (int, float),
                    'range': (0.0, 1.0),
                    'required': False
                }
            },
            'tokenizer': {
                'encoder_max_len': {
                    'type': int,
                    'range': (1, 8192),
                    'required': True
                },
                'decoder_max_len': {
                    'type': int,
                    'range': (1, 2048),
                    'required': True
                }
            },
            'generation': {
                'num_beams': {
                    'type': int,
                    'range': (1, 20),
                    'required': False
                },
                'length_penalty': {
                    'type': (int, float),
                    'range': (0.1, 3.0),
                    'required': False
                }
            }
        }
    
    def validate_config(self, config: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """
        ì„¤ì • ê²€ì¦
        
        Returns:
            (ê²€ì¦ í†µê³¼ ì—¬ë¶€, ì˜¤ë¥˜ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸)
        """
        errors = []
        
        for section_name, section_rules in self.validation_rules.items():
            if section_name not in config:
                errors.append(f"Missing required section: {section_name}")
                continue
            
            section_config = config[section_name]
            
            for param_name, rules in section_rules.items():
                # í•„ìˆ˜ íŒŒë¼ë¯¸í„° í™•ì¸
                if rules.get('required', False) and param_name not in section_config:
                    errors.append(f"Missing required parameter: {section_name}.{param_name}")
                    continue
                
                if param_name not in section_config:
                    continue  # ì„ íƒì  íŒŒë¼ë¯¸í„°
                
                value = section_config[param_name]
                
                # íƒ€ì… ê²€ì¦
                if 'type' in rules:
                    expected_types = rules['type']
                    if not isinstance(expected_types, tuple):
                        expected_types = (expected_types,)
                    
                    if not isinstance(value, expected_types):
                        errors.append(f"Invalid type for {section_name}.{param_name}: "
                                    f"expected {expected_types}, got {type(value)}")
                        continue
                
                # ë²”ìœ„ ê²€ì¦
                if 'range' in rules and isinstance(value, (int, float)):
                    min_val, max_val = rules['range']
                    if not (min_val <= value <= max_val):
                        errors.append(f"Value out of range for {section_name}.{param_name}: "
                                    f"{value} not in [{min_val}, {max_val}]")
        
        # êµì°¨ ê²€ì¦ (ì˜ˆ: encoder_max_len > decoder_max_len)
        cross_validation_errors = self._cross_validate(config)
        errors.extend(cross_validation_errors)
        
        return len(errors) == 0, errors
    
    def _cross_validate(self, config: Dict[str, Any]) -> List[str]:
        """êµì°¨ ê²€ì¦"""
        errors = []
        
        # í† í¬ë‚˜ì´ì € ê¸¸ì´ ê²€ì¦
        if 'tokenizer' in config:
            tokenizer_config = config['tokenizer']
            encoder_len = tokenizer_config.get('encoder_max_len')
            decoder_len = tokenizer_config.get('decoder_max_len')
            
            if encoder_len and decoder_len and decoder_len > encoder_len:
                errors.append("decoder_max_len should not be greater than encoder_max_len")
        
        # ë°°ì¹˜ í¬ê¸°ì™€ ë©”ëª¨ë¦¬ ê²€ì¦
        if 'training' in config and 'tokenizer' in config:
            batch_size = config['training'].get('per_device_train_batch_size', 0)
            seq_len = config['tokenizer'].get('encoder_max_len', 0)
            
            # ê°„ë‹¨í•œ ë©”ëª¨ë¦¬ ì¶”ì • (GPU ë©”ëª¨ë¦¬ ê¸°ë°˜)
            estimated_memory_gb = (batch_size * seq_len * 4) / (1024**3)  # ë§¤ìš° ë‹¨ìˆœí™”
            
            if estimated_memory_gb > 16:  # 16GB ì„ê³„ê°’
                errors.append(f"Configuration may require too much memory (~{estimated_memory_gb:.1f}GB). "
                            f"Consider reducing batch_size or encoder_max_len")
        
        return errors
```

---

## ğŸ“‹ ìˆ˜ì • ìš°ì„ ìˆœìœ„ ë° ì¼ì •

### ğŸ”´ Critical (ì¦‰ì‹œ ìˆ˜ì • - Week 1)
1. **ê²½ë¡œ ì²˜ë¦¬ ê°œì„ ** (trainer.py, config_manager.py) - 2ì‹œê°„
2. **setup_aistages.sh ê²½ë¡œ ìˆ˜ì •** - 1ì‹œê°„
3. **utils/__init__.py ì¶”ê°€** - 30ë¶„

### ğŸŸ¡ ì¤‘ìš” (Week 1-2 ì¤‘)
4. **data_utils.py ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”** - 3ì‹œê°„
5. **sweep_runner.py ë©”ëª¨ë¦¬ ê´€ë¦¬** - 2ì‹œê°„
6. **requirements.txt ì •ë¦¬** - 1ì‹œê°„

### ğŸŸ¢ ê°œì„  (Week 2-3 ì¤‘)
7. **ë¡œê¹… ì‹œìŠ¤í…œ í‘œì¤€í™”** - 4ì‹œê°„
8. **ì„¤ì • ê²€ì¦ ê°•í™”** - 3ì‹œê°„

---

## ğŸ› ï¸ ìˆ˜ì • ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ê¸´ê¸‰ ìˆ˜ì • (Day 1-2)
- [ ] PathManager í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ
- [ ] trainer.py ê²½ë¡œ ì²˜ë¦¬ ìˆ˜ì •
- [ ] config_manager.py í™˜ê²½ë³€ìˆ˜ ë§¤í•‘ í™•ì¥
- [ ] setup_aistages.sh ë™ì  ê²½ë¡œ ì²˜ë¦¬
- [ ] utils/__init__.py ì¶”ê°€

### Phase 2: ì•ˆì •ì„± ê°œì„  (Day 3-5)
- [ ] data_utils.py ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
- [ ] sweep_runner.py ë©”ëª¨ë¦¬ ê´€ë¦¬ ê°œì„ 
- [ ] requirements.txt ì˜ì¡´ì„± ì •ë¦¬
- [ ] í¬ë¡œìŠ¤ í”Œë«í¼ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰

### Phase 3: í’ˆì§ˆ í–¥ìƒ (Week 2)
- [ ] ë¡œê¹… ì‹œìŠ¤í…œ í‘œì¤€í™”
- [ ] ì„¤ì • ê²€ì¦ ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ì½”ë“œ ìŠ¤íƒ€ì¼ í†µì¼
- [ ] ë¬¸ì„œí™” ì—…ë°ì´íŠ¸

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### í¬ë¡œìŠ¤ í”Œë«í¼ í…ŒìŠ¤íŠ¸
```bash
# Windowsì—ì„œ í…ŒìŠ¤íŠ¸
python -c "from utils.path_utils import PathManager; print(PathManager.get_project_root())"

# macOSì—ì„œ í…ŒìŠ¤íŠ¸  
python -c "from utils.path_utils import PathManager; print(PathManager.get_project_root())"

# Linuxì—ì„œ í…ŒìŠ¤íŠ¸
python -c "from utils.path_utils import PathManager; print(PathManager.get_project_root())"
```

### ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í…ŒìŠ¤íŠ¸
```python
# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
import psutil
import torch

def test_memory_leak():
    initial_memory = psutil.virtual_memory().used
    initial_gpu = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
    
    # ì—¬ëŸ¬ ë²ˆ í•™ìŠµ ì‹¤í–‰
    for i in range(5):
        # í•™ìŠµ ì‹¤í–‰
        result = run_training()
        
        # ë©”ëª¨ë¦¬ ì²´í¬
        current_memory = psutil.virtual_memory().used
        current_gpu = torch.cuda.memory_allocated() if torch.cuda.is_available() else 0
        
        print(f"Iteration {i}: CPU +{(current_memory - initial_memory) / 1024**2:.1f}MB, "
              f"GPU +{(current_gpu - initial_gpu) / 1024**2:.1f}MB")
```

---

## ğŸ“ˆ ê°œì„  íš¨ê³¼ ì˜ˆìƒ

### ì•ˆì •ì„± í–¥ìƒ
- **í¬ë¡œìŠ¤ í”Œë«í¼ í˜¸í™˜ì„±**: 100% â†’ Windows, macOS, Linux ëª¨ë‘ ì§€ì›
- **ì—ëŸ¬ ë°œìƒë¥ **: 50% ê°ì†Œ â†’ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€ì™€ ì²˜ë¦¬
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: 30% í–¥ìƒ â†’ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€

### ê°œë°œ íš¨ìœ¨ì„± í–¥ìƒ
- **ë””ë²„ê¹… ì‹œê°„**: 40% ë‹¨ì¶• â†’ í‘œì¤€í™”ëœ ë¡œê¹…
- **ì„¤ì • ì˜¤ë¥˜**: 80% ê°ì†Œ â†’ ìë™ ê²€ì¦ ì‹œìŠ¤í…œ
- **í™˜ê²½ ì„¤ì • ì‹œê°„**: 70% ë‹¨ì¶• â†’ ìë™ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸

### ìœ ì§€ë³´ìˆ˜ì„± í–¥ìƒ
- **ì½”ë“œ ì¼ê´€ì„±**: í¬ê²Œ í–¥ìƒ â†’ í‘œì¤€í™”ëœ êµ¬ì¡°
- **ìƒˆ ê¸°ëŠ¥ ì¶”ê°€**: ìš©ì´ â†’ ëª¨ë“ˆí™”ëœ ì•„í‚¤í…ì²˜
- **íŒ€ í˜‘ì—…**: í–¥ìƒ â†’ ëª…í™•í•œ ì»¨ë²¤ì…˜

ì´ëŸ¬í•œ ìˆ˜ì •ë“¤ì„ í†µí•´ í”„ë¡œì íŠ¸ì˜ ì•ˆì •ì„±ê³¼ í™•ì¥ì„±ì„ í¬ê²Œ í–¥ìƒì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.