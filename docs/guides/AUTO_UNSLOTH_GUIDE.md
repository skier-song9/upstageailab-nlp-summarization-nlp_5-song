# ğŸš€ ìƒˆë¡œìš´ ëª¨ë¸ ìë™ Unsloth í™œì„±í™” ê°€ì´ë“œ

## ğŸ“Š ì‹œìŠ¤í…œ ê°œìš”

ì´ì œ **ëª¨ë“  ìƒˆë¡œìš´ ëª¨ë¸**ì´ ì¶”ê°€ë  ë•Œ **í™˜ê²½ì„ ìë™ìœ¼ë¡œ ê°ì§€**í•˜ê³ , **Ubuntu + CUDA í™˜ê²½**ì—ì„œëŠ” **ìë™ìœ¼ë¡œ Unslothë¥¼ í™œì„±í™”**í•©ë‹ˆë‹¤.

## âš¡ ìë™ í™œì„±í™” ì¡°ê±´

### âœ… **Unsloth ìë™ í™œì„±í™” ì¡°ê±´**
1. **OS**: Ubuntu (Linux)
2. **CUDA**: ì‚¬ìš© ê°€ëŠ¥ (torch.cuda.is_available() == True)
3. **GPU ë©”ëª¨ë¦¬**: 6GB ì´ìƒ
4. **CUDA ë²„ì „**: 11.8 ì´ìƒ
5. **Unsloth íŒ¨í‚¤ì§€**: ì„¤ì¹˜ë¨

### ğŸ¯ **ìë™ ìµœì í™” ì ìš©**
- **RTX 3090 (24GB)**: batch_size=12, bf16=True
- **RTX 4080 (16GB)**: batch_size=8, fp16=True  
- **RTX 4070 (12GB)**: batch_size=6, fp16=True
- **RTX 4060 (8GB)**: batch_size=4, fp16=True

## ğŸ”§ ìƒˆë¡œìš´ ëª¨ë¸ ì„¤ì • ë°©ë²•

### 1. **ì„¤ì • íŒŒì¼ì—ì„œ ëª…ì‹œì  í™œì„±í™”**
```yaml
# config/new_model.yaml
model:
  architecture: t5
  checkpoint: my-new-t5-model

qlora:
  use_unsloth: true    # ëª…ì‹œì  í™œì„±í™”
  use_qlora: true
```

### 2. **í™˜ê²½ ìë™ ê°ì§€ ì˜ì¡´ (ê¶Œì¥)**
```yaml
# config/new_model.yaml
model:
  architecture: bart
  checkpoint: my-new-bart-model

qlora:
  # use_unslothë¥¼ ëª…ì‹œí•˜ì§€ ì•ŠìŒ
  # â†’ Ubuntu + CUDA í™˜ê²½ì—ì„œ ìë™ í™œì„±í™”
  use_qlora: true
```

### 3. **ìë™ ê°ì§€ ë¬´ì‹œ (ë¹„í™œì„±í™”)**
```yaml
# config/new_model.yaml
model:
  architecture: gpt2
  checkpoint: my-new-gpt2-model

qlora:
  use_unsloth: false   # ëª…ì‹œì  ë¹„í™œì„±í™”
  use_qlora: true
```

## ğŸ¯ ìš°ì„ ìˆœìœ„ ê·œì¹™

```python
# Unsloth í™œì„±í™” ê²°ì • ë¡œì§
config_use_unsloth = qlora_config.get('use_unsloth', False)
auto_use_unsloth = auto_config.get('use_unsloth', False)

# ìµœì¢… ê²°ì •: ì„¤ì •íŒŒì¼ OR ìë™ê°ì§€
use_unsloth = (config_use_unsloth or auto_use_unsloth) and UNSLOTH_AVAILABLE
```

**ìš°ì„ ìˆœìœ„:**
1. **ì„¤ì • íŒŒì¼ ëª…ì‹œ** (`use_unsloth: true/false`)
2. **í™˜ê²½ ìë™ ê°ì§€** (Ubuntu + CUDA + GPU ë©”ëª¨ë¦¬ ì¶©ë¶„)
3. **ê¸°ë³¸ê°’** (`false`)

## ğŸ“± ì‹¤í–‰ ì‹œ ë¡œê·¸ ì˜ˆì‹œ

### âœ… **AIStages ì„œë²„ (ìë™ í™œì„±í™”)**
```
ğŸ” ìë™ í™˜ê²½ ê°ì§€ ê²°ê³¼
============================================================
OS: Linux (Ubuntu 20.04)
Python: 3.11.13
CPU Cores: 48
ğŸ® CUDA: Available (v12.6)
GPU Count: 1
  - NVIDIA GeForce RTX 3090: 24.0GB

âš¡ Unsloth ì§€ì›
ì¶”ì²œ ì—¬ë¶€: âœ… ì¶”ì²œ
ì„¤ì¹˜ ìƒíƒœ: âœ… ì„¤ì¹˜ë¨

ğŸš€ ìë™ ìµœì í™” ì„¤ì •
use_unsloth: True
recommended_batch_size: 12
fp16: False, bf16: True
dataloader_num_workers: 8
============================================================

ğŸš€ í™˜ê²½ ìë™ ê°ì§€: Ubuntu + CUDA í™˜ê²½ì—ì„œ Unsloth ìë™ í™œì„±í™”
ğŸ“Š ê¸°ë³¸ ë°°ì¹˜ í¬ê¸° ê¶Œì¥: 12
Loading model: my-new-model (t5)
QLoRA enabled: True, unsloth enabled: True
ğŸš€ unslothë¡œ ê³ íš¨ìœ¨ ëª¨ë¸ ë¡œë”© ì¤‘...
```

### âŒ **macOS (ìë™ ë¹„í™œì„±í™”)**
```
ğŸ” ìë™ í™˜ê²½ ê°ì§€ ê²°ê³¼
============================================================
OS: Darwin (macOS 14.0)
Python: 3.11.13
ğŸ® CUDA: Not Available

âš¡ Unsloth ì§€ì›
ì¶”ì²œ ì—¬ë¶€: âŒ ë¹„ì¶”ì²œ
ì„¤ì¹˜ ìƒíƒœ: âŒ ë¯¸ì„¤ì¹˜

ğŸš€ ìë™ ìµœì í™” ì„¤ì •
use_unsloth: False
recommended_batch_size: 2
fp16: False, bf16: False
dataloader_num_workers: 0
============================================================

Loading model: my-new-model (t5)
QLoRA enabled: True, unsloth enabled: False
Loading model with standard QLoRA...
```

## ğŸ”„ ê¸°ì¡´ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥

### âœ… **ì´ë¯¸ í™œì„±í™”ëœ ëª¨ë¸ë“¤**
- ê¸°ì¡´ ì„¤ì • íŒŒì¼ì˜ `use_unsloth: true`ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
- ì¶”ê°€ì ì¸ ìë™ ìµœì í™” íš¨ê³¼ ì ìš©

### ğŸ”§ **ì„¤ì • ì—†ë˜ ëª¨ë¸ë“¤**
- AIStages ì„œë²„ì—ì„œëŠ” ìë™ìœ¼ë¡œ Unsloth í™œì„±í™”
- macOS/Windowsì—ì„œëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ë¹„í™œì„±í™”

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë°©ë²•

### 1. **í™˜ê²½ ê°ì§€ í…ŒìŠ¤íŠ¸**
```bash
python test_auto_environment.py
```

### 2. **ìƒˆë¡œìš´ ëª¨ë¸ ì„¤ì • í…ŒìŠ¤íŠ¸**
```yaml
# config/test_new_model.yaml
general:
  model_name: facebook/bart-base
  
# qlora ì„¹ì…˜ ì—†ìŒ â†’ ìë™ ê°ì§€ ì ìš©
```

```bash
python code/trainer.py --config config/test_new_model.yaml
```

### 3. **ë¡œê·¸ í™•ì¸**
```bash
# í™˜ê²½ ê°ì§€ ë¡œê·¸ í™•ì¸
tail -f logs/training.log | grep "í™˜ê²½ ìë™ ê°ì§€"

# Unsloth í™œì„±í™” ë¡œê·¸ í™•ì¸  
tail -f logs/training.log | grep "unsloth"
```

## ğŸ¯ ì‹¤ì œ ì ìš© ì˜ˆì‹œ

### ìƒˆë¡œìš´ KoGPT ëª¨ë¸ ì¶”ê°€
```yaml
# config/experiments/new_kogpt_experiment.yaml
experiment_name: kogpt_new_test
description: "ìƒˆë¡œìš´ KoGPT ëª¨ë¸ í…ŒìŠ¤íŠ¸"

general:
  model_name: skt/kogpt2-base-v2
  model_type: causal_lm

# qlora ì„¤ì • ì—†ìŒ â†’ AIStagesì—ì„œ ìë™ Unsloth í™œì„±í™”!

training:
  num_train_epochs: 3
  # batch_sizeëŠ” ìë™ ê¶Œì¥ê°’ (RTX 3090: 12) ì°¸ê³ 
```

**ê²°ê³¼**: AIStages ì„œë²„ì—ì„œ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ Unsloth í™œì„±í™”, ë©”ëª¨ë¦¬ ì ˆì•½ ë° ì†ë„ í–¥ìƒ!

## ğŸ’¡ ê¶Œì¥ì‚¬í•­

### âœ… **ìƒˆë¡œìš´ ëª¨ë¸ ì„¤ì • ì‹œ**
1. **qlora ì„¹ì…˜ì„ ë¹„ì›Œë‘ê¸°** (ìë™ ê°ì§€ í™œìš©)
2. **í™˜ê²½ë³„ í…ŒìŠ¤íŠ¸** í›„ ëª…ì‹œì  ì„¤ì • ê³ ë ¤
3. **ë¡œê·¸ë¥¼ í™•ì¸**í•˜ì—¬ ìµœì í™” ì ìš© ì—¬ë¶€ ê²€ì¦

### ğŸ¯ **íŒ€ í˜‘ì—… ì‹œ**
1. **AIStages ì„œë²„**: ìë™ í™œì„±í™” ê¸°ëŒ€
2. **ê°œë°œ í™˜ê²½ (macOS)**: ìë™ ë¹„í™œì„±í™” ì˜ˆìƒ
3. **ì„¤ì • í†µì¼ í•„ìš”ì‹œ**: ëª…ì‹œì ìœ¼ë¡œ `use_unsloth: true/false` ì„¤ì •

---

**ğŸš€ ê²°ë¡ **: ì´ì œ ìƒˆë¡œìš´ ëª¨ë¸ì„ ì¶”ê°€í•  ë•Œë§ˆë‹¤ ë³„ë„ ì„¤ì • ì—†ì´ë„ **í™˜ê²½ì— ë§ëŠ” ìµœì í™”ê°€ ìë™ ì ìš©**ë©ë‹ˆë‹¤!
