# ðŸ–¥ï¸ AIStages Ubuntu ì„œë²„ ì„¤ì • ê°€ì´ë“œ (UV í™˜ê²½)

## ðŸ“‹ ê°œìš”

ë§¥(Mac)ì—ì„œ ê°œë°œí•œ í”„ë¡œì íŠ¸ë¥¼ AIStages Ubuntu ì„œë²„ë¡œ ì „ì†¡í•˜ì—¬ ì‹¤í—˜ì„ ì‹¤í–‰í•˜ëŠ” ê°€ì´ë“œìž…ë‹ˆë‹¤.
**UV íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ì¡´ì„±ì„ ê´€ë¦¬í•˜ë©°, pytorch_model.bin íŒŒì¼ì„ í¬í•¨í•œ ëŒ€ìš©ëŸ‰ ëª¨ë¸ íŒŒì¼ë“¤ì€ ìžë™ ë‹¤ìš´ë¡œë“œë¥¼ í†µí•´ ì²˜ë¦¬í•©ë‹ˆë‹¤.

## ðŸ”„ Git ì „ì†¡ ì›Œí¬í”Œë¡œìš°

### 1ë‹¨ê³„: ë¡œì»¬ì—ì„œ Git ì¤€ë¹„

```bash
# í˜„ìž¬ ìƒíƒœ í™•ì¸
git status

# ë³€ê²½ì‚¬í•­ ìŠ¤í…Œì´ì§• (pytorch_model.binì€ .gitignoreë¡œ ì œì™¸ë¨)
git add .

# ì»¤ë°‹
git commit -m "feat: eenzeenee ëª¨ë¸ ì™„ì „ í†µí•© ë° ë¬¸ì„œí™” ì™„ë£Œ

- eenzeenee_utils.py ì „ìš© ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ ì¶”ê°€ (12ê°œ í•¨ìˆ˜)
- ì •í™•í•œ ëª¨ë¸ëª…ìœ¼ë¡œ ìˆ˜ì •: eenzeenee/t5-base-korean-summarization  
- config.yaml ìµœì  ì„¤ì •ê°’ ì ìš© (64í† í°, 3ë¹”)
- EENZEENEE_INTEGRATION_REPORT.md ìƒì„¸ í†µí•© ë³´ê³ ì„œ
- EENZEENEE_GUIDE.md ì™„ì „ ì‚¬ìš©ìž ê°€ì´ë“œ 
- 4/4 í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼"

# ì›ê²© ì €ìž¥ì†Œì— í‘¸ì‹œ
git push origin main
```

### 2ë‹¨ê³„: AIStages ì„œë²„ì—ì„œ ë°›ê¸°

```bash
# ì„œë²„ì— SSH ì ‘ì†
ssh username@your-aistages-server

# í”„ë¡œì íŠ¸ í´ë¡  (ì²˜ìŒ) ë˜ëŠ” í’€ (ê¸°ì¡´)
git clone [your-repository-url]
# ë˜ëŠ”
git pull origin main

# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd nlp-sum-lyj
```

### 3ë‹¨ê³„: UVë¥¼ ì‚¬ìš©í•œ ì„œë²„ í™˜ê²½ ì„¤ì •

```bash
# UVê°€ ì„¤ì¹˜ë˜ì–´ ìžˆëŠ”ì§€ í™•ì¸
uv --version

# UVê°€ ì—†ë‹¤ë©´ ì„¤ì¹˜
curl -LsSf https://astral.sh/uv/install.sh | sh
source ~/.bashrc  # ë˜ëŠ” ~/.zshrc

# UVë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ìƒí™˜ê²½ ìƒì„± ë° ì˜ì¡´ì„± ì„¤ì¹˜
uv sync

# ë˜ëŠ” ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œë„ ê°€ëŠ¥
uv venv
source .venv/bin/activate
uv pip install -r requirements.txt

# uv.lock íŒŒì¼ì´ ìžˆë‹¤ë©´ (ê¶Œìž¥)
uv sync --frozen

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (í•„ìš”ì‹œ)
cp .env.template .env
# .env íŒŒì¼ íŽ¸ì§‘
```

## ðŸš€ UV ëª…ë ¹ì–´ ì°¸ì¡°

### ê¸°ë³¸ UV ëª…ë ¹ì–´
```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
uv add package-name

# ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜  
uv add --dev package-name

# ì˜ì¡´ì„± ë™ê¸°í™”
uv sync

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
uv run python script.py

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source .venv/bin/activate
# ë˜ëŠ”
uv shell
```

### í”„ë¡œì íŠ¸ë³„ UV ì‚¬ìš©ë²•
```bash
# ì‹¤í—˜ ì‹¤í–‰ì‹œ UV ì‚¬ìš©
uv run python code/trainer.py --config config.yaml

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
uv run python test_eenzeenee_integration.py

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
uv run python -c "from code.utils.eenzeenee_utils import *; print('UV í™˜ê²½ í…ŒìŠ¤íŠ¸ ì„±ê³µ!')"
```

## ðŸ¤– ëª¨ë¸ ìžë™ ë‹¤ìš´ë¡œë“œ ì²˜ë¦¬

### pytorch_model.bin íŒŒì¼ íŠ¹ì„±
- **mT5 ëª¨ë¸**: 2.2GB
- **eenzeenee ëª¨ë¸**: ~800MB 
- **ìžë™ ë‹¤ìš´ë¡œë“œ**: ì²« ì‹¤í–‰ì‹œ Hugging Face Hubì—ì„œ ìžë™ ë‹¤ìš´ë¡œë“œ
- **ìºì‹œ ìœ„ì¹˜**: `~/.cache/huggingface/transformers/`

### UVë¥¼ ì‚¬ìš©í•œ ìžë™ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸

```bash
# UV í™˜ê²½ì—ì„œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í…ŒìŠ¤íŠ¸ (ì‹¤ì œ í•™ìŠµ ì „ ê¶Œìž¥)
uv run python -c "
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

print('ðŸ“¥ mT5 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...')
mT5_model = AutoModelForSeq2SeqLM.from_pretrained('csebuetnlp/mT5_multilingual_XLSum')
mT5_tokenizer = AutoTokenizer.from_pretrained('csebuetnlp/mT5_multilingual_XLSum')
print('âœ… mT5 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ')

print('ðŸ“¥ eenzeenee ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...')  
eenzeenee_model = AutoModelForSeq2SeqLM.from_pretrained('eenzeenee/t5-base-korean-summarization')
eenzeenee_tokenizer = AutoTokenizer.from_pretrained('eenzeenee/t5-base-korean-summarization') 
print('âœ… eenzeenee ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ')

print('ðŸŽ‰ ëª¨ë“  ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!')
"
```

## ðŸ§ª UVë¥¼ ì‚¬ìš©í•œ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰

### ê¸°ë³¸ í†µí•© í…ŒìŠ¤íŠ¸

```bash
# UV í™˜ê²½ì—ì„œ eenzeenee ëª¨ë¸ í†µí•© í…ŒìŠ¤íŠ¸
uv run python test_eenzeenee_integration.py

# ì¶œë ¥ ì˜ˆì‹œ:
# ðŸŽ‰ ëª¨ë“  í†µí•© í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤!
# eenzeenee ëª¨ë¸ì´ í”„ë¡œì íŠ¸ì— ì„±ê³µì ìœ¼ë¡œ í†µí•©ë˜ì—ˆìŠµë‹ˆë‹¤.
```

### UVë¥¼ ì‚¬ìš©í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸

```bash
# UV í™˜ê²½ì—ì„œ eenzeenee_utils ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
uv run python -c "
import sys
sys.path.append('code/utils')
from eenzeenee_utils import *

print('=== UV í™˜ê²½ì—ì„œ eenzeenee_utils í…ŒìŠ¤íŠ¸ ===')
info = get_eenzeenee_model_info()
print(f'ëª¨ë¸ëª…: {info[\"model_name\"]}')
print(f'íŒŒë¼ë¯¸í„°: {info[\"parameters\"]}')

text = 'UV í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸í•˜ëŠ” í…ìŠ¤íŠ¸ìž…ë‹ˆë‹¤.'
processed = preprocess_for_eenzeenee(text)
print(f'ì „ì²˜ë¦¬ ê²°ê³¼: {processed}')
print('âœ… UV í™˜ê²½ì—ì„œ ì •ìƒ ìž‘ë™!')
"
```

## ðŸš€ UVë¥¼ ì‚¬ìš©í•œ ì‹¤í—˜ ì‹¤í–‰

### 1. eenzeenee ëª¨ë¸ ì‹¤í—˜

```bash
# ìŠ¤í¬ë¦½íŠ¸ ê¶Œí•œ í™•ì¸
chmod +x run_eenzeenee_experiment.sh

# UV í™˜ê²½ì—ì„œ ì„¤ì • í™•ì¸ ëª¨ë“œ (ì•ˆì „ í…ŒìŠ¤íŠ¸)
uv run ./run_eenzeenee_experiment.sh

# UV í™˜ê²½ì—ì„œ ì‹¤ì œ í•™ìŠµ ì‹¤í–‰
EENZEENEE_RUN_ACTUAL=true uv run ./run_eenzeenee_experiment.sh

# ë˜ëŠ” ì§ì ‘ trainer ì‹¤í–‰
uv run python code/trainer.py \
    --config config.yaml \
    --config-section eenzeenee \
    --train-data data/train.csv \
    --val-data data/dev.csv \
    --test-data data/test.csv
```

### 2. mT5 ëª¨ë¸ ì‹¤í—˜

```bash
# UV í™˜ê²½ì—ì„œ mT5 ì‹¤í—˜ ì‹¤í–‰
uv run python code/trainer.py \
    --config config.yaml \
    --config-section xlsum_mt5 \
    --train-data data/train.csv \
    --val-data data/dev.csv \
    --test-data data/test.csv
```

### 3. ë‹¤ì¤‘ ëª¨ë¸ ë¹„êµ ì‹¤í—˜

```bash
# UV í™˜ê²½ì—ì„œ ì—¬ëŸ¬ ëª¨ë¸ ë™ì‹œ ë¹„êµ
chmod +x run_multi_model_experiments.sh
uv run ./run_multi_model_experiments.sh
```

### 4. UVë¥¼ í™œìš©í•œ ë³‘ë ¬ ì‹¤í—˜

```bash
# UV í™˜ê²½ì—ì„œ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í—˜ ì‹¤í–‰
uv run python code/trainer.py --config config.yaml --config-section eenzeenee &
uv run python code/trainer.py --config config.yaml --config-section xlsum_mt5 &
wait  # ëª¨ë“  ë°±ê·¸ë¼ìš´ë“œ ìž‘ì—… ì™„ë£Œ ëŒ€ê¸°
```

## ðŸ“Š ì‹¤í—˜ ê²°ê³¼ í™•ì¸

### ì‹¤í—˜ ì¶œë ¥ ë””ë ‰í† ë¦¬

```bash
# eenzeenee ì‹¤í—˜ ê²°ê³¼
ls outputs/eenzeenee_experiment_*/
# experiment_info.json  training.log  results/

# ë‹¤ë¥¸ ëª¨ë¸ ì‹¤í—˜ ê²°ê³¼
ls outputs/
```

### ë¡œê·¸ í™•ì¸

```bash
# ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
tail -f outputs/eenzeenee_experiment_*/training.log

# ì‹¤í—˜ ë©”íƒ€ë°ì´í„° í™•ì¸
cat outputs/eenzeenee_experiment_*/experiment_info.json
```

## âš™ï¸ UV í™˜ê²½ ìµœì í™”

### pyproject.toml í™œìš©

```toml
# pyproject.tomlì—ì„œ ìŠ¤í¬ë¦½íŠ¸ ì •ì˜ (ìžˆë‹¤ë©´)
[project.scripts]
train-eenzeenee = "code.trainer:main"
test-integration = "test_eenzeenee_integration:main"

# UVë¡œ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
uv run train-eenzeenee --config config.yaml --config-section eenzeenee
```

### UV ì˜ì¡´ì„± ê´€ë¦¬

```bash
# ìƒˆë¡œìš´ íŒ¨í‚¤ì§€ ì¶”ê°€
uv add transformers torch

# ê°œë°œ ì „ìš© íŒ¨í‚¤ì§€ ì¶”ê°€
uv add --dev pytest black

# íŠ¹ì • ë²„ì „ ì„¤ì¹˜
uv add "torch>=2.0.0"

# ì˜ì¡´ì„± ì—…ë°ì´íŠ¸
uv lock --upgrade

# ì˜ì¡´ì„± ì •ë³´ í™•ì¸
uv tree
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

### UV í™˜ê²½ ê´€ë¦¬

1. **ê°€ìƒí™˜ê²½ ìœ„ì¹˜**: UVëŠ” í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.venv` ìƒì„±
2. **Lock íŒŒì¼**: `uv.lock` íŒŒì¼ë¡œ ì •í™•í•œ ë²„ì „ ê´€ë¦¬
3. **ìºì‹œ ê´€ë¦¬**: UVëŠ” ê¸€ë¡œë²Œ ìºì‹œ ì‚¬ìš©ìœ¼ë¡œ ë¹ ë¥¸ ì„¤ì¹˜

### ë„¤íŠ¸ì›Œí¬ ë° ë‹¤ìš´ë¡œë“œ

1. **ì¸í„°ë„· ì—°ê²° í•„ìˆ˜**: ì²« ì‹¤í–‰ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ ì¸í„°ë„· ì—°ê²° í•„ìš”
2. **ë‹¤ìš´ë¡œë“œ ì‹œê°„**: 
   - mT5 (2.2GB): ì•½ 5-10ë¶„
   - eenzeenee (800MB): ì•½ 2-5ë¶„
3. **ë””ìŠ¤í¬ ê³µê°„**: ìµœì†Œ 5GB ì—¬ìœ  ê³µê°„ ê¶Œìž¥

### GPU ë©”ëª¨ë¦¬ ê´€ë¦¬

```bash
# GPU ìƒíƒœ í™•ì¸
nvidia-smi

# UV í™˜ê²½ì—ì„œ GPU í…ŒìŠ¤íŠ¸
uv run python -c "
import torch
print(f'CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU ê°œìˆ˜: {torch.cuda.device_count()}')
    print(f'í˜„ìž¬ GPU: {torch.cuda.get_device_name()}')
"

# ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ë°°ì¹˜ í¬ê¸° ì¡°ì •
# config.yamlì—ì„œ inference.batch_size ê°ì†Œ (8 â†’ 4 â†’ 2)
```

## ðŸ”§ UV í™˜ê²½ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ì˜¤ë¥˜

#### 1. UV ì„¤ì¹˜ ì˜¤ë¥˜
```bash
âŒ uv: command not found
```
**í•´ê²°ë°©ë²•**:
```bash
# UV ì„¤ì¹˜
curl -LsSf https://astral.sh/uv/install.sh | sh
source ~/.bashrc

# ë˜ëŠ” pipë¡œ ì„¤ì¹˜
pip install uv
```

#### 2. ì˜ì¡´ì„± ì¶©ëŒ
```bash
âŒ ResolutionImpossible: Could not resolve dependencies
```
**í•´ê²°ë°©ë²•**:
```bash
# Lock íŒŒì¼ ìž¬ìƒì„±
rm uv.lock
uv lock

# ë˜ëŠ” ê°•ì œ ìž¬ì„¤ì¹˜
uv sync --reinstall
```

#### 3. ê°€ìƒí™˜ê²½ ì˜¤ë¥˜
```bash
âŒ No virtual environment found
```
**í•´ê²°ë°©ë²•**:
```bash
# ê°€ìƒí™˜ê²½ ìž¬ìƒì„±
rm -rf .venv
uv venv
uv sync
```

#### 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```bash
âŒ Connection timeout / HTTP 403 error
```
**í•´ê²°ë°©ë²•**:
```bash
# Hugging Face í† í° ì„¤ì • (í•„ìš”ì‹œ)
uv run huggingface-cli login

# ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ ì„¤ì •
export HUGGINGFACE_HUB_TOKEN=your_token
```

#### 5. GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
âŒ CUDA out of memory
```
**í•´ê²°ë°©ë²•**:
```yaml
# config.yaml ìˆ˜ì •
inference:
  batch_size: 2  # 8ì—ì„œ 2ë¡œ ê°ì†Œ
```

## ðŸ“ˆ UV í™˜ê²½ ì„±ëŠ¥ ìµœì í™”

### ì„œë²„ ë¦¬ì†ŒìŠ¤ í™œìš©

```bash
# ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
uv run python -c "
import os, psutil, torch
print(f'CPU ì½”ì–´: {os.cpu_count()}')
print(f'ë©”ëª¨ë¦¬: {psutil.virtual_memory().total // (1024**3)}GB')
if torch.cuda.is_available():
    print(f'GPU: {torch.cuda.get_device_name()}')
    print(f'GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory // (1024**3)}GB')
"

# ìµœì  ë°°ì¹˜ í¬ê¸° ì„¤ì •
# GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì •:
# - 8GB: batch_size=4-8
# - 16GB: batch_size=8-16
# - 24GB+: batch_size=16+
```

### UV ìºì‹œ ìµœì í™”

```bash
# UV ìºì‹œ ì •ë³´ í™•ì¸
uv cache info

# ìºì‹œ ì •ë¦¬ (í•„ìš”ì‹œ)
uv cache clean

# ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸
uv cache dir
```

## ðŸ”„ ê°œë°œ ì›Œí¬í”Œë¡œìš°

### ë¡œì»¬-ì„œë²„ ë™ê¸°í™”

```bash
# ðŸ–¥ï¸ ë¡œì»¬(ë§¥)ì—ì„œ ê°œë°œ
uv add new-package        # ìƒˆ íŒ¨í‚¤ì§€ ì¶”ê°€
uv sync                   # ë¡œì»¬ í™˜ê²½ ë™ê¸°í™”
git add uv.lock pyproject.toml
git commit -m "deps: ìƒˆ íŒ¨í‚¤ì§€ ì¶”ê°€"
git push origin main

# ðŸ§ ì„œë²„ì—ì„œ ë™ê¸°í™”
git pull origin main
uv sync                   # ì„œë²„ í™˜ê²½ ë™ê¸°í™”
```

### ì‹¤í—˜ ìžë™í™”

```bash
# UVë¥¼ ì‚¬ìš©í•œ ì‹¤í—˜ ìžë™í™” ìŠ¤í¬ë¦½íŠ¸ ì˜ˆì‹œ
cat > run_experiments.sh << 'EOF'
#!/bin/bash
set -e

echo "ðŸš€ UV í™˜ê²½ì—ì„œ ìžë™ ì‹¤í—˜ ì‹œìž‘"

# í™˜ê²½ í™•ì¸
uv --version
uv sync

# ëª¨ë¸ë³„ ì‹¤í—˜ ì‹¤í–‰
echo "ðŸ“Š eenzeenee ëª¨ë¸ ì‹¤í—˜"
uv run python code/trainer.py --config config.yaml --config-section eenzeenee

echo "ðŸ“Š mT5 ëª¨ë¸ ì‹¤í—˜" 
uv run python code/trainer.py --config config.yaml --config-section xlsum_mt5

echo "âœ… ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ"
EOF

chmod +x run_experiments.sh
uv run ./run_experiments.sh
```

## ðŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### UV ê´€ë ¨ ë¬¸ì„œ
- **UV ê³µì‹ ë¬¸ì„œ**: https://docs.astral.sh/uv/
- **pyproject.toml ê°€ì´ë“œ**: https://peps.python.org/pep-0621/

### í”„ë¡œì íŠ¸ ë¬¸ì„œ
- **í”„ë¡œì íŠ¸ ë¬¸ì„œ**: `README.md`
- **eenzeenee ê°€ì´ë“œ**: `EENZEENEE_GUIDE.md`  
- **í†µí•© ë³´ê³ ì„œ**: `EENZEENEE_INTEGRATION_REPORT.md`
- **mT5 ë³´ê³ ì„œ**: `MT5_INTEGRATION_REPORT.md`

---

## ðŸŽ¯ UV í™˜ê²½ ìš”ì•½

### âœ… UV ì‚¬ìš©ì˜ ìž¥ì 
1. **ë¹ ë¥¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜**: Rust ê¸°ë°˜ìœ¼ë¡œ pipë³´ë‹¤ 10-100ë°° ë¹ ë¦„
2. **ì •í™•í•œ ì˜ì¡´ì„± ê´€ë¦¬**: `uv.lock` íŒŒì¼ë¡œ ìž¬í˜„ ê°€ëŠ¥í•œ í™˜ê²½
3. **ê°„íŽ¸í•œ ëª…ë ¹ì–´**: `uv run`, `uv sync` ë“± ì§ê´€ì  ëª…ë ¹ì–´
4. **í”„ë¡œì íŠ¸ ê²©ë¦¬**: í”„ë¡œì íŠ¸ë³„ ë…ë¦½ì ì¸ ê°€ìƒí™˜ê²½

### ðŸ“‹ í•µì‹¬ ëª…ë ¹ì–´ ìš”ì•½
```bash
# í™˜ê²½ ì„¤ì •
uv sync                    # ì˜ì¡´ì„± ë™ê¸°í™”
uv add package            # íŒ¨í‚¤ì§€ ì¶”ê°€
uv run python script.py   # ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰

# ì‹¤í—˜ ì‹¤í–‰
uv run python code/trainer.py --config config.yaml --config-section eenzeenee
uv run python test_eenzeenee_integration.py

# í™˜ê²½ ê´€ë¦¬
uv cache clean            # ìºì‹œ ì •ë¦¬
uv tree                   # ì˜ì¡´ì„± íŠ¸ë¦¬ í™•ì¸
```

## ðŸŽ‰ ìµœì¢… ì •ë¦¬

1. **pytorch_model.bin íŒŒì¼ì€ Gitì— í¬í•¨í•˜ì§€ ì•ŠìŒ** (.gitignoreì— ì´ë¯¸ ì„¤ì •)
2. **UVë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹ ë¥´ê³  ì•ˆì •ì ì¸ ì˜ì¡´ì„± ê´€ë¦¬**
3. **ì„œë²„ì—ì„œ ì²« ì‹¤í–‰ì‹œ ëª¨ë¸ ìžë™ ë‹¤ìš´ë¡œë“œ** (2-10ë¶„ ì†Œìš”)
4. **`uv run` ëª…ë ¹ì–´ë¡œ ëª¨ë“  ì‹¤í—˜ ì‹¤í–‰**

**ì´ì œ UV í™˜ê²½ì—ì„œ AIStages ì„œë²„ì—ì„œ ì•ˆì „í•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì‹¤í—˜ì„ ì‹¤í–‰í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤! ðŸš€**
