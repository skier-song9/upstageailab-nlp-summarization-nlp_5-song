# ğŸ”— ì•™ìƒë¸” ê¸°ë²• ê°€ì´ë“œ

ë‹¤ì¤‘ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ì•™ìƒë¸” ê¸°ë²•ë“¤ì— ëŒ€í•œ ìƒì„¸ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨
1. [ì•™ìƒë¸” ê°œìš”](#ì•™ìƒë¸”-ê°œìš”)
2. [ì•™ìƒë¸” ì „ëµ](#ì•™ìƒë¸”-ì „ëµ)
3. [êµ¬í˜„ ë°©ë²•](#êµ¬í˜„-ë°©ë²•)
4. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)
5. [ì‹¤í—˜ ê²°ê³¼](#ì‹¤í—˜-ê²°ê³¼)
6. [ì‹¤ë¬´ ì ìš©](#ì‹¤ë¬´-ì ìš©)

---

## ì•™ìƒë¸” ê°œìš”

### ì•™ìƒë¸”ì˜ ê¸°ë³¸ ì›ë¦¬

ì•™ìƒë¸”ì€ ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ëª¨ë¸ì„ ê²°í•©í•˜ì—¬ ë‹¨ì¼ ëª¨ë¸ë³´ë‹¤ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì–»ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤.

**í•µì‹¬ ê°œë…:**
- **ë‹¤ì–‘ì„± (Diversity)**: ì„œë¡œ ë‹¤ë¥¸ íŠ¹ì„±ì„ ê°€ì§„ ëª¨ë¸ë“¤
- **ì§‘ë‹¨ ì§€ì„± (Collective Intelligence)**: ê°œë³„ ëª¨ë¸ì˜ ì•½ì ì„ ì„œë¡œ ë³´ì™„
- **ë¶„ì‚° ê°ì†Œ (Variance Reduction)**: ì˜ˆì¸¡ì˜ ì•ˆì •ì„± í–¥ìƒ

### ëŒ€í™” ìš”ì•½ì—ì„œì˜ ì•™ìƒë¸” íš¨ê³¼

```python
# ë‹¨ì¼ ëª¨ë¸ vs ì•™ìƒë¸” ì„±ëŠ¥ ë¹„êµ
PERFORMANCE_COMPARISON = {
    "KoBART (ë‹¨ì¼)": {
        "rouge1_f1": 0.471,
        "rouge2_f1": 0.312,
        "rougeL_f1": 0.395
    },
    "3-Model Ensemble": {
        "rouge1_f1": 0.485,  # +1.4%p í–¥ìƒ
        "rouge2_f1": 0.329,  # +1.7%p í–¥ìƒ
        "rougeL_f1": 0.408   # +1.3%p í–¥ìƒ
    }
}
```

---

## ì•™ìƒë¸” ì „ëµ

### 1. ëª¨ë¸ ë‹¤ì–‘ì„± í™•ë³´

#### A. ì•„í‚¤í…ì²˜ ë‹¤ì–‘ì„±
```python
ENSEMBLE_MODELS = {
    "kobart": {
        "model_path": "outputs/kobart_model",
        "architecture": "encoder-decoder",
        "strength": "í•œêµ­ì–´ ì´í•´",
        "weight": 0.4
    },
    "kt5": {
        "model_path": "outputs/kt5_model", 
        "architecture": "encoder-decoder",
        "strength": "í…ìŠ¤íŠ¸ ìƒì„±",
        "weight": 0.3
    },
    "mt5": {
        "model_path": "outputs/mt5_model",
        "architecture": "encoder-decoder", 
        "strength": "ë‹¤êµ­ì–´ ì§€ì›",
        "weight": 0.3
    }
}
```

### 2. ì•™ìƒë¸” ê²°í•© ë°©ë²•

#### A. Voting ê¸°ë°˜ ì•™ìƒë¸”
```python
class VotingEnsemble:
    """íˆ¬í‘œ ê¸°ë°˜ ì•™ìƒë¸”"""
    
    def predict(self, dialogue: str) -> str:
        predictions = []
        weights = []
        
        for model_config in self.models:
            model = self._load_model(model_config["path"])
            pred = model.generate_summary(dialogue)
            
            predictions.append(pred)
            weights.append(model_config["weight"])
        
        return self._weighted_vote(predictions, weights)
```

#### B. ë‹¤ë‹¨ê³„ ì•™ìƒë¸”
```python
class MultiStageEnsemble:
    """ë‹¤ë‹¨ê³„ ì•™ìƒë¸” (ì¡°ê±´ë¶€ ê²°í•©)"""
    
    def predict(self, dialogue: str) -> str:
        # 1. ì…ë ¥ ë¶„ì„
        features = self._analyze_dialogue(dialogue)
        
        # 2. ì „ëµ ì„ íƒ
        strategy = self._select_strategy(features)
        
        # 3. ì„ íƒëœ ì „ëµìœ¼ë¡œ ì•™ìƒë¸”
        if strategy == "simple":
            return self._simple_ensemble(dialogue)
        elif strategy == "weighted":
            return self._weighted_ensemble(dialogue, features)
        else:
            return self._adaptive_ensemble(dialogue, features)
```

---

## êµ¬í˜„ ë°©ë²•

### ê¸°ë³¸ ì•™ìƒë¸” í”„ë ˆì„ì›Œí¬

```python
# core/ensemble/ensemble_model.py
class EnsemblePredictor:
    """ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ì˜ˆì¸¡ê¸°"""
    
    def __init__(self, model_configs: List[Dict[str, Any]]):
        self.models = []
        self.weights = []
        
        for config in model_configs:
            model = self._load_model(config['path'])
            weight = config.get('weight', 1.0)
            
            self.models.append(model)
            self.weights.append(weight)
        
        # ê°€ì¤‘ì¹˜ ì •ê·œí™”
        total_weight = sum(self.weights)
        self.weights = [w / total_weight for w in self.weights]
    
    def predict_ensemble(self, dialogue: str, strategy: str = "weighted") -> str:
        """ì•™ìƒë¸” ì˜ˆì¸¡"""
        
        predictions = []
        for model in self.models:
            pred = model.generate_summary(dialogue)
            predictions.append(pred)
        
        if strategy == "weighted":
            return self._weighted_combine(predictions)
        elif strategy == "voting":
            return self._majority_vote(predictions)
        elif strategy == "best":
            return self._select_best(predictions, dialogue)
        else:
            return predictions[0]
    
    def _weighted_combine(self, predictions: List[str]) -> str:
        """ê°€ì¤‘ì¹˜ ê¸°ë°˜ ê²°í•©"""
        
        # ë¬¸ì¥ ë ˆë²¨ì—ì„œ ê°€ì¤‘ ì„ íƒ
        sentence_groups = [pred.split('.') for pred in predictions]
        combined_sentences = []
        
        max_sentences = max(len(group) for group in sentence_groups)
        
        for i in range(max_sentences):
            sentence_scores = {}
            
            for j, (sentences, weight) in enumerate(zip(sentence_groups, self.weights)):
                if i < len(sentences) and sentences[i].strip():
                    sent = sentences[i].strip()
                    sentence_scores[sent] = sentence_scores.get(sent, 0) + weight
            
            if sentence_scores:
                best_sentence = max(sentence_scores, key=sentence_scores.get)
                combined_sentences.append(best_sentence)
        
        return '. '.join(combined_sentences)
    
    def _majority_vote(self, predictions: List[str]) -> str:
        """ë‹¤ìˆ˜ê²° íˆ¬í‘œ"""
        
        from collections import defaultdict
        import difflib
        
        # ìœ ì‚¬í•œ ì˜ˆì¸¡ ê·¸ë£¹í™”
        groups = defaultdict(list)
        
        for i, pred in enumerate(predictions):
            assigned = False
            for group_rep in groups:
                similarity = difflib.SequenceMatcher(None, pred, group_rep).ratio()
                if similarity > 0.7:
                    groups[group_rep].append((i, pred))
                    assigned = True
                    break
            
            if not assigned:
                groups[pred].append((i, pred))
        
        # ìµœëŒ€ ê·¸ë£¹ì—ì„œ ìµœê³  ê°€ì¤‘ì¹˜ ì„ íƒ
        largest_group = max(groups.values(), key=len)
        
        best_pred = None
        best_weight = 0
        
        for idx, pred in largest_group:
            if self.weights[idx] > best_weight:
                best_weight = self.weights[idx]
                best_pred = pred
        
        return best_pred
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•™ìƒë¸”

```python
class MemoryEfficientEnsemble:
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•™ìƒë¸”"""
    
    def predict_streaming(self, dialogue: str) -> str:
        """ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ ì˜ˆì¸¡"""
        
        predictions = []
        
        for config in self.model_configs:
            # ëª¨ë¸ ë¡œë”©
            model = self._load_model_lazy(config['path'])
            
            # ì˜ˆì¸¡
            pred = model.generate_summary(dialogue)
            predictions.append((pred, config['weight']))
            
            # ë©”ëª¨ë¦¬ ì •ë¦¬
            del model
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        
        return self._weighted_combine(predictions)
```

### 2. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

```python
class BatchEnsembleProcessor:
    """ë°°ì¹˜ ì•™ìƒë¸” ì²˜ë¦¬"""
    
    def process_batch(self, dialogues: List[str]) -> List[str]:
        """íš¨ìœ¨ì ì¸ ë°°ì¹˜ ì²˜ë¦¬"""
        
        # ëª¨ë“  ëª¨ë¸ì˜ ë°°ì¹˜ ì˜ˆì¸¡ ìˆ˜ì§‘
        all_predictions = []
        
        for model in self.models:
            batch_preds = model.predict_batch(dialogues)
            all_predictions.append(batch_preds)
        
        # ìƒ˜í”Œë³„ ì•™ìƒë¸”
        results = []
        for i in range(len(dialogues)):
            sample_preds = [preds[i] for preds in all_predictions]
            ensemble_result = self._combine_predictions(sample_preds)
            results.append(ensemble_result)
        
        return results
```

---

## ì‹¤í—˜ ê²°ê³¼

### ì•™ìƒë¸” ì„±ëŠ¥ ë¹„êµ

```python
ENSEMBLE_RESULTS = {
    "ë² ì´ìŠ¤ë¼ì¸ (ë‹¨ì¼ KoBART)": {
        "rouge1_f1": 0.471,
        "rouge2_f1": 0.312,
        "rougeL_f1": 0.395,
        "inference_time": "1.2s/sample"
    },
    "2ëª¨ë¸ ì•™ìƒë¸” (KoBART + KE-T5)": {
        "rouge1_f1": 0.482,
        "rouge2_f1": 0.324,
        "rougeL_f1": 0.403,
        "inference_time": "2.8s/sample"
    },
    "3ëª¨ë¸ ì•™ìƒë¸” (+ mT5)": {
        "rouge1_f1": 0.485,
        "rouge2_f1": 0.329,
        "rougeL_f1": 0.408,
        "inference_time": "3.8s/sample"
    },
    "5ëª¨ë¸ ì•™ìƒë¸”": {
        "rouge1_f1": 0.491,
        "rouge2_f1": 0.337,
        "rougeL_f1": 0.415,
        "inference_time": "6.2s/sample"
    }
}
```

### ëª¨ë¸ ì¡°í•© íš¨ê³¼

| ì¡°í•© | ROUGE-1 F1 | ROUGE-2 F1 | ROUGE-L F1 | ê°œì„ ë¥  |
|------|-------------|-------------|-------------|--------|
| KoBART ë‹¨ì¼ | 0.471 | 0.312 | 0.395 | - |
| + KE-T5 | 0.482 | 0.324 | 0.403 | +2.3% |
| + mT5 | 0.485 | 0.329 | 0.408 | +3.0% |
| + Solar API | 0.488 | 0.332 | 0.411 | +3.6% |

---

## ì‹¤ë¬´ ì ìš©

### 1. í”„ë¡œë•ì…˜ ë°°í¬

```python
# deployment/ensemble_api.py
class EnsembleAPI:
    """ì•™ìƒë¸” ëª¨ë¸ API"""
    
    def __init__(self, config_path: str):
        self.config = self._load_config(config_path)
        self.ensemble = self._setup_ensemble()
        
    def summarize(self, dialogue: str, strategy: str = "auto") -> Dict[str, Any]:
        """ì•™ìƒë¸” ìš”ì•½ ìƒì„±"""
        
        start_time = time.time()
        
        # ìë™ ì „ëµ ì„ íƒ
        if strategy == "auto":
            strategy = self._select_optimal_strategy(dialogue)
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        summary = self.ensemble.predict_ensemble(dialogue, strategy)
        
        processing_time = time.time() - start_time
        
        return {
            "summary": summary,
            "strategy_used": strategy,
            "processing_time": processing_time,
            "model_count": len(self.ensemble.models)
        }
    
    def _select_optimal_strategy(self, dialogue: str) -> str:
        """ëŒ€í™” íŠ¹ì„±ì— ë”°ë¥¸ ìµœì  ì „ëµ ì„ íƒ"""
        
        length = len(dialogue.split())
        
        if length < 50:
            return "simple"  # ì§§ì€ ëŒ€í™”ëŠ” ë‹¨ìˆœ ì „ëµ
        elif length > 300:
            return "weighted"  # ê¸´ ëŒ€í™”ëŠ” ê°€ì¤‘ ì „ëµ
        else:
            return "voting"  # ì¤‘ê°„ ê¸¸ì´ëŠ” íˆ¬í‘œ ì „ëµ
```

### 2. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
class EnsembleMonitor:
    """ì•™ìƒë¸” ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.metrics = {
            "total_requests": 0,
            "average_latency": 0,
            "strategy_usage": defaultdict(int),
            "model_agreement": []
        }
    
    def log_prediction(self, dialogue: str, predictions: List[str], strategy: str, latency: float):
        """ì˜ˆì¸¡ ê²°ê³¼ ë¡œê¹…"""
        
        self.metrics["total_requests"] += 1
        self.metrics["average_latency"] = (
            (self.metrics["average_latency"] * (self.metrics["total_requests"] - 1) + latency) 
            / self.metrics["total_requests"]
        )
        self.metrics["strategy_usage"][strategy] += 1
        
        # ëª¨ë¸ ê°„ ì¼ì¹˜ë„ ê³„ì‚°
        agreement = self._calculate_agreement(predictions)
        self.metrics["model_agreement"].append(agreement)
    
    def _calculate_agreement(self, predictions: List[str]) -> float:
        """ëª¨ë¸ ê°„ ì˜ˆì¸¡ ì¼ì¹˜ë„ ê³„ì‚°"""
        
        total_pairs = 0
        agreement_sum = 0
        
        for i in range(len(predictions)):
            for j in range(i + 1, len(predictions)):
                similarity = self._calculate_similarity(predictions[i], predictions[j])
                agreement_sum += similarity
                total_pairs += 1
        
        return agreement_sum / total_pairs if total_pairs > 0 else 0
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        
        return {
            "ì´ ìš”ì²­ ìˆ˜": self.metrics["total_requests"],
            "í‰ê·  ì‘ë‹µì‹œê°„": f"{self.metrics['average_latency']:.2f}ì´ˆ",
            "ì „ëµ ì‚¬ìš©ë¥ ": dict(self.metrics["strategy_usage"]),
            "í‰ê·  ëª¨ë¸ ì¼ì¹˜ë„": f"{np.mean(self.metrics['model_agreement']):.3f}",
            "ì¼ì¹˜ë„ í‘œì¤€í¸ì°¨": f"{np.std(self.metrics['model_agreement']):.3f}"
        }
```

### 3. A/B í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬

```python
class EnsembleABTest:
    """ì•™ìƒë¸” A/B í…ŒìŠ¤íŠ¸"""
    
    def __init__(self, control_model, test_ensemble, split_ratio: float = 0.5):
        self.control_model = control_model
        self.test_ensemble = test_ensemble
        self.split_ratio = split_ratio
        self.results = {"control": [], "test": []}
    
    def predict_with_ab_test(self, dialogue: str) -> Dict[str, Any]:
        """A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ì˜ˆì¸¡"""
        
        import random
        
        # ì‚¬ìš©ì ê·¸ë£¹ ê²°ì •
        use_ensemble = random.random() < self.split_ratio
        
        start_time = time.time()
        
        if use_ensemble:
            summary = self.test_ensemble.predict_ensemble(dialogue)
            group = "test"
        else:
            summary = self.control_model.generate_summary(dialogue)
            group = "control"
        
        latency = time.time() - start_time
        
        # ê²°ê³¼ ê¸°ë¡
        self.results[group].append({
            "dialogue_length": len(dialogue.split()),
            "summary_length": len(summary.split()),
            "latency": latency
        })
        
        return {
            "summary": summary,
            "group": group,
            "latency": latency
        }
    
    def get_ab_test_results(self) -> Dict[str, Any]:
        """A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
        
        control_latencies = [r["latency"] for r in self.results["control"]]
        test_latencies = [r["latency"] for r in self.results["test"]]
        
        return {
            "control_group": {
                "requests": len(self.results["control"]),
                "avg_latency": np.mean(control_latencies),
                "avg_summary_length": np.mean([r["summary_length"] for r in self.results["control"]])
            },
            "test_group": {
                "requests": len(self.results["test"]),
                "avg_latency": np.mean(test_latencies),
                "avg_summary_length": np.mean([r["summary_length"] for r in self.results["test"]])
            },
            "performance_gain": {
                "latency_ratio": np.mean(test_latencies) / np.mean(control_latencies),
                "request_distribution": f"Control: {len(control_latencies)}, Test: {len(test_latencies)}"
            }
        }
```

---

## ğŸ¯ ì•™ìƒë¸” í™œìš© ê°€ì´ë“œ

### ì–¸ì œ ì•™ìƒë¸”ì„ ì‚¬ìš©í•´ì•¼ í• ê¹Œ?

#### ì¶”ì²œ ìƒí™©
- **ë†’ì€ ì •í™•ë„ê°€ ì¤‘ìš”í•œ ê²½ìš°**: ì˜ë£Œ, ë²•ë¥  ë“± ë„ë©”ì¸
- **ë‹¤ì–‘í•œ ì…ë ¥ì´ ì˜ˆìƒë˜ëŠ” ê²½ìš°**: ì—¬ëŸ¬ ë„ë©”ì¸ì˜ ëŒ€í™”
- **ì•ˆì •ì ì¸ ì„±ëŠ¥ì´ í•„ìš”í•œ ê²½ìš°**: í”„ë¡œë•ì…˜ í™˜ê²½

#### ë¹„ì¶”ì²œ ìƒí™©
- **ì‹¤ì‹œê°„ ì²˜ë¦¬ê°€ ì¤‘ìš”í•œ ê²½ìš°**: ì±„íŒ…ë´‡, ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤
- **ë¦¬ì†ŒìŠ¤ê°€ ì œí•œì ì¸ ê²½ìš°**: ëª¨ë°”ì¼, ì—£ì§€ ë””ë°”ì´ìŠ¤
- **ë‹¨ìˆœí•œ íƒœìŠ¤í¬ì˜ ê²½ìš°**: ê¸°ë³¸ì ì¸ ìš”ì•½ë§Œ í•„ìš”

### ìµœì  ì•™ìƒë¸” êµ¬ì„±

#### 2-3ê°œ ëª¨ë¸ ì•™ìƒë¸” (ê¶Œì¥)
```python
RECOMMENDED_ENSEMBLE = {
    "ëª¨ë¸ ìˆ˜": 2-3,
    "ë‹¤ì–‘ì„±": "ì•„í‚¤í…ì²˜ ë˜ëŠ” í•™ìŠµ ì „ëµ",
    "ê°€ì¤‘ì¹˜": "ì„±ëŠ¥ ê¸°ë°˜ ì„¤ì •",
    "ì „ëµ": "ê°€ì¤‘ íˆ¬í‘œ",
    "ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ": "2-4%p",
    "ì§€ì—°ì‹œê°„ ì¦ê°€": "2-3ë°°"
}
```

#### ê³ ì„±ëŠ¥ ì•™ìƒë¸” (ì—°êµ¬ìš©)
```python
RESEARCH_ENSEMBLE = {
    "ëª¨ë¸ ìˆ˜": 5-7,
    "ë‹¤ì–‘ì„±": "ì•„í‚¤í…ì²˜ + ë°ì´í„° + í•™ìŠµ",
    "ê°€ì¤‘ì¹˜": "ë™ì  ì¡°ì •",
    "ì „ëµ": "ë‹¤ë‹¨ê³„ ì•™ìƒë¸”",
    "ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ": "4-6%p",
    "ì§€ì—°ì‹œê°„ ì¦ê°€": "5-10ë°°"
}
```

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [Solar API í†µí•©](./solar_api_integration.md) - ì™¸ë¶€ API ì•™ìƒë¸”
- [ì„±ëŠ¥ ë¶„ì„](../../02_user_guides/evaluation/performance_analysis.md) - ì„±ëŠ¥ í‰ê°€
- [ë°°í¬ ê°€ì´ë“œ](../../05_deployment/README.md) - í”„ë¡œë•ì…˜ ë°°í¬
- [ì‹¤í—˜ ê´€ë¦¬](../../04_experiments/README.md) - ì•™ìƒë¸” ì‹¤í—˜

---

ì•™ìƒë¸” ê¸°ë²•ì„ í†µí•´ ë‹¨ì¼ ëª¨ë¸ì˜ í•œê³„ë¥¼ ê·¹ë³µí•˜ê³  ë” ì•ˆì •ì ì´ê³  ì •í™•í•œ ëŒ€í™” ìš”ì•½ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì„¸ìš”.
