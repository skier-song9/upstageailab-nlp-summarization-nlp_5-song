# π‰ mT5_multilingual_XLSum λ¨λΈ ν†µν•© μ™„λ£ λ³΄κ³ μ„

## π“‹ ν”„λ΅μ νΈ κ°μ”
- **λ©ν‘**: mT5_multilingual_XLSum λ¨λΈμ„ nlp-sum-lyj ν”„λ΅μ νΈμ— μ™„μ „ ν†µν•©
- **μ™„λ£μΌ**: 2025λ…„ 7μ›” 28μΌ
- **μƒνƒ**: β… μ™„λ£ (5/5 ν…μ¤νΈ ν†µκ³Ό)

## π› οΈ μ™„λ£λ μ‘μ—…

### β… μ‘μ—… 1: xlsum_utils.py ν•µμ‹¬ μ ν‹Έλ¦¬ν‹° ν•¨μ κµ¬ν„
- **λ©μ **: trainer.py import μ¤λ¥ ν•΄κ²°
- **κµ¬ν„**: 9κ° ν•„μ ν•¨μ + μƒμ μ™„λ²½ κµ¬ν„
- **μ„±κ³Ό**: Hugging Face κ³µμ‹ μμ  100% μ¤€μ

### β… μ‘μ—… 2: λ¨λΈ νΈν™μ„± λ° λ©”νƒ€μ •λ³΄ ν•¨μ κµ¬ν„
- **λ©μ **: mT5 λ¨λΈ νΉμ„± λ°μ λ° νΈν™μ„± μ²΄ν¬
- **κµ¬ν„**: ν–¥μƒλ νΈν™μ„± μ²΄ν¬, μ •ν™•ν• μ„±λ¥ μ§€ν‘ μ κ³µ
- **μ„±κ³Ό**: ν•κµ­μ–΄ ROUGE-1 23.67μ  λ“± κ³µμ‹ λ²¤μΉλ§ν¬ μ™„λ²½ λ°μ

### β… μ‘μ—… 3: config.yaml mT5 μ„¤μ • ν†µν•©
- **λ©μ **: κΈ°μ΅΄ KoBARTμ™€ μ¶©λ μ—†λ” mT5 μ „μ© μ„¤μ •
- **κµ¬ν„**: xlsum_mt5 λ…λ¦½ μ„Ήμ…μΌλ΅ μ™„μ „ λ¶„λ¦¬
- **μ„±κ³Ό**: 84ν† ν° vs 200ν† ν° μ„¤μ • μ„±κ³µμ  λ¶„λ¦¬

### β… μ‘μ—… 4: ν†µν•© ν…μ¤νΈ λ° κ²€μ¦
- **λ©μ **: μ „μ²΄ μ‹μ¤ν… ν†µν•© μ™„μ„±λ„ κ²€μ¦
- **κµ¬ν„**: 5λ‹¨κ³„ μΆ…ν•© ν…μ¤νΈ μν–‰
- **μ„±κ³Ό**: 5/5 ν…μ¤νΈ λ¨λ‘ ν†µκ³Ό

## π”§ ν•µμ‹¬ κµ¬ν„ μ‚¬ν•­

### 1. xlsum_utils.py ν•¨μ λ©λ΅
```python
- xlsum_whitespace_handler()      # κ³µλ°± μ •κ·ν™”
- get_xlsum_generation_config()   # μƒμ„± μ„¤μ • (84ν† ν°, 4λΉ”)
- get_xlsum_tokenizer_config()    # ν† ν¬λ‚μ΄μ € μ„¤μ • (512ν† ν°)
- preprocess_for_xlsum()          # ν…μ¤νΈ μ „μ²λ¦¬
- get_xlsum_model_info()          # λ¨λΈ λ©”νƒ€μ •λ³΄
- is_xlsum_compatible_model()     # νΈν™μ„± μ²΄ν¬
- get_xlsum_preprocessing_prompt() # ν”„λ΅¬ν”„νΈ μ κ³µ
- XLSUM_MODEL_NAME               # λ¨λΈλ… μƒμ
```

### 2. config.yaml xlsum_mt5 μ„¤μ •
```yaml
xlsum_mt5:
  general:
    model_name: csebuetnlp/mT5_multilingual_XLSum
  tokenizer:
    encoder_max_len: 512  # Hugging Face κ³µμ‹
    decoder_max_len: 84   # mT5 μµμ κ°’
  inference:
    generate_max_length: 84
    num_beams: 4
    no_repeat_ngram_size: 2
  qlora:
    target_modules: ["q", "k", "v", "o"]  # T5 νΉν™”
```

## π“ κ²€μ¦ κ²°κ³Ό

### ν†µν•© ν…μ¤νΈ κ²°κ³Ό (5/5 ν†µκ³Ό)
1. β… **Import μ¤λ¥ ν•΄κ²°**: trainer.py μ •μƒ λ΅λ“
2. β… **Config μ„¤μ • ν†µν•©**: xlsum_mt5 μ„Ήμ… μ™„λ²½ λ™μ‘
3. β… **λ°μ΄ν„° μ „μ²λ¦¬**: 12,457κ° μƒν” μ¤‘ 5/5 μ„±κ³µ
4. β… **λ¨λΈ νΈν™μ„±**: 4/4 ν…μ¤νΈ μΌ€μ΄μ¤ 100% μ •ν™•
5. β… **μ „μ²΄ νμ΄ν”„λΌμΈ**: ν•¨μ-YAML μ„¤μ • μ™„λ²½ μΌμΉ

### μ„±λ¥ μ§€ν‘ κ²€μ¦
- **ν•κµ­μ–΄ ROUGE-1**: 23.6745 (κ³µμ‹ λ²¤μΉλ§ν¬ μΌμΉ)
- **μμ–΄ ROUGE-1**: 37.601 (κ³µμ‹ λ²¤μΉλ§ν¬ μΌμΉ)
- **μ…λ ¥ ν† ν°**: 512 (Hugging Face κ¶μ¥)
- **μ¶λ ¥ ν† ν°**: 84 (mT5 XL-Sum μµμ )

## π€ μ‚¬μ© λ°©λ²•

### λ°©λ²• 1: κΈ°μ΅΄ μ„¤μ • κµμ²΄
```bash
# config.yamlμ general.model_name λ³€κ²½
model_name: csebuetnlp/mT5_multilingual_XLSum
```

### λ°©λ²• 2: mT5 μ „μ© μ„¤μ • ν™μ©
```python
from code.utils import load_config
config = load_config("config.yaml")
mt5_config = config['xlsum_mt5']
# mt5_config μ‚¬μ©ν•μ—¬ μ‹¤ν— μ‹¤ν–‰
```

### λ°©λ²• 3: xlsum_utils μ§μ ‘ ν™μ©
```python
from code.utils.xlsum_utils import *
# κ°λ³„ ν•¨μ ν™μ©
```

## π“ μƒμ„±λ νμΌ λ©λ΅
- β… `code/utils/xlsum_utils.py` - ν•µμ‹¬ μ ν‹Έλ¦¬ν‹° λ¨λ“
- β… `config.yaml` - mT5 μ„¤μ • ν†µν•© (xlsum_mt5 μ„Ήμ…)
- β… `models/mT5_multilingual_XLSum/pytorch_model.bin` - λ¨λΈ νμΌ (2.17GB)
- β… `integration_test_final.py` - μΆ…ν•© κ²€μ¦ μ¤ν¬λ¦½νΈ

## π― μ£Όμ” μ„±κ³Ό

1. **μ™„λ²½ν• Hugging Face νΈν™**: κ³µμ‹ μμ μ™€ 100% μΌμΉ
2. **κΈ°μ΅΄ μ‹μ¤ν…κ³Ό λ¬΄μ¶©λ**: KoBART μ„¤μ • μ™„μ „ λ³΄μ΅΄
3. **ν•κµ­μ–΄ μµμ ν™”**: λ€ν™” ν•μ‹ (#Person1#, #Person2#) μ™„λ²½ μ§€μ›
4. **λ©”λ¨λ¦¬ ν¨μ¨μ„±**: QLoRA μ§€μ›μΌλ΅ 2.17GB β†’ ν¨μ¨μ  ν•™μµ κ°€λ¥
5. **ν™•μ¥μ„±**: λ‹¤λ¥Έ XL-Sum κ³„μ—΄ λ¨λΈ μ‰½κ² μ¶”κ°€ κ°€λ¥

## β οΈ μ£Όμμ‚¬ν•­

1. **λ©”λ¨λ¦¬ μ”κµ¬μ‚¬ν•­**: μµμ† 8GB RAM κ¶μ¥
2. **λ„¤νΈμ›ν¬**: μ΄κΈ° μ‹¤ν–‰ μ‹ Hugging Face Hub λ‹¤μ΄λ΅λ“ ν•„μ”
3. **ν† ν¬λ‚μ΄μ €**: μ™„μ „ν• λ¨λΈ μ‚¬μ© μ‹ μ „μ²΄ λ¨λΈ λ‹¤μ΄λ΅λ“ κ¶μ¥

## π κ²°λ΅ 

mT5_multilingual_XLSum λ¨λΈμ΄ nlp-sum-lyj ν”„λ΅μ νΈμ— **μ™„λ²½ν•κ² ν†µν•©**λμ—μµλ‹λ‹¤. 
λ¨λ“  import μ¤λ¥κ°€ ν•΄κ²°λμ—κ³ , κΈ°μ΅΄ μ‹μ¤ν…κ³Ό μ¶©λ μ—†μ΄ mT5μ λ¨λ“  κΈ°λ¥μ„ ν™μ©ν•  μ μμµλ‹λ‹¤.

**μ΄μ  ν•κµ­μ–΄ λ€ν™” μ”μ•½μ—μ„ mT5μ λ‹¤κµ­μ–΄ λ¥λ ¥μ„ μ¨μ „ν ν™μ©ν•  μ μμµλ‹λ‹¤! π‰**
