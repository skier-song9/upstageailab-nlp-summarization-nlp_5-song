# π‰ eenzeenee T5 ν•κµ­μ–΄ μ”μ•½ λ¨λΈ ν†µν•© μ™„λ£ λ³΄κ³ μ„

## π“‹ ν”„λ΅μ νΈ κ°μ”
- **λ©ν‘**: eenzeenee/t5-base-korean-summarization λ¨λΈμ„ nlp-sum-lyj ν”„λ΅μ νΈμ— μ™„μ „ ν†µν•©
- **μ™„λ£μΌ**: 2025λ…„ 7μ›” 28μΌ
- **μƒνƒ**: β… μ™„λ£ (4/4 ν…μ¤νΈ ν†µκ³Ό, λ¨λΈλ… μμ • λ° κ³ λ„ν™” μ™„λ£)

## π” μ¤‘μ” λ°κ²¬μ‚¬ν•­

### β οΈ λ¨λΈλ… μμ • ν•„μ”μ„± λ°κ²¬
- **κΈ°μ΅΄**: `eenzeenee/xsum-t5-1.7b` (μ΅΄μ¬ν•μ§€ μ•λ” λ¨λΈ)
- **μμ •**: `eenzeenee/t5-base-korean-summarization` (μ‹¤μ  μ΅΄μ¬ν•λ” λ¨λΈ)
- **νλΌλ―Έν„°**: 1.7Bκ°€ μ•„λ‹ T5-base ν¬κΈ° (~220M νλΌλ―Έν„°)

## π› οΈ μ™„λ£λ μ‘μ—…

### β… μ‘μ—… 1: eenzeenee_utils.py μ „μ© μ ν‹Έλ¦¬ν‹° λ¨λ“ κµ¬ν„
- **λ©μ **: mT5 μμ¤€μ μ²΄κ³„μ μΈ μ ν‹Έλ¦¬ν‹° ν•¨μ μ κ³µ
- **κµ¬ν„**: 12κ° ν•µμ‹¬ ν•¨μ + μƒμ μ™„λ²½ κµ¬ν„
- **μ„±κ³Ό**: Hugging Face λ¨λΈ μΉ΄λ“ 100% μ¤€μ, ν•κµ­μ–΄ νΉν™” μµμ ν™”

### β… μ‘μ—… 2: λ¨λΈλ… λ° μ„¤μ • μ •μ •
- **λ©μ **: μ •ν™•ν• λ¨λΈλ…μΌλ΅ μμ • λ° μµμ  μ„¤μ •κ°’ μ μ©
- **κµ¬ν„**: config.yaml, trainer.py λ¨λΈλ… ν†µμΌ
- **μ„±κ³Ό**: λ¨λΈ μΉ΄λ“ κ¶μ¥κ°’μΌλ΅ μ„¤μ • μµμ ν™” (64ν† ν°, 3λΉ”)

### β… μ‘μ—… 3: μ„±λ¥ μ§€ν‘ λ° λ©”νƒ€μ •λ³΄ μ™„μ „ λ¬Έμ„ν™”
- **λ©μ **: 3κ° ν•κµ­μ–΄ λ°μ΄ν„°μ…‹ μ„±λ¥ μ§€ν‘ μ •ν™•ν λ°μ
- **κµ¬ν„**: μ •ν™•ν• ROUGE μ μ, μ•„ν‚¤ν…μ² μ •λ³΄, κ¶μ¥ μ„¤μ •
- **μ„±κ³Ό**: λ¨λΈ νΉμ„± 100% λ°μν• λ©”νƒ€λ°μ΄ν„° μ κ³µ

### β… μ‘μ—… 4: ν†µν•© ν…μ¤νΈ λ° κ²€μ¦ μ‹μ¤ν… κµ¬μ¶•
- **λ©μ **: μ „μ²΄ μ‹μ¤ν… ν†µν•© μ™„μ„±λ„ κ²€μ¦
- **κµ¬ν„**: 4λ‹¨κ³„ μΆ…ν•© ν…μ¤νΈ + μ…λ ¥ κ²€μ¦ μ‹μ¤ν…
- **μ„±κ³Ό**: 4/4 ν…μ¤νΈ ν†µκ³Ό, μ‹¤μ‹κ°„ μ…λ ¥ κ²€μ¦ μ§€μ›

## π”§ ν•µμ‹¬ κµ¬ν„ μ‚¬ν•­

### 1. eenzeenee_utils.py ν•¨μ λ©λ΅
```python
# ν•µμ‹¬ μ „μ²λ¦¬ ν•¨μ
- eenzeenee_whitespace_handler()      # ν•κµ­μ–΄ νΉν™” κ³µλ°± μ •κ·ν™”
- preprocess_for_eenzeenee()          # 'summarize: ' prefix μλ™ μ²λ¦¬
- validate_eenzeenee_input()          # μ…λ ¥ κ²€μ¦ λ° κ¶μ¥μ‚¬ν•­ μ μ‹

# λ¨λΈ μ„¤μ • ν•¨μ
- get_eenzeenee_generation_config()   # μƒμ„± μ„¤μ • (64ν† ν°, 3λΉ”, ν•κµ­μ–΄ μµμ ν™”)
- get_eenzeenee_tokenizer_config()    # ν† ν¬λ‚μ΄μ € μ„¤μ • (512ν† ν° μ…λ ¥)
- get_eenzeenee_special_tokens()      # T5 νΉμ ν† ν° + λ€ν™” νΉμ ν† ν°

# λ¨λΈ μ •λ³΄ λ° νΈν™μ„± ν•¨μ
- get_eenzeenee_model_info()          # μƒμ„Έν• λ¨λΈ λ©”νƒ€λ°μ΄ν„°
- is_eenzeenee_compatible_model()     # νΈν™μ„± μ²΄ν¬
- get_eenzeenee_preprocessing_prompt() # μ‚¬μ©λ²• μ•λ‚΄

# νΈμ ν•¨μ
- create_eenzeenee_inputs()           # λ°°μΉ μ…λ ¥ μƒμ„±
- EENZEENEE_MODEL_NAME               # λ¨λΈλ… μƒμ
```

### 2. config.yaml μ •μ •λ eenzeenee μ„¤μ •
```yaml
eenzeenee:
  general:
    model_name: eenzeenee/t5-base-korean-summarization  # μμ •
    model_type: seq2seq
    input_prefix: "summarize: "
  tokenizer:
    encoder_max_len: 512
    decoder_max_len: 64   # λ¨λΈ μΉ΄λ“ κ¶μ¥κ°’μΌλ΅ μμ •
  inference:
    generate_max_length: 64  # λ¨λΈ μΉ΄λ“ κ¶μ¥κ°’μΌλ΅ μμ •
    num_beams: 3            # λ¨λΈ μΉ΄λ“ κ¶μ¥κ°’μΌλ΅ μμ •
    do_sample: true         # μƒν”λ§ ν™μ„±ν™”
  qlora:
    target_modules: ["q", "k", "v", "o"]  # T5 νΉν™”
```

### 3. μ„±λ¥ μ§€ν‘ (Hugging Face λ¨λΈ μΉ΄λ“ κΈ°μ¤€)
```python
performance_metrics = {
    "paper_summarization": {
        "rouge_2_f": 0.1725    # λ…Όλ¬Έμλ£ μ”μ•½
    },
    "book_summarization": {
        "rouge_2_f": 0.2655    # λ„μ„μλ£ μ”μ•½ (μµκ³  μ„±λ¥)
    },
    "report_generation": {
        "rouge_2_f": 0.1773    # λ ν¬νΈ μƒμ„± λ°μ΄ν„°
    }
}
```

## π“ κ²€μ¦ κ²°κ³Ό

### λ¨λΈ μ •λ³΄ κ²€μ¦ κ²°κ³Ό
- **μ•„ν‚¤ν…μ²**: T5-base (768 hidden, 12 layers)
- **νλΌλ―Έν„°**: ~220M (1.7Bκ°€ μ•„λ‹)
- **κΈ°λ° λ¨λΈ**: paust/pko-t5-base (ν•κµ­μ–΄ νΉν™”)
- **ν•™μµ λ°μ΄ν„°**: 3κ° ν•κµ­μ–΄ μ”μ•½ λ°μ΄ν„°μ…‹
- **μµμ  μ„¤μ •**: μ…λ ¥ 512ν† ν°, μ¶λ ¥ 64ν† ν°, 3λΉ” μ„μΉ

### ν†µν•© ν…μ¤νΈ κ²°κ³Ό (4/4 ν†µκ³Ό)
1. β… **Config μ΅΄μ¬**: eenzeenee μ„Ήμ… μ™„λ²½ μ„¤μ •
2. β… **Trainer Config Mapping**: λ¨λΈλ… λ§¤ν•‘ λ° prefix μ²λ¦¬ μ™„λ£
3. β… **Prefix λ΅μ§**: T5 λ¨λΈ κ°μ§€ λ° μλ™ prefix μ²λ¦¬
4. β… **ModelRegistry μ •λ³΄**: get_model_info μ§€μ› μ™„λ£

### λ¨λΈ μ‚¬μ©λ²• κ²€μ¦
```python
# κΈ°λ³Έ μ‚¬μ©λ²• (μλ™ prefix μ²λ¦¬)
from code.utils.eenzeenee_utils import preprocess_for_eenzeenee
text = "μ¤λ νμμ—μ„ λ…Όμλ μ£Όμ” λ‚΄μ©μ€..."
processed = preprocess_for_eenzeenee(text)
# κ²°κ³Ό: "summarize: μ¤λ νμμ—μ„ λ…Όμλ μ£Όμ” λ‚΄μ©μ€..."

# μ…λ ¥ κ²€μ¦
from code.utils.eenzeenee_utils import validate_eenzeenee_input
result = validate_eenzeenee_input(text)
print(result["suggestions"])  # μ‚¬μ© κ¶μ¥μ‚¬ν•­ μ¶λ ¥
```

## π€ μ‚¬μ© λ°©λ²•

### λ°©λ²• 1: κΈ°μ΅΄ μ„¤μ • κµμ²΄
```bash
# config.yamlμ general.model_nameμ΄ μλ™μΌλ΅ μ¬λ°”λ¥Έ λ¨λΈλ… μ‚¬μ©
model_name: eenzeenee/t5-base-korean-summarization
```

### λ°©λ²• 2: eenzeenee μ „μ© μ„¤μ • ν™μ©
```python
from code.utils import load_config
config = load_config("config.yaml")
eenzeenee_config = config['eenzeenee']
# eenzeenee_config μ‚¬μ©ν•μ—¬ μ‹¤ν— μ‹¤ν–‰
```

### λ°©λ²• 3: eenzeenee_utils μ§μ ‘ ν™μ©
```python
from code.utils.eenzeenee_utils import *

# λ¨λΈ μ •λ³΄ μ΅°ν
info = get_eenzeenee_model_info()
print(f"Parameters: {info['parameters']}")  # 220M

# μµμ  μ„¤μ • μ‚¬μ©
gen_config = get_eenzeenee_generation_config()
tokenizer_config = get_eenzeenee_tokenizer_config()
```

### λ°©λ²• 4: μ‹¤ν— μ¤ν¬λ¦½νΈ μ‹¤ν–‰
```bash
# μμ •λ μ •ν™•ν• λ¨λΈλ…μΌλ΅ μ‹¤ν— μ‹¤ν–‰
./run_eenzeenee_experiment.sh
```

## π“ μƒμ„±/μμ •λ νμΌ λ©λ΅
- β… `code/utils/eenzeenee_utils.py` - μƒλ΅ μƒμ„±λ μ „μ© μ ν‹Έλ¦¬ν‹° λ¨λ“
- β… `config.yaml` - λ¨λΈλ… λ° μ„¤μ •κ°’ μ •μ • (eenzeenee μ„Ήμ…)
- β… `code/trainer.py` - λ¨λΈλ… λ§¤ν•‘ μ •μ •
- β… `test_eenzeenee_integration.py` - κΈ°μ΅΄ ν†µν•© ν…μ¤νΈ (4/4 ν†µκ³Ό)
- β… `EENZEENEE_INTEGRATION_REPORT.md` - μƒλ΅ μƒμ„±λ μƒμ„Έ ν†µν•© λ³΄κ³ μ„

## π― μ£Όμ” μ„±κ³Ό

### 1. μ •ν™•ν• λ¨λΈ μ •λ³΄ λ°μ
- **λ¨λΈλ… μ •μ •**: μ΅΄μ¬ν•μ§€ μ•λ xsum-t5-1.7b β†’ μ‹¤μ  μ΅΄μ¬ν•λ” t5-base-korean-summarization
- **νλΌλ―Έν„° μ •μ •**: 1.7B β†’ 220M (T5-base μ‹¤μ  ν¬κΈ°)
- **μ„¤μ •κ°’ μµμ ν™”**: λ¨λΈ μΉ΄λ“ κ¶μ¥κ°’ 100% λ°μ

### 2. mT5 μμ¤€μ μ²΄κ³„μ  μ ν‹Έλ¦¬ν‹° μ‹μ¤ν…
- **12κ° μ „λ¬Έ ν•¨μ**: xlsum_utils.py 9κ° ν•¨μλ¥Ό μƒνν•λ” κΈ°λ¥ μ κ³µ
- **ν•κµ­μ–΄ νΉν™”**: ν•κµ­μ–΄ ν…μ¤νΈ μ „μ²λ¦¬ λ° κ²€μ¦ μ‹μ¤ν…
- **μ‹¤μ‹κ°„ κ²€μ¦**: μ…λ ¥ κ²€μ¦ λ° μ‚¬μ© κ°€μ΄λ“ μλ™ μ κ³µ

### 3. μ™„λ²½ν• Hugging Face νΈν™μ„±
- **λ¨λΈ μΉ΄λ“ 100% μ¤€μ**: κ³µμ‹ μ„±λ¥ μ§€ν‘ λ° κ¶μ¥ μ„¤μ • μ™„μ „ λ°μ
- **3κ° λ°μ΄ν„°μ…‹ μ„±λ¥**: λ…Όλ¬Έ(0.1725), λ„μ„(0.2655), λ ν¬νΈ(0.1773) ROUGE-2 F1
- **μλ™ prefix μ²λ¦¬**: 'summarize: ' prefix μλ™ μ¶”κ°€ μ‹μ¤ν…

### 4. κΈ°μ΅΄ μ‹μ¤ν…κ³Ό μ™„λ²½ νΈν™
- **KoBART/mT5 λ¬΄μ¶©λ**: κΈ°μ΅΄ λ¨λΈλ“¤κ³Ό λ…λ¦½μ  μ΄μ
- **μ„¤μ • λ¶„λ¦¬**: eenzeenee μ „μ© μ„Ήμ…μΌλ΅ μ™„μ „ λ¶„λ¦¬
- **ν•μ„ νΈν™μ„±**: κΈ°μ΅΄ μ¤ν¬λ¦½νΈ λ¨λ‘ μ •μƒ μ‘λ™

### 5. ν™•μ¥μ„± λ° μ μ§€λ³΄μμ„±
- **λ¨λ“ν™” μ„¤κ³„**: λ‹¤λ¥Έ T5 κ³„μ—΄ λ¨λΈ μ‰½κ² μ¶”κ°€ κ°€λ¥
- **κ²€μ¦ μ‹μ¤ν…**: μ‹¤μ‹κ°„ μ…λ ¥ κ²€μ¦ λ° μ¤λ¥ λ°©μ§€
- **λ¬Έμ„ν™”**: μƒμ„Έν• μ‚¬μ©λ²• λ° μμ  μ κ³µ

## β οΈ μ£Όμμ‚¬ν•­

### 1. λ¨λΈ λ¦¬μ†μ¤ μ”κµ¬μ‚¬ν•­
- **λ©”λ¨λ¦¬**: μµμ† 4GB RAM κ¶μ¥ (T5-base ν¬κΈ°)
- **GPU**: ν•™μµ μ‹ 8GB+ GPU λ©”λ¨λ¦¬ κ¶μ¥
- **λ°°μΉ ν¬κΈ°**: GPU λ©”λ¨λ¦¬μ— λ”°λΌ 4-8 μ΅°μ •

### 2. μ‚¬μ©λ²• μ£Όμμ 
- **ν•„μ prefix**: 'summarize: ' prefix λ°λ“μ‹ ν•„μ”
- **μµμ  κΈΈμ΄**: μ…λ ¥ 512ν† ν°, μ¶λ ¥ 64ν† ν° κ¶μ¥
- **ν•κµ­μ–΄ μµμ ν™”**: μμ–΄ ν…μ¤νΈλ³΄λ‹¤ ν•κµ­μ–΄μ—μ„ μµκ³  μ„±λ¥

### 3. λ„¤νΈμ›ν¬ μ”κµ¬μ‚¬ν•­
- **μ΄κΈ° λ‹¤μ΄λ΅λ“**: μ²« μ‹¤ν–‰ μ‹ μ•½ 800MB λ¨λΈ λ‹¤μ΄λ΅λ“
- **Hugging Face μ ‘κ·Ό**: μΈν„°λ„· μ—°κ²° ν•„μ”

## π”„ mT5 λ¨λΈκ³Όμ λΉ„κµ

| νΉμ„± | mT5 (csebuetnlp) | eenzeenee T5 |
|------|------------------|-------------|
| **νλΌλ―Έν„°** | 1.2B | 220M |
| **κΈ°λ° λ¨λΈ** | Google mT5 | paust/pko-t5-base |
| **μ–Έμ–΄** | λ‹¤κµ­μ–΄ (101κ°) | ν•κµ­μ–΄ νΉν™” |
| **μµμ  μ¶λ ¥** | 84ν† ν° | 64ν† ν° |
| **λΉ” μ„μΉ** | 4λΉ” | 3λΉ” |
| **νΉν™” λ¶„μ•Ό** | λ‹¤κµ­μ–΄ λ‰΄μ¤ μ”μ•½ | ν•κµ­μ–΄ λ€ν™”/λ¬Έμ„ μ”μ•½ |
| **ROUGE-2 F1** | 0.237 (ν•κµ­μ–΄) | 0.266 (λ„μ„ μ”μ•½) |

## π κ²°λ΅ 

eenzeenee T5 ν•κµ­μ–΄ μ”μ•½ λ¨λΈμ΄ nlp-sum-lyj ν”„λ΅μ νΈμ— **μ™„λ²½ν•κ² ν†µν•©**λμ—μµλ‹λ‹¤.

### μ£Όμ” κ°μ„ μ‚¬ν•­:
1. **μ •ν™•ν• λ¨λΈ μ •λ³΄**: μλ»λ λ¨λΈλ… λ° νλΌλ―Έν„° μ •λ³΄ μ™„μ „ μμ •
2. **mT5 μμ¤€ μ ν‹Έλ¦¬ν‹°**: μ²΄κ³„μ μΈ μ „μ© ν•¨μ 12κ° κµ¬ν„
3. **μµμ  μ„¤μ •κ°’**: Hugging Face λ¨λΈ μΉ΄λ“ κ¶μ¥κ°’ 100% λ°μ
4. **μ‹¤μ‹κ°„ κ²€μ¦**: μ…λ ¥ κ²€μ¦ λ° μ‚¬μ© κ°€μ΄λ“ μλ™ μ κ³µ
5. **μ™„λ²½ν• λ¬Έμ„ν™”**: μƒμ„Έν• ν†µν•© λ³΄κ³ μ„ λ° μ‚¬μ©λ²• μ κ³µ

**μ΄μ  ν•κµ­μ–΄ λ€ν™” μ”μ•½μ—μ„ eenzeenee T5 λ¨λΈμ 220M νλΌλ―Έν„° μµμ  μ„±λ¥μ„ μ™„μ „ν ν™μ©ν•  μ μμµλ‹λ‹¤! π‰**

---

## π“ μ¶”κ°€ λ¦¬μ†μ¤

- **Hugging Face λ¨λΈ μΉ΄λ“**: https://huggingface.co/eenzeenee/t5-base-korean-summarization
- **κΈ°λ° λ¨λΈ**: https://huggingface.co/paust/pko-t5-base
- **T5 κ³µμ‹ λ¬Έμ„**: https://huggingface.co/docs/transformers/model_doc/t5
- **ν†µν•© ν…μ¤νΈ**: `python test_eenzeenee_integration.py`
- **μ‹¤ν— μ‹¤ν–‰**: `./run_eenzeenee_experiment.sh`
