#!/usr/bin/env python3
"""
auto_experiment_runner.pyì— ì¶”ë¡  ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ëŠ” íŒ¨ì¹˜ ìŠ¤í¬ë¦½íŠ¸
"""

import re

def patch_auto_experiment_runner():
    # íŒŒì¼ ì½ê¸°
    with open('/data/ephemeral/home/upstageailab-nlp-summarization-nlp_5/code/auto_experiment_runner.py', 'r', encoding='utf-8') as f:
        content = f.read()

    # ì‚½ì…í•  ì¶”ë¡  ì½”ë“œ
    inference_code = '''                
                # ğŸ†• í•™ìŠµ ì™„ë£Œ í›„ test.csv ì¶”ë¡  ìˆ˜í–‰
                print(f"\\nğŸ“Š Test ì¶”ë¡  ì‹œì‘: {experiment_id}")
                
                try:
                    # ë² ìŠ¤íŠ¸ ì²´í¬í¬ì¸íŠ¸ ì°¾ê¸°
                    output_dir = Path(config.get('training', {}).get('output_dir', 'outputs'))
                    checkpoint_dirs = list(output_dir.glob('checkpoint-*'))
                    
                    if checkpoint_dirs:
                        # ê°€ì¥ ìµœê·¼ ì²´í¬í¬ì¸íŠ¸ ì„ íƒ
                        best_checkpoint = max(checkpoint_dirs, key=lambda p: p.stat().st_mtime)
                        print(f"ğŸ¯ ë² ìŠ¤íŠ¸ ì²´í¬í¬ì¸íŠ¸: {best_checkpoint}")
                        
                        # post_training_inference í™œìš©
                        try:
                            from post_training_inference import generate_submission_after_training
                            
                            submission_path = generate_submission_after_training(
                                experiment_name=experiment_id,
                                model_path=str(best_checkpoint),
                                config_dict=config
                            )
                            
                            print(f"âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {submission_path}")
                            result = self._collect_results(config, Path(config_path).stem)
                            result['submission_path'] = submission_path
                            
                        except ImportError as ie:
                            print(f"âš ï¸ post_training_inference import ì‹¤íŒ¨: {ie}")
                            # ëŒ€ì•ˆ: run_inference.py ì§ì ‘ ì‚¬ìš©
                            try:
                                inference_cmd = [
                                    sys.executable,
                                    str(path_manager.resolve_path("code/run_inference.py")),
                                    "--model_path", str(best_checkpoint),
                                    "--input_file", "data/test.csv",
                                    "--output_file", f"outputs/auto_experiments/{experiment_id}_submission.csv",
                                    "--batch_size", "16"
                                ]
                                
                                print(f"ğŸ”„ ëŒ€ì•ˆ ì¶”ë¡  ì‹¤í–‰: {' '.join(inference_cmd)}")
                                
                                inference_process = subprocess.run(
                                    inference_cmd,
                                    capture_output=True,
                                    text=True,
                                    env=env
                                )
                                
                                if inference_process.returncode == 0:
                                    submission_path = f"outputs/auto_experiments/{experiment_id}_submission.csv"
                                    print(f"âœ… ëŒ€ì•ˆ ì¶”ë¡  ì„±ê³µ: {submission_path}")
                                    result = self._collect_results(config, Path(config_path).stem)
                                    result['submission_path'] = submission_path
                                else:
                                    print(f"âŒ ëŒ€ì•ˆ ì¶”ë¡  ì‹¤íŒ¨: {inference_process.stderr}")
                                    result = self._collect_results(config, Path(config_path).stem)
                                    result['inference_error'] = inference_process.stderr
                                    
                            except Exception as alt_e:
                                print(f"âŒ ëŒ€ì•ˆ ì¶”ë¡  ì˜ˆì™¸: {alt_e}")
                                result = self._collect_results(config, Path(config_path).stem)
                                result['inference_error'] = str(alt_e)
                                
                    else:
                        print("âš ï¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        result = self._collect_results(config, Path(config_path).stem)
                        result['inference_error'] = "No checkpoint found"
                        
                except Exception as inf_e:
                    print(f"âŒ ì¶”ë¡  ì‹¤í–‰ ì¤‘ ì˜ˆì™¸: {inf_e}")
                    result = self._collect_results(config, Path(config_path).stem)
                    result['inference_error'] = str(inf_e)'''

    # íƒ€ê²Ÿ ë¼ì¸ ì°¾ê¸° ë° êµì²´
    original_line = "                result = self._collect_results(config, Path(config_path).stem)"

    if original_line in content:
        # ì›ë³¸ ë¼ì¸ì„ ì¶”ë¡  ì½”ë“œë¡œ êµì²´ (ì¶”ë¡  ì½”ë“œ ë‚´ì— ì´ë¯¸ result í• ë‹¹ í¬í•¨)
        new_content = content.replace(
            original_line,
            inference_code.rstrip()
        )
        
        # íŒŒì¼ ì“°ê¸°
        with open('/data/ephemeral/home/upstageailab-nlp-summarization-nlp_5/code/auto_experiment_runner.py', 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        print("âœ… auto_experiment_runner.py ìˆ˜ì • ì™„ë£Œ!")
        print("ì¶”ê°€ëœ ê¸°ëŠ¥: í•™ìŠµ ì™„ë£Œ í›„ ìë™ test.csv ì¶”ë¡ ")
        return True
    else:
        print("âŒ íƒ€ê²Ÿ ë¼ì¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ì›ë³¸ ë¼ì¸:", repr(original_line))
        return False

if __name__ == "__main__":
    patch_auto_experiment_runner()
